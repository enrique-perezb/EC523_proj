{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph Attention Model Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import MSELoss\n",
    "from torch.optim import Adam\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def train_gat(model, train_loader, val_loader, epochs=10, lr=1e-3, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "\n",
    "    # Create dictionary to save all results (used for plots)\n",
    "    results_dict = {\n",
    "        'train_loss': [],\n",
    "        'train_mae': [],\n",
    "        'val_loss': [],\n",
    "        'val_mae': [],\n",
    "        'train_preds': [],\n",
    "        'train_targets': [],\n",
    "        'val_preds': [],\n",
    "        'val_targets': [],\n",
    "    }\n",
    "\n",
    "    # Start model, with Adam optimizer and MSE loss\n",
    "    model = model.to(device)\n",
    "    optimizer = Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = MSELoss()\n",
    "\n",
    "    best_val_mae = float('inf')\n",
    "    best_val_rmse = float('inf')\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "\n",
    "        train_preds = []\n",
    "        train_targets = []\n",
    "\n",
    "        # Train loop\n",
    "        for batch in train_loader:\n",
    "            batch = batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(batch)\n",
    "            loss = loss_fn(out, batch.y.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "            train_preds.extend(out.detach().cpu().numpy())\n",
    "            train_targets.extend(batch.y.cpu().numpy())\n",
    "\n",
    "        train_mae = mean_absolute_error(train_targets, train_preds)\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        val_preds = []\n",
    "        val_targets = []\n",
    "\n",
    "        # Validation loop\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                batch = batch.to(device)\n",
    "                out = model(batch)\n",
    "                val_preds.extend(out.cpu().numpy())\n",
    "                val_targets.extend(batch.y.cpu().numpy())\n",
    "\n",
    "        # Rest of function stores information of model\n",
    "        val_mae = mean_absolute_error(val_targets, val_preds)\n",
    "        val_rmse = np.sqrt(np.mean([(pred - target)**2 for pred, target in zip(val_preds, val_targets)]))\n",
    "\n",
    "        print(f\"Epoch {epoch:03d}: Train Loss = {sum(train_losses)/len(train_losses):.4f}, Val MAE = {val_mae:.2f}, Val RMSE = {val_rmse:.2f}\")\n",
    "\n",
    "        if val_mae < best_val_mae:\n",
    "            best_val_mae = val_mae\n",
    "            best_val_rmse = val_rmse\n",
    "            best_model_state = model.state_dict()\n",
    "\n",
    "            results_dict['train_preds'] = train_preds\n",
    "            results_dict['train_targets'] = train_targets\n",
    "            results_dict['val_preds'] = val_preds\n",
    "            results_dict['val_targets'] = val_targets\n",
    "\n",
    "        results_dict['train_loss'].append(sum(train_losses)/len(train_losses))\n",
    "        results_dict['train_mae'].append(train_mae)\n",
    "\n",
    "        val_losses = [(pred - target)**2 for pred, target in zip(val_preds, val_targets)]\n",
    "        val_loss_epoch = sum(val_losses) / len(val_losses)\n",
    "        results_dict['val_loss'].append(val_loss_epoch)\n",
    "        results_dict['val_mae'].append(val_mae)\n",
    "        \n",
    "\n",
    "    return best_model_state, best_val_mae, best_val_rmse, results_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1 --------------------------\n",
      "Epoch 001: Train Loss = 84046.7769, Val MAE = 18.56, Val RMSE = 23.60\n",
      "Epoch 002: Train Loss = 1312.8610, Val MAE = 8.75, Val RMSE = 17.26\n",
      "Epoch 003: Train Loss = 795.6152, Val MAE = 8.29, Val RMSE = 14.86\n",
      "Epoch 004: Train Loss = 641.5888, Val MAE = 11.69, Val RMSE = 14.53\n",
      "Epoch 005: Train Loss = 537.1790, Val MAE = 8.33, Val RMSE = 11.46\n",
      "Epoch 006: Train Loss = 496.9230, Val MAE = 5.81, Val RMSE = 9.64\n",
      "Epoch 007: Train Loss = 322.5262, Val MAE = 4.24, Val RMSE = 6.18\n",
      "Epoch 008: Train Loss = 274.1289, Val MAE = 6.80, Val RMSE = 7.67\n",
      "Epoch 009: Train Loss = 201.1462, Val MAE = 4.31, Val RMSE = 5.50\n",
      "Epoch 010: Train Loss = 210.7611, Val MAE = 4.45, Val RMSE = 5.71\n",
      "Epoch 011: Train Loss = 153.9927, Val MAE = 3.86, Val RMSE = 5.15\n",
      "Epoch 012: Train Loss = 153.4748, Val MAE = 4.55, Val RMSE = 6.24\n",
      "Epoch 013: Train Loss = 119.2142, Val MAE = 4.74, Val RMSE = 6.32\n",
      "Epoch 014: Train Loss = 118.6211, Val MAE = 4.10, Val RMSE = 5.90\n",
      "Epoch 015: Train Loss = 94.5282, Val MAE = 4.57, Val RMSE = 5.94\n",
      "Epoch 016: Train Loss = 82.0927, Val MAE = 3.75, Val RMSE = 5.24\n",
      "Epoch 017: Train Loss = 66.2562, Val MAE = 3.98, Val RMSE = 5.38\n",
      "Epoch 018: Train Loss = 57.4528, Val MAE = 6.10, Val RMSE = 7.29\n",
      "Epoch 019: Train Loss = 81.5860, Val MAE = 4.20, Val RMSE = 5.90\n",
      "Epoch 020: Train Loss = 61.3279, Val MAE = 5.21, Val RMSE = 6.41\n",
      "Epoch 021: Train Loss = 58.0608, Val MAE = 6.76, Val RMSE = 7.83\n",
      "Epoch 022: Train Loss = 56.7904, Val MAE = 6.80, Val RMSE = 7.78\n",
      "Epoch 023: Train Loss = 54.0331, Val MAE = 5.19, Val RMSE = 6.32\n",
      "Epoch 024: Train Loss = 40.7689, Val MAE = 4.05, Val RMSE = 5.40\n",
      "Epoch 025: Train Loss = 46.0239, Val MAE = 3.88, Val RMSE = 5.37\n",
      "Epoch 026: Train Loss = 53.4524, Val MAE = 5.87, Val RMSE = 6.88\n",
      "Epoch 027: Train Loss = 48.6707, Val MAE = 5.68, Val RMSE = 6.74\n",
      "Epoch 028: Train Loss = 42.0072, Val MAE = 4.04, Val RMSE = 5.42\n",
      "Epoch 029: Train Loss = 56.3540, Val MAE = 4.32, Val RMSE = 6.02\n",
      "Epoch 030: Train Loss = 45.6524, Val MAE = 5.38, Val RMSE = 6.44\n",
      "Epoch 031: Train Loss = 42.4196, Val MAE = 3.96, Val RMSE = 5.36\n",
      "Epoch 032: Train Loss = 49.7048, Val MAE = 3.95, Val RMSE = 5.37\n",
      "Epoch 033: Train Loss = 42.7364, Val MAE = 3.95, Val RMSE = 5.39\n",
      "Epoch 034: Train Loss = 38.3303, Val MAE = 5.63, Val RMSE = 6.65\n",
      "Epoch 035: Train Loss = 46.6387, Val MAE = 4.00, Val RMSE = 5.50\n",
      "Epoch 036: Train Loss = 46.4771, Val MAE = 4.91, Val RMSE = 6.14\n",
      "Epoch 037: Train Loss = 46.7081, Val MAE = 5.11, Val RMSE = 6.32\n",
      "Epoch 038: Train Loss = 41.5775, Val MAE = 4.01, Val RMSE = 5.35\n",
      "Epoch 039: Train Loss = 45.8274, Val MAE = 5.01, Val RMSE = 6.15\n",
      "Epoch 040: Train Loss = 43.6473, Val MAE = 4.18, Val RMSE = 5.66\n",
      "Epoch 041: Train Loss = 41.2311, Val MAE = 4.99, Val RMSE = 6.09\n",
      "Epoch 042: Train Loss = 46.9080, Val MAE = 4.10, Val RMSE = 5.62\n",
      "Epoch 043: Train Loss = 45.9285, Val MAE = 4.12, Val RMSE = 5.58\n",
      "Epoch 044: Train Loss = 49.8332, Val MAE = 3.94, Val RMSE = 5.55\n",
      "Epoch 045: Train Loss = 36.5613, Val MAE = 4.05, Val RMSE = 5.49\n",
      "Epoch 046: Train Loss = 38.1278, Val MAE = 4.87, Val RMSE = 6.05\n",
      "Epoch 047: Train Loss = 42.2533, Val MAE = 5.06, Val RMSE = 6.65\n",
      "Epoch 048: Train Loss = 45.0952, Val MAE = 5.02, Val RMSE = 6.13\n",
      "Epoch 049: Train Loss = 34.9260, Val MAE = 4.45, Val RMSE = 5.67\n",
      "Epoch 050: Train Loss = 44.6889, Val MAE = 7.96, Val RMSE = 8.79\n",
      "Fold 1 Best MAE: 3.75, Best RMSE: 5.24\n",
      "\n",
      "Fold 2 --------------------------\n",
      "Epoch 001: Train Loss = 1846.5022, Val MAE = 11.76, Val RMSE = 20.83\n",
      "Epoch 002: Train Loss = 1044.8546, Val MAE = 9.60, Val RMSE = 16.00\n",
      "Epoch 003: Train Loss = 655.1635, Val MAE = 7.42, Val RMSE = 11.53\n",
      "Epoch 004: Train Loss = 606.5994, Val MAE = 8.04, Val RMSE = 11.48\n",
      "Epoch 005: Train Loss = 345.6348, Val MAE = 7.93, Val RMSE = 10.81\n",
      "Epoch 006: Train Loss = 235.5924, Val MAE = 7.36, Val RMSE = 10.35\n",
      "Epoch 007: Train Loss = 248.2108, Val MAE = 7.49, Val RMSE = 10.33\n",
      "Epoch 008: Train Loss = 237.3288, Val MAE = 7.52, Val RMSE = 10.85\n",
      "Epoch 009: Train Loss = 177.5305, Val MAE = 7.77, Val RMSE = 10.49\n",
      "Epoch 010: Train Loss = 161.3227, Val MAE = 6.68, Val RMSE = 9.87\n",
      "Epoch 011: Train Loss = 145.6418, Val MAE = 6.32, Val RMSE = 8.80\n",
      "Epoch 012: Train Loss = 141.1587, Val MAE = 6.50, Val RMSE = 8.63\n",
      "Epoch 013: Train Loss = 129.2677, Val MAE = 6.95, Val RMSE = 9.00\n",
      "Epoch 014: Train Loss = 111.4136, Val MAE = 6.13, Val RMSE = 8.31\n",
      "Epoch 015: Train Loss = 105.5158, Val MAE = 6.20, Val RMSE = 8.95\n",
      "Epoch 016: Train Loss = 90.0847, Val MAE = 6.13, Val RMSE = 8.54\n",
      "Epoch 017: Train Loss = 73.2562, Val MAE = 6.70, Val RMSE = 9.09\n",
      "Epoch 018: Train Loss = 80.7131, Val MAE = 6.11, Val RMSE = 8.11\n",
      "Epoch 019: Train Loss = 69.3527, Val MAE = 6.00, Val RMSE = 7.95\n",
      "Epoch 020: Train Loss = 58.0943, Val MAE = 5.77, Val RMSE = 7.55\n",
      "Epoch 021: Train Loss = 62.1981, Val MAE = 5.80, Val RMSE = 7.47\n",
      "Epoch 022: Train Loss = 54.6814, Val MAE = 5.52, Val RMSE = 7.06\n",
      "Epoch 023: Train Loss = 49.6690, Val MAE = 5.55, Val RMSE = 7.02\n",
      "Epoch 024: Train Loss = 50.1340, Val MAE = 5.76, Val RMSE = 7.30\n",
      "Epoch 025: Train Loss = 58.4265, Val MAE = 5.67, Val RMSE = 6.96\n",
      "Epoch 026: Train Loss = 44.6458, Val MAE = 5.53, Val RMSE = 6.87\n",
      "Epoch 027: Train Loss = 51.7058, Val MAE = 5.41, Val RMSE = 6.53\n",
      "Epoch 028: Train Loss = 45.7715, Val MAE = 5.35, Val RMSE = 6.40\n",
      "Epoch 029: Train Loss = 44.0615, Val MAE = 5.29, Val RMSE = 6.50\n",
      "Epoch 030: Train Loss = 44.2928, Val MAE = 5.28, Val RMSE = 6.23\n",
      "Epoch 031: Train Loss = 50.3205, Val MAE = 5.27, Val RMSE = 6.19\n",
      "Epoch 032: Train Loss = 45.5462, Val MAE = 5.42, Val RMSE = 6.61\n",
      "Epoch 033: Train Loss = 41.4040, Val MAE = 6.22, Val RMSE = 7.58\n",
      "Epoch 034: Train Loss = 40.1274, Val MAE = 5.22, Val RMSE = 6.16\n",
      "Epoch 035: Train Loss = 44.9233, Val MAE = 5.17, Val RMSE = 6.24\n",
      "Epoch 036: Train Loss = 44.2650, Val MAE = 5.23, Val RMSE = 6.27\n",
      "Epoch 037: Train Loss = 40.4226, Val MAE = 5.09, Val RMSE = 6.21\n",
      "Epoch 038: Train Loss = 39.2600, Val MAE = 5.17, Val RMSE = 6.24\n",
      "Epoch 039: Train Loss = 37.7404, Val MAE = 5.05, Val RMSE = 6.08\n",
      "Epoch 040: Train Loss = 37.4927, Val MAE = 5.01, Val RMSE = 5.89\n",
      "Epoch 041: Train Loss = 45.4999, Val MAE = 5.02, Val RMSE = 5.97\n",
      "Epoch 042: Train Loss = 40.2395, Val MAE = 6.35, Val RMSE = 7.51\n",
      "Epoch 043: Train Loss = 45.3053, Val MAE = 5.13, Val RMSE = 6.17\n",
      "Epoch 044: Train Loss = 39.1025, Val MAE = 5.39, Val RMSE = 6.49\n",
      "Epoch 045: Train Loss = 41.4629, Val MAE = 5.15, Val RMSE = 6.05\n",
      "Epoch 046: Train Loss = 47.5868, Val MAE = 5.17, Val RMSE = 6.04\n",
      "Epoch 047: Train Loss = 43.1836, Val MAE = 5.42, Val RMSE = 6.35\n",
      "Epoch 048: Train Loss = 50.7714, Val MAE = 6.12, Val RMSE = 7.37\n",
      "Epoch 049: Train Loss = 41.9130, Val MAE = 5.30, Val RMSE = 6.16\n",
      "Epoch 050: Train Loss = 44.1564, Val MAE = 5.29, Val RMSE = 6.08\n",
      "Fold 2 Best MAE: 5.01, Best RMSE: 5.89\n",
      "\n",
      "Fold 3 --------------------------\n",
      "Epoch 001: Train Loss = 85786.7731, Val MAE = 46.23, Val RMSE = 46.59\n",
      "Epoch 002: Train Loss = 2110.4854, Val MAE = 15.12, Val RMSE = 21.52\n",
      "Epoch 003: Train Loss = 1349.7366, Val MAE = 9.63, Val RMSE = 18.10\n",
      "Epoch 004: Train Loss = 962.8507, Val MAE = 8.64, Val RMSE = 15.36\n",
      "Epoch 005: Train Loss = 737.3149, Val MAE = 7.64, Val RMSE = 13.16\n",
      "Epoch 006: Train Loss = 511.1905, Val MAE = 6.42, Val RMSE = 10.91\n",
      "Epoch 007: Train Loss = 340.2769, Val MAE = 5.40, Val RMSE = 9.23\n",
      "Epoch 008: Train Loss = 309.4291, Val MAE = 4.92, Val RMSE = 7.53\n",
      "Epoch 009: Train Loss = 314.0802, Val MAE = 5.14, Val RMSE = 6.95\n",
      "Epoch 010: Train Loss = 221.4969, Val MAE = 4.57, Val RMSE = 6.10\n",
      "Epoch 011: Train Loss = 154.0135, Val MAE = 3.76, Val RMSE = 5.35\n",
      "Epoch 012: Train Loss = 120.2458, Val MAE = 3.69, Val RMSE = 4.99\n",
      "Epoch 013: Train Loss = 117.0598, Val MAE = 3.80, Val RMSE = 5.08\n",
      "Epoch 014: Train Loss = 85.3736, Val MAE = 3.67, Val RMSE = 4.87\n",
      "Epoch 015: Train Loss = 68.6793, Val MAE = 4.09, Val RMSE = 4.88\n",
      "Epoch 016: Train Loss = 72.3591, Val MAE = 3.56, Val RMSE = 4.58\n",
      "Epoch 017: Train Loss = 69.7211, Val MAE = 3.76, Val RMSE = 4.61\n",
      "Epoch 018: Train Loss = 62.0223, Val MAE = 3.31, Val RMSE = 4.49\n",
      "Epoch 019: Train Loss = 62.8924, Val MAE = 3.39, Val RMSE = 4.40\n",
      "Epoch 020: Train Loss = 65.3117, Val MAE = 3.47, Val RMSE = 4.44\n",
      "Epoch 021: Train Loss = 49.0087, Val MAE = 3.42, Val RMSE = 4.52\n",
      "Epoch 022: Train Loss = 52.4887, Val MAE = 3.43, Val RMSE = 4.55\n",
      "Epoch 023: Train Loss = 53.4433, Val MAE = 3.71, Val RMSE = 4.58\n",
      "Epoch 024: Train Loss = 54.5546, Val MAE = 3.79, Val RMSE = 4.71\n",
      "Epoch 025: Train Loss = 44.3181, Val MAE = 3.73, Val RMSE = 4.68\n",
      "Epoch 026: Train Loss = 45.0201, Val MAE = 3.49, Val RMSE = 4.49\n",
      "Epoch 027: Train Loss = 49.9678, Val MAE = 3.46, Val RMSE = 4.51\n",
      "Epoch 028: Train Loss = 46.0101, Val MAE = 3.42, Val RMSE = 4.43\n",
      "Epoch 029: Train Loss = 48.7793, Val MAE = 3.71, Val RMSE = 4.71\n",
      "Epoch 030: Train Loss = 51.0240, Val MAE = 3.46, Val RMSE = 4.63\n",
      "Epoch 031: Train Loss = 45.6669, Val MAE = 3.60, Val RMSE = 4.52\n",
      "Epoch 032: Train Loss = 45.9659, Val MAE = 3.42, Val RMSE = 4.35\n",
      "Epoch 033: Train Loss = 47.9080, Val MAE = 4.11, Val RMSE = 4.79\n",
      "Epoch 034: Train Loss = 44.7406, Val MAE = 3.35, Val RMSE = 4.41\n",
      "Epoch 035: Train Loss = 45.9031, Val MAE = 3.38, Val RMSE = 4.34\n",
      "Epoch 036: Train Loss = 41.4145, Val MAE = 3.47, Val RMSE = 4.40\n",
      "Epoch 037: Train Loss = 41.3280, Val MAE = 3.71, Val RMSE = 4.46\n",
      "Epoch 038: Train Loss = 43.1470, Val MAE = 3.46, Val RMSE = 4.34\n",
      "Epoch 039: Train Loss = 42.8931, Val MAE = 3.29, Val RMSE = 4.24\n",
      "Epoch 040: Train Loss = 44.1633, Val MAE = 3.36, Val RMSE = 4.28\n",
      "Epoch 041: Train Loss = 39.7026, Val MAE = 3.97, Val RMSE = 4.66\n",
      "Epoch 042: Train Loss = 35.4722, Val MAE = 3.66, Val RMSE = 4.44\n",
      "Epoch 043: Train Loss = 33.7283, Val MAE = 3.40, Val RMSE = 4.35\n",
      "Epoch 044: Train Loss = 48.6706, Val MAE = 3.38, Val RMSE = 4.29\n",
      "Epoch 045: Train Loss = 41.6360, Val MAE = 3.31, Val RMSE = 4.24\n",
      "Epoch 046: Train Loss = 39.3003, Val MAE = 3.66, Val RMSE = 4.51\n",
      "Epoch 047: Train Loss = 43.1017, Val MAE = 3.37, Val RMSE = 4.27\n",
      "Epoch 048: Train Loss = 42.8222, Val MAE = 3.72, Val RMSE = 4.48\n",
      "Epoch 049: Train Loss = 39.9824, Val MAE = 3.31, Val RMSE = 4.21\n",
      "Epoch 050: Train Loss = 44.7030, Val MAE = 3.99, Val RMSE = 4.68\n",
      "Fold 3 Best MAE: 3.29, Best RMSE: 4.24\n",
      "\n",
      "Fold 4 --------------------------\n",
      "Epoch 001: Train Loss = 1448772.1739, Val MAE = 27.47, Val RMSE = 29.01\n",
      "Epoch 002: Train Loss = 926.7284, Val MAE = 15.60, Val RMSE = 19.38\n",
      "Epoch 003: Train Loss = 781.4215, Val MAE = 13.21, Val RMSE = 17.51\n",
      "Epoch 004: Train Loss = 601.9164, Val MAE = 11.18, Val RMSE = 15.96\n",
      "Epoch 005: Train Loss = 627.4121, Val MAE = 10.19, Val RMSE = 14.82\n",
      "Epoch 006: Train Loss = 589.0449, Val MAE = 9.34, Val RMSE = 13.67\n",
      "Epoch 007: Train Loss = 517.9624, Val MAE = 8.37, Val RMSE = 12.43\n",
      "Epoch 008: Train Loss = 422.4858, Val MAE = 7.50, Val RMSE = 11.22\n",
      "Epoch 009: Train Loss = 337.1167, Val MAE = 6.05, Val RMSE = 9.57\n",
      "Epoch 010: Train Loss = 234.7623, Val MAE = 5.33, Val RMSE = 8.32\n",
      "Epoch 011: Train Loss = 205.2817, Val MAE = 4.48, Val RMSE = 7.10\n",
      "Epoch 012: Train Loss = 137.4198, Val MAE = 4.28, Val RMSE = 6.59\n",
      "Epoch 013: Train Loss = 87.1377, Val MAE = 4.11, Val RMSE = 6.06\n",
      "Epoch 014: Train Loss = 101.7572, Val MAE = 4.19, Val RMSE = 5.76\n",
      "Epoch 015: Train Loss = 72.5084, Val MAE = 3.95, Val RMSE = 5.47\n",
      "Epoch 016: Train Loss = 74.5316, Val MAE = 3.63, Val RMSE = 5.04\n",
      "Epoch 017: Train Loss = 77.2233, Val MAE = 3.55, Val RMSE = 5.13\n",
      "Epoch 018: Train Loss = 67.1647, Val MAE = 3.65, Val RMSE = 4.98\n",
      "Epoch 019: Train Loss = 58.0552, Val MAE = 3.40, Val RMSE = 4.90\n",
      "Epoch 020: Train Loss = 56.7315, Val MAE = 3.54, Val RMSE = 4.84\n",
      "Epoch 021: Train Loss = 54.8565, Val MAE = 3.46, Val RMSE = 4.76\n",
      "Epoch 022: Train Loss = 52.4705, Val MAE = 3.53, Val RMSE = 4.74\n",
      "Epoch 023: Train Loss = 69.6339, Val MAE = 3.47, Val RMSE = 4.79\n",
      "Epoch 024: Train Loss = 52.3297, Val MAE = 3.49, Val RMSE = 4.78\n",
      "Epoch 025: Train Loss = 45.2206, Val MAE = 3.54, Val RMSE = 4.73\n",
      "Epoch 026: Train Loss = 53.0948, Val MAE = 3.55, Val RMSE = 4.69\n",
      "Epoch 027: Train Loss = 52.8051, Val MAE = 3.56, Val RMSE = 4.71\n",
      "Epoch 028: Train Loss = 53.1789, Val MAE = 3.58, Val RMSE = 4.69\n",
      "Epoch 029: Train Loss = 62.4016, Val MAE = 3.57, Val RMSE = 4.79\n",
      "Epoch 030: Train Loss = 58.0709, Val MAE = 3.66, Val RMSE = 4.68\n",
      "Epoch 031: Train Loss = 57.0477, Val MAE = 3.58, Val RMSE = 4.59\n",
      "Epoch 032: Train Loss = 53.1034, Val MAE = 3.49, Val RMSE = 4.49\n",
      "Epoch 033: Train Loss = 60.9699, Val MAE = 3.51, Val RMSE = 4.55\n",
      "Epoch 034: Train Loss = 47.3089, Val MAE = 3.50, Val RMSE = 4.57\n",
      "Epoch 035: Train Loss = 45.2278, Val MAE = 3.55, Val RMSE = 4.73\n",
      "Epoch 036: Train Loss = 57.0916, Val MAE = 3.79, Val RMSE = 4.84\n",
      "Epoch 037: Train Loss = 66.5526, Val MAE = 3.53, Val RMSE = 4.77\n",
      "Epoch 038: Train Loss = 56.0718, Val MAE = 3.60, Val RMSE = 4.70\n",
      "Epoch 039: Train Loss = 48.5322, Val MAE = 3.65, Val RMSE = 4.75\n",
      "Epoch 040: Train Loss = 56.0915, Val MAE = 3.63, Val RMSE = 4.67\n",
      "Epoch 041: Train Loss = 53.6687, Val MAE = 3.52, Val RMSE = 4.61\n",
      "Epoch 042: Train Loss = 46.7351, Val MAE = 3.66, Val RMSE = 4.65\n",
      "Epoch 043: Train Loss = 48.3349, Val MAE = 3.47, Val RMSE = 4.60\n",
      "Epoch 044: Train Loss = 51.2820, Val MAE = 4.41, Val RMSE = 6.52\n",
      "Epoch 045: Train Loss = 68.9972, Val MAE = 3.51, Val RMSE = 4.65\n",
      "Epoch 046: Train Loss = 48.7653, Val MAE = 3.76, Val RMSE = 4.88\n",
      "Epoch 047: Train Loss = 46.5981, Val MAE = 3.64, Val RMSE = 4.63\n",
      "Epoch 048: Train Loss = 42.1504, Val MAE = 3.56, Val RMSE = 4.60\n",
      "Epoch 049: Train Loss = 52.8156, Val MAE = 3.59, Val RMSE = 4.54\n",
      "Epoch 050: Train Loss = 50.7850, Val MAE = 3.56, Val RMSE = 4.55\n",
      "Fold 4 Best MAE: 3.40, Best RMSE: 4.90\n",
      "\n",
      "Fold 5 --------------------------\n",
      "Epoch 001: Train Loss = 2254.0798, Val MAE = 11.34, Val RMSE = 18.89\n",
      "Epoch 002: Train Loss = 1254.7290, Val MAE = 9.40, Val RMSE = 15.31\n",
      "Epoch 003: Train Loss = 865.8325, Val MAE = 7.84, Val RMSE = 12.16\n",
      "Epoch 004: Train Loss = 724.8616, Val MAE = 6.60, Val RMSE = 10.07\n",
      "Epoch 005: Train Loss = 522.2438, Val MAE = 6.05, Val RMSE = 9.62\n",
      "Epoch 006: Train Loss = 465.7189, Val MAE = 6.06, Val RMSE = 9.43\n",
      "Epoch 007: Train Loss = 328.3536, Val MAE = 5.88, Val RMSE = 8.08\n",
      "Epoch 008: Train Loss = 221.9636, Val MAE = 5.32, Val RMSE = 7.30\n",
      "Epoch 009: Train Loss = 173.4683, Val MAE = 4.78, Val RMSE = 6.82\n",
      "Epoch 010: Train Loss = 164.2378, Val MAE = 6.17, Val RMSE = 8.42\n",
      "Epoch 011: Train Loss = 121.5721, Val MAE = 5.03, Val RMSE = 6.76\n",
      "Epoch 012: Train Loss = 106.8491, Val MAE = 6.14, Val RMSE = 7.30\n",
      "Epoch 013: Train Loss = 84.0343, Val MAE = 4.89, Val RMSE = 5.82\n",
      "Epoch 014: Train Loss = 85.5879, Val MAE = 5.17, Val RMSE = 7.12\n",
      "Epoch 015: Train Loss = 76.1852, Val MAE = 4.87, Val RMSE = 6.23\n",
      "Epoch 016: Train Loss = 54.6606, Val MAE = 4.56, Val RMSE = 6.17\n",
      "Epoch 017: Train Loss = 68.8281, Val MAE = 4.17, Val RMSE = 5.40\n",
      "Epoch 018: Train Loss = 59.1297, Val MAE = 4.79, Val RMSE = 6.08\n",
      "Epoch 019: Train Loss = 52.9456, Val MAE = 5.29, Val RMSE = 6.51\n",
      "Epoch 020: Train Loss = 45.0905, Val MAE = 4.37, Val RMSE = 5.87\n",
      "Epoch 021: Train Loss = 42.4053, Val MAE = 3.92, Val RMSE = 5.20\n",
      "Epoch 022: Train Loss = 43.3512, Val MAE = 4.11, Val RMSE = 5.55\n",
      "Epoch 023: Train Loss = 40.3357, Val MAE = 3.93, Val RMSE = 5.31\n",
      "Epoch 024: Train Loss = 39.0574, Val MAE = 4.82, Val RMSE = 6.24\n",
      "Epoch 025: Train Loss = 44.5683, Val MAE = 4.07, Val RMSE = 5.50\n",
      "Epoch 026: Train Loss = 35.8248, Val MAE = 4.07, Val RMSE = 5.41\n",
      "Epoch 027: Train Loss = 41.4821, Val MAE = 4.16, Val RMSE = 5.46\n",
      "Epoch 028: Train Loss = 36.7779, Val MAE = 4.43, Val RMSE = 6.01\n",
      "Epoch 029: Train Loss = 36.4398, Val MAE = 4.92, Val RMSE = 6.08\n",
      "Epoch 030: Train Loss = 35.1717, Val MAE = 8.40, Val RMSE = 9.52\n",
      "Epoch 031: Train Loss = 37.3731, Val MAE = 4.05, Val RMSE = 5.28\n",
      "Epoch 032: Train Loss = 38.8278, Val MAE = 4.21, Val RMSE = 5.42\n",
      "Epoch 033: Train Loss = 27.1783, Val MAE = 5.83, Val RMSE = 6.93\n",
      "Epoch 034: Train Loss = 28.9543, Val MAE = 3.95, Val RMSE = 5.36\n",
      "Epoch 035: Train Loss = 28.0855, Val MAE = 4.09, Val RMSE = 5.32\n",
      "Epoch 036: Train Loss = 28.3983, Val MAE = 5.08, Val RMSE = 6.22\n",
      "Epoch 037: Train Loss = 30.2299, Val MAE = 3.96, Val RMSE = 5.09\n",
      "Epoch 038: Train Loss = 32.9420, Val MAE = 4.05, Val RMSE = 5.37\n",
      "Epoch 039: Train Loss = 31.1869, Val MAE = 5.01, Val RMSE = 6.11\n",
      "Epoch 040: Train Loss = 29.4172, Val MAE = 4.25, Val RMSE = 5.58\n",
      "Epoch 041: Train Loss = 33.9359, Val MAE = 4.18, Val RMSE = 5.68\n",
      "Epoch 042: Train Loss = 34.8973, Val MAE = 4.24, Val RMSE = 5.49\n",
      "Epoch 043: Train Loss = 26.6033, Val MAE = 4.49, Val RMSE = 5.83\n",
      "Epoch 044: Train Loss = 26.2242, Val MAE = 4.22, Val RMSE = 5.81\n",
      "Epoch 045: Train Loss = 31.8702, Val MAE = 4.40, Val RMSE = 5.84\n",
      "Epoch 046: Train Loss = 23.8020, Val MAE = 4.47, Val RMSE = 5.96\n",
      "Epoch 047: Train Loss = 26.7627, Val MAE = 4.37, Val RMSE = 5.88\n",
      "Epoch 048: Train Loss = 29.6550, Val MAE = 4.98, Val RMSE = 6.22\n",
      "Epoch 049: Train Loss = 30.2636, Val MAE = 4.27, Val RMSE = 5.65\n",
      "Epoch 050: Train Loss = 30.9162, Val MAE = 5.42, Val RMSE = 6.80\n",
      "Fold 5 Best MAE: 3.92, Best RMSE: 5.20\n",
      "\n",
      "Fold 6 --------------------------\n",
      "Epoch 001: Train Loss = 2345.2941, Val MAE = 11.95, Val RMSE = 22.38\n",
      "Epoch 002: Train Loss = 1468.3421, Val MAE = 12.50, Val RMSE = 21.10\n",
      "Epoch 003: Train Loss = 1125.8307, Val MAE = 10.31, Val RMSE = 18.00\n",
      "Epoch 004: Train Loss = 712.3708, Val MAE = 8.99, Val RMSE = 16.28\n",
      "Epoch 005: Train Loss = 482.9005, Val MAE = 9.16, Val RMSE = 14.72\n",
      "Epoch 006: Train Loss = 338.8380, Val MAE = 7.97, Val RMSE = 13.02\n",
      "Epoch 007: Train Loss = 253.9846, Val MAE = 7.22, Val RMSE = 11.84\n",
      "Epoch 008: Train Loss = 204.0610, Val MAE = 6.23, Val RMSE = 10.95\n",
      "Epoch 009: Train Loss = 169.3411, Val MAE = 5.91, Val RMSE = 10.37\n",
      "Epoch 010: Train Loss = 136.6174, Val MAE = 5.76, Val RMSE = 10.00\n",
      "Epoch 011: Train Loss = 114.0939, Val MAE = 5.63, Val RMSE = 9.79\n",
      "Epoch 012: Train Loss = 99.6213, Val MAE = 5.61, Val RMSE = 9.61\n",
      "Epoch 013: Train Loss = 75.7915, Val MAE = 6.76, Val RMSE = 9.89\n",
      "Epoch 014: Train Loss = 69.6303, Val MAE = 5.32, Val RMSE = 9.29\n",
      "Epoch 015: Train Loss = 69.3723, Val MAE = 5.41, Val RMSE = 9.12\n",
      "Epoch 016: Train Loss = 59.1830, Val MAE = 5.10, Val RMSE = 8.48\n",
      "Epoch 017: Train Loss = 59.2058, Val MAE = 5.75, Val RMSE = 9.07\n",
      "Epoch 018: Train Loss = 48.3388, Val MAE = 5.94, Val RMSE = 9.20\n",
      "Epoch 019: Train Loss = 53.5515, Val MAE = 5.29, Val RMSE = 8.87\n",
      "Epoch 020: Train Loss = 44.8378, Val MAE = 5.66, Val RMSE = 8.94\n",
      "Epoch 021: Train Loss = 45.3253, Val MAE = 4.68, Val RMSE = 8.28\n",
      "Epoch 022: Train Loss = 34.6473, Val MAE = 4.96, Val RMSE = 8.19\n",
      "Epoch 023: Train Loss = 40.4739, Val MAE = 4.54, Val RMSE = 7.80\n",
      "Epoch 024: Train Loss = 35.8266, Val MAE = 4.55, Val RMSE = 7.82\n",
      "Epoch 025: Train Loss = 39.0207, Val MAE = 4.69, Val RMSE = 7.88\n",
      "Epoch 026: Train Loss = 34.5238, Val MAE = 4.35, Val RMSE = 6.99\n",
      "Epoch 027: Train Loss = 28.8752, Val MAE = 4.32, Val RMSE = 6.93\n",
      "Epoch 028: Train Loss = 35.3776, Val MAE = 4.45, Val RMSE = 7.03\n",
      "Epoch 029: Train Loss = 27.0144, Val MAE = 4.51, Val RMSE = 7.09\n",
      "Epoch 030: Train Loss = 34.6692, Val MAE = 4.98, Val RMSE = 7.36\n",
      "Epoch 031: Train Loss = 30.3632, Val MAE = 5.15, Val RMSE = 7.58\n",
      "Epoch 032: Train Loss = 28.4461, Val MAE = 4.29, Val RMSE = 7.13\n",
      "Epoch 033: Train Loss = 31.4674, Val MAE = 4.35, Val RMSE = 7.37\n",
      "Epoch 034: Train Loss = 30.7973, Val MAE = 4.25, Val RMSE = 6.97\n",
      "Epoch 035: Train Loss = 29.9213, Val MAE = 4.66, Val RMSE = 7.10\n",
      "Epoch 036: Train Loss = 28.1030, Val MAE = 4.41, Val RMSE = 7.22\n",
      "Epoch 037: Train Loss = 34.8253, Val MAE = 4.36, Val RMSE = 7.16\n",
      "Epoch 038: Train Loss = 27.3534, Val MAE = 4.55, Val RMSE = 7.45\n",
      "Epoch 039: Train Loss = 30.5036, Val MAE = 4.43, Val RMSE = 7.18\n",
      "Epoch 040: Train Loss = 32.7623, Val MAE = 5.13, Val RMSE = 7.54\n",
      "Epoch 041: Train Loss = 29.7163, Val MAE = 4.72, Val RMSE = 7.29\n",
      "Epoch 042: Train Loss = 30.5738, Val MAE = 4.32, Val RMSE = 7.26\n",
      "Epoch 043: Train Loss = 31.3237, Val MAE = 4.59, Val RMSE = 7.44\n",
      "Epoch 044: Train Loss = 42.5677, Val MAE = 4.22, Val RMSE = 6.31\n",
      "Epoch 045: Train Loss = 32.9322, Val MAE = 4.54, Val RMSE = 6.51\n",
      "Epoch 046: Train Loss = 27.9656, Val MAE = 4.29, Val RMSE = 6.54\n",
      "Epoch 047: Train Loss = 27.5747, Val MAE = 4.14, Val RMSE = 6.43\n",
      "Epoch 048: Train Loss = 30.5007, Val MAE = 4.01, Val RMSE = 6.34\n",
      "Epoch 049: Train Loss = 30.0786, Val MAE = 4.20, Val RMSE = 6.46\n",
      "Epoch 050: Train Loss = 25.5582, Val MAE = 3.99, Val RMSE = 6.28\n",
      "Fold 6 Best MAE: 3.99, Best RMSE: 6.28\n",
      "\n",
      "Fold 7 --------------------------\n",
      "Epoch 001: Train Loss = 7857.3436, Val MAE = 11.53, Val RMSE = 20.82\n",
      "Epoch 002: Train Loss = 1444.2720, Val MAE = 11.20, Val RMSE = 20.35\n",
      "Epoch 003: Train Loss = 1465.2472, Val MAE = 10.70, Val RMSE = 19.29\n",
      "Epoch 004: Train Loss = 1361.0102, Val MAE = 11.59, Val RMSE = 18.53\n",
      "Epoch 005: Train Loss = 893.9619, Val MAE = 12.55, Val RMSE = 17.91\n",
      "Epoch 006: Train Loss = 638.1746, Val MAE = 9.67, Val RMSE = 15.07\n",
      "Epoch 007: Train Loss = 463.9897, Val MAE = 9.16, Val RMSE = 13.82\n",
      "Epoch 008: Train Loss = 318.8732, Val MAE = 7.51, Val RMSE = 11.92\n",
      "Epoch 009: Train Loss = 254.2062, Val MAE = 7.29, Val RMSE = 10.80\n",
      "Epoch 010: Train Loss = 264.7734, Val MAE = 7.07, Val RMSE = 10.16\n",
      "Epoch 011: Train Loss = 332.2228, Val MAE = 8.21, Val RMSE = 10.68\n",
      "Epoch 012: Train Loss = 253.1121, Val MAE = 6.22, Val RMSE = 9.19\n",
      "Epoch 013: Train Loss = 193.6935, Val MAE = 5.97, Val RMSE = 8.75\n",
      "Epoch 014: Train Loss = 302.4378, Val MAE = 7.63, Val RMSE = 9.69\n",
      "Epoch 015: Train Loss = 205.9694, Val MAE = 8.59, Val RMSE = 10.24\n",
      "Epoch 016: Train Loss = 151.0365, Val MAE = 10.63, Val RMSE = 12.15\n",
      "Epoch 017: Train Loss = 136.0216, Val MAE = 4.89, Val RMSE = 7.09\n",
      "Epoch 018: Train Loss = 106.4329, Val MAE = 4.82, Val RMSE = 6.81\n",
      "Epoch 019: Train Loss = 128.7880, Val MAE = 8.54, Val RMSE = 10.10\n",
      "Epoch 020: Train Loss = 125.1196, Val MAE = 4.49, Val RMSE = 6.44\n",
      "Epoch 021: Train Loss = 97.0688, Val MAE = 4.64, Val RMSE = 6.31\n",
      "Epoch 022: Train Loss = 167.0380, Val MAE = 5.24, Val RMSE = 7.07\n",
      "Epoch 023: Train Loss = 96.8799, Val MAE = 5.32, Val RMSE = 7.05\n",
      "Epoch 024: Train Loss = 134.7040, Val MAE = 4.89, Val RMSE = 6.53\n",
      "Epoch 025: Train Loss = 75.9538, Val MAE = 5.26, Val RMSE = 6.50\n",
      "Epoch 026: Train Loss = 71.9185, Val MAE = 4.99, Val RMSE = 6.28\n",
      "Epoch 027: Train Loss = 62.8937, Val MAE = 7.23, Val RMSE = 8.38\n",
      "Epoch 028: Train Loss = 72.3466, Val MAE = 5.16, Val RMSE = 6.20\n",
      "Epoch 029: Train Loss = 84.3215, Val MAE = 9.39, Val RMSE = 10.18\n",
      "Epoch 030: Train Loss = 119.1773, Val MAE = 22.45, Val RMSE = 23.96\n",
      "Epoch 031: Train Loss = 115.6100, Val MAE = 12.20, Val RMSE = 12.88\n",
      "Epoch 032: Train Loss = 81.0036, Val MAE = 5.49, Val RMSE = 6.72\n",
      "Epoch 033: Train Loss = 56.5995, Val MAE = 4.33, Val RMSE = 5.20\n",
      "Epoch 034: Train Loss = 50.3737, Val MAE = 8.08, Val RMSE = 8.84\n",
      "Epoch 035: Train Loss = 60.6408, Val MAE = 6.29, Val RMSE = 7.13\n",
      "Epoch 036: Train Loss = 68.0871, Val MAE = 9.45, Val RMSE = 10.44\n",
      "Epoch 037: Train Loss = 75.7163, Val MAE = 5.73, Val RMSE = 6.81\n",
      "Epoch 038: Train Loss = 65.4437, Val MAE = 4.36, Val RMSE = 5.31\n",
      "Epoch 039: Train Loss = 51.9907, Val MAE = 4.23, Val RMSE = 5.13\n",
      "Epoch 040: Train Loss = 77.1268, Val MAE = 8.01, Val RMSE = 8.76\n",
      "Epoch 041: Train Loss = 48.6579, Val MAE = 4.06, Val RMSE = 4.86\n",
      "Epoch 042: Train Loss = 44.7345, Val MAE = 4.08, Val RMSE = 4.86\n",
      "Epoch 043: Train Loss = 81.8088, Val MAE = 9.30, Val RMSE = 10.31\n",
      "Epoch 044: Train Loss = 64.1861, Val MAE = 7.69, Val RMSE = 8.65\n",
      "Epoch 045: Train Loss = 44.3131, Val MAE = 6.79, Val RMSE = 7.68\n",
      "Epoch 046: Train Loss = 54.0374, Val MAE = 4.09, Val RMSE = 4.97\n",
      "Epoch 047: Train Loss = 48.8487, Val MAE = 4.24, Val RMSE = 5.11\n",
      "Epoch 048: Train Loss = 34.8088, Val MAE = 4.71, Val RMSE = 5.79\n",
      "Epoch 049: Train Loss = 97.4995, Val MAE = 6.13, Val RMSE = 7.05\n",
      "Epoch 050: Train Loss = 43.7403, Val MAE = 4.30, Val RMSE = 5.16\n",
      "Fold 7 Best MAE: 4.06, Best RMSE: 4.86\n",
      "\n",
      "Fold 8 --------------------------\n",
      "Epoch 001: Train Loss = 1925.1134, Val MAE = 10.31, Val RMSE = 19.75\n",
      "Epoch 002: Train Loss = 837.3108, Val MAE = 10.41, Val RMSE = 18.53\n",
      "Epoch 003: Train Loss = 639.0236, Val MAE = 10.52, Val RMSE = 21.03\n",
      "Epoch 004: Train Loss = 334.6933, Val MAE = 10.16, Val RMSE = 25.48\n",
      "Epoch 005: Train Loss = 291.8845, Val MAE = 10.55, Val RMSE = 25.36\n",
      "Epoch 006: Train Loss = 313.9405, Val MAE = 9.23, Val RMSE = 21.32\n",
      "Epoch 007: Train Loss = 259.6726, Val MAE = 8.92, Val RMSE = 19.15\n",
      "Epoch 008: Train Loss = 160.5570, Val MAE = 8.69, Val RMSE = 19.92\n",
      "Epoch 009: Train Loss = 208.4065, Val MAE = 8.70, Val RMSE = 18.99\n",
      "Epoch 010: Train Loss = 188.9724, Val MAE = 8.49, Val RMSE = 18.06\n",
      "Epoch 011: Train Loss = 150.4935, Val MAE = 7.75, Val RMSE = 16.05\n",
      "Epoch 012: Train Loss = 143.3849, Val MAE = 8.45, Val RMSE = 17.25\n",
      "Epoch 013: Train Loss = 154.1639, Val MAE = 7.41, Val RMSE = 14.88\n",
      "Epoch 014: Train Loss = 114.6820, Val MAE = 7.42, Val RMSE = 14.95\n",
      "Epoch 015: Train Loss = 120.7663, Val MAE = 7.51, Val RMSE = 14.62\n",
      "Epoch 016: Train Loss = 104.2089, Val MAE = 6.85, Val RMSE = 12.43\n",
      "Epoch 017: Train Loss = 105.4532, Val MAE = 7.31, Val RMSE = 13.92\n",
      "Epoch 018: Train Loss = 100.5836, Val MAE = 6.37, Val RMSE = 11.44\n",
      "Epoch 019: Train Loss = 109.0783, Val MAE = 6.65, Val RMSE = 11.61\n",
      "Epoch 020: Train Loss = 90.7384, Val MAE = 5.71, Val RMSE = 10.31\n",
      "Epoch 021: Train Loss = 70.9060, Val MAE = 6.00, Val RMSE = 10.58\n",
      "Epoch 022: Train Loss = 58.7809, Val MAE = 5.98, Val RMSE = 10.38\n",
      "Epoch 023: Train Loss = 73.3422, Val MAE = 5.15, Val RMSE = 7.93\n",
      "Epoch 024: Train Loss = 60.6991, Val MAE = 6.07, Val RMSE = 9.79\n",
      "Epoch 025: Train Loss = 48.3917, Val MAE = 5.02, Val RMSE = 7.71\n",
      "Epoch 026: Train Loss = 51.1588, Val MAE = 5.56, Val RMSE = 9.10\n",
      "Epoch 027: Train Loss = 55.0326, Val MAE = 4.48, Val RMSE = 6.57\n",
      "Epoch 028: Train Loss = 47.9174, Val MAE = 4.70, Val RMSE = 6.95\n",
      "Epoch 029: Train Loss = 48.8629, Val MAE = 4.34, Val RMSE = 6.02\n",
      "Epoch 030: Train Loss = 47.2241, Val MAE = 6.18, Val RMSE = 7.74\n",
      "Epoch 031: Train Loss = 53.4558, Val MAE = 5.08, Val RMSE = 7.61\n",
      "Epoch 032: Train Loss = 39.5059, Val MAE = 4.30, Val RMSE = 5.93\n",
      "Epoch 033: Train Loss = 47.4440, Val MAE = 4.08, Val RMSE = 6.56\n",
      "Epoch 034: Train Loss = 41.4787, Val MAE = 4.08, Val RMSE = 5.70\n",
      "Epoch 035: Train Loss = 40.2148, Val MAE = 4.34, Val RMSE = 5.97\n",
      "Epoch 036: Train Loss = 35.7498, Val MAE = 4.47, Val RMSE = 5.91\n",
      "Epoch 037: Train Loss = 33.7977, Val MAE = 3.84, Val RMSE = 5.65\n",
      "Epoch 038: Train Loss = 42.7094, Val MAE = 5.11, Val RMSE = 6.90\n",
      "Epoch 039: Train Loss = 36.4763, Val MAE = 3.89, Val RMSE = 5.80\n",
      "Epoch 040: Train Loss = 40.2372, Val MAE = 5.75, Val RMSE = 7.85\n",
      "Epoch 041: Train Loss = 47.4613, Val MAE = 4.72, Val RMSE = 6.73\n",
      "Epoch 042: Train Loss = 31.8783, Val MAE = 4.62, Val RMSE = 7.41\n",
      "Epoch 043: Train Loss = 36.2410, Val MAE = 6.01, Val RMSE = 8.11\n",
      "Epoch 044: Train Loss = 37.2388, Val MAE = 4.47, Val RMSE = 8.00\n",
      "Epoch 045: Train Loss = 35.8235, Val MAE = 4.78, Val RMSE = 7.24\n",
      "Epoch 046: Train Loss = 35.8741, Val MAE = 4.76, Val RMSE = 7.35\n",
      "Epoch 047: Train Loss = 33.8674, Val MAE = 3.84, Val RMSE = 6.07\n",
      "Epoch 048: Train Loss = 35.9648, Val MAE = 3.92, Val RMSE = 6.60\n",
      "Epoch 049: Train Loss = 39.1978, Val MAE = 3.84, Val RMSE = 6.50\n",
      "Epoch 050: Train Loss = 40.5268, Val MAE = 3.76, Val RMSE = 6.51\n",
      "Fold 8 Best MAE: 3.76, Best RMSE: 6.51\n",
      "\n",
      "Fold 9 --------------------------\n",
      "Epoch 001: Train Loss = 12069.3663, Val MAE = 13.95, Val RMSE = 21.92\n",
      "Epoch 002: Train Loss = 1313.8498, Val MAE = 10.48, Val RMSE = 18.68\n",
      "Epoch 003: Train Loss = 859.4455, Val MAE = 11.20, Val RMSE = 17.54\n",
      "Epoch 004: Train Loss = 597.4537, Val MAE = 8.74, Val RMSE = 14.98\n",
      "Epoch 005: Train Loss = 558.3236, Val MAE = 7.48, Val RMSE = 12.93\n",
      "Epoch 006: Train Loss = 429.4512, Val MAE = 6.94, Val RMSE = 11.89\n",
      "Epoch 007: Train Loss = 334.6398, Val MAE = 7.85, Val RMSE = 11.80\n",
      "Epoch 008: Train Loss = 394.8528, Val MAE = 7.41, Val RMSE = 11.03\n",
      "Epoch 009: Train Loss = 220.6561, Val MAE = 10.39, Val RMSE = 12.66\n",
      "Epoch 010: Train Loss = 210.9907, Val MAE = 8.61, Val RMSE = 10.90\n",
      "Epoch 011: Train Loss = 190.3902, Val MAE = 6.53, Val RMSE = 9.48\n",
      "Epoch 012: Train Loss = 163.6299, Val MAE = 10.81, Val RMSE = 12.59\n",
      "Epoch 013: Train Loss = 154.8773, Val MAE = 6.15, Val RMSE = 9.16\n",
      "Epoch 014: Train Loss = 132.8694, Val MAE = 5.68, Val RMSE = 8.63\n",
      "Epoch 015: Train Loss = 123.2434, Val MAE = 6.14, Val RMSE = 8.90\n",
      "Epoch 016: Train Loss = 143.3672, Val MAE = 5.73, Val RMSE = 8.53\n",
      "Epoch 017: Train Loss = 94.4816, Val MAE = 7.28, Val RMSE = 9.55\n",
      "Epoch 018: Train Loss = 129.0046, Val MAE = 11.47, Val RMSE = 12.95\n",
      "Epoch 019: Train Loss = 85.7369, Val MAE = 6.17, Val RMSE = 8.78\n",
      "Epoch 020: Train Loss = 211.5002, Val MAE = 5.32, Val RMSE = 8.26\n",
      "Epoch 021: Train Loss = 95.8302, Val MAE = 5.95, Val RMSE = 8.41\n",
      "Epoch 022: Train Loss = 102.2264, Val MAE = 5.35, Val RMSE = 7.89\n",
      "Epoch 023: Train Loss = 111.6580, Val MAE = 5.07, Val RMSE = 7.65\n",
      "Epoch 024: Train Loss = 90.7746, Val MAE = 9.87, Val RMSE = 11.10\n",
      "Epoch 025: Train Loss = 61.9901, Val MAE = 4.74, Val RMSE = 7.23\n",
      "Epoch 026: Train Loss = 95.1876, Val MAE = 6.21, Val RMSE = 8.02\n",
      "Epoch 027: Train Loss = 62.5165, Val MAE = 5.39, Val RMSE = 7.37\n",
      "Epoch 028: Train Loss = 69.0648, Val MAE = 4.92, Val RMSE = 7.04\n",
      "Epoch 029: Train Loss = 60.1725, Val MAE = 5.25, Val RMSE = 7.19\n",
      "Epoch 030: Train Loss = 71.2392, Val MAE = 17.19, Val RMSE = 18.22\n",
      "Epoch 031: Train Loss = 124.7798, Val MAE = 7.41, Val RMSE = 8.61\n",
      "Epoch 032: Train Loss = 84.9840, Val MAE = 8.66, Val RMSE = 9.60\n",
      "Epoch 033: Train Loss = 60.3402, Val MAE = 8.27, Val RMSE = 9.41\n",
      "Epoch 034: Train Loss = 50.0486, Val MAE = 5.06, Val RMSE = 6.81\n",
      "Epoch 035: Train Loss = 41.1359, Val MAE = 5.10, Val RMSE = 6.82\n",
      "Epoch 036: Train Loss = 36.3869, Val MAE = 4.34, Val RMSE = 6.03\n",
      "Epoch 037: Train Loss = 33.8630, Val MAE = 4.36, Val RMSE = 5.93\n",
      "Epoch 038: Train Loss = 39.9452, Val MAE = 4.34, Val RMSE = 5.97\n",
      "Epoch 039: Train Loss = 39.6538, Val MAE = 3.86, Val RMSE = 5.52\n",
      "Epoch 040: Train Loss = 30.8058, Val MAE = 3.82, Val RMSE = 5.43\n",
      "Epoch 041: Train Loss = 32.7771, Val MAE = 4.17, Val RMSE = 5.82\n",
      "Epoch 042: Train Loss = 34.4600, Val MAE = 4.14, Val RMSE = 5.81\n",
      "Epoch 043: Train Loss = 26.9431, Val MAE = 5.20, Val RMSE = 6.57\n",
      "Epoch 044: Train Loss = 35.6568, Val MAE = 3.98, Val RMSE = 5.53\n",
      "Epoch 045: Train Loss = 40.4134, Val MAE = 3.90, Val RMSE = 5.45\n",
      "Epoch 046: Train Loss = 41.5373, Val MAE = 4.07, Val RMSE = 5.71\n",
      "Epoch 047: Train Loss = 33.8992, Val MAE = 4.47, Val RMSE = 6.08\n",
      "Epoch 048: Train Loss = 34.8655, Val MAE = 4.08, Val RMSE = 5.65\n",
      "Epoch 049: Train Loss = 30.6466, Val MAE = 4.22, Val RMSE = 5.64\n",
      "Epoch 050: Train Loss = 34.2937, Val MAE = 4.51, Val RMSE = 5.98\n",
      "Fold 9 Best MAE: 3.82, Best RMSE: 5.43\n",
      "\n",
      "Fold 10 --------------------------\n",
      "Epoch 001: Train Loss = 1881.7929, Val MAE = 13.76, Val RMSE = 22.11\n",
      "Epoch 002: Train Loss = 862.0897, Val MAE = 9.59, Val RMSE = 15.20\n",
      "Epoch 003: Train Loss = 724.5948, Val MAE = 8.90, Val RMSE = 13.48\n",
      "Epoch 004: Train Loss = 506.2176, Val MAE = 7.12, Val RMSE = 11.09\n",
      "Epoch 005: Train Loss = 25599.5858, Val MAE = 97.40, Val RMSE = 103.03\n",
      "Epoch 006: Train Loss = 2959.4328, Val MAE = 10.88, Val RMSE = 14.64\n",
      "Epoch 007: Train Loss = 373.1151, Val MAE = 11.41, Val RMSE = 13.73\n",
      "Epoch 008: Train Loss = 306.7440, Val MAE = 9.74, Val RMSE = 12.31\n",
      "Epoch 009: Train Loss = 317.4064, Val MAE = 9.11, Val RMSE = 12.07\n",
      "Epoch 010: Train Loss = 257.6628, Val MAE = 9.87, Val RMSE = 12.41\n",
      "Epoch 011: Train Loss = 255.2422, Val MAE = 8.78, Val RMSE = 11.68\n",
      "Epoch 012: Train Loss = 267.9248, Val MAE = 8.84, Val RMSE = 11.56\n",
      "Epoch 013: Train Loss = 253.6507, Val MAE = 8.42, Val RMSE = 11.24\n",
      "Epoch 014: Train Loss = 280.0299, Val MAE = 8.79, Val RMSE = 11.31\n",
      "Epoch 015: Train Loss = 204.3351, Val MAE = 8.88, Val RMSE = 11.38\n",
      "Epoch 016: Train Loss = 217.9695, Val MAE = 8.27, Val RMSE = 11.03\n",
      "Epoch 017: Train Loss = 231.0752, Val MAE = 7.64, Val RMSE = 10.18\n",
      "Epoch 018: Train Loss = 205.8856, Val MAE = 7.62, Val RMSE = 10.28\n",
      "Epoch 019: Train Loss = 152.6105, Val MAE = 7.11, Val RMSE = 8.97\n",
      "Epoch 020: Train Loss = 164.2030, Val MAE = 8.28, Val RMSE = 9.75\n",
      "Epoch 021: Train Loss = 130.6161, Val MAE = 6.15, Val RMSE = 8.23\n",
      "Epoch 022: Train Loss = 134.4563, Val MAE = 6.06, Val RMSE = 7.95\n",
      "Epoch 023: Train Loss = 122.9133, Val MAE = 6.41, Val RMSE = 7.98\n",
      "Epoch 024: Train Loss = 102.2779, Val MAE = 5.28, Val RMSE = 7.15\n",
      "Epoch 025: Train Loss = 119.3180, Val MAE = 4.74, Val RMSE = 7.58\n",
      "Epoch 026: Train Loss = 123.8017, Val MAE = 4.44, Val RMSE = 6.25\n",
      "Epoch 027: Train Loss = 115.1004, Val MAE = 5.22, Val RMSE = 6.55\n",
      "Epoch 028: Train Loss = 109.5674, Val MAE = 5.53, Val RMSE = 6.75\n",
      "Epoch 029: Train Loss = 106.2654, Val MAE = 4.45, Val RMSE = 5.68\n",
      "Epoch 030: Train Loss = 94.5121, Val MAE = 5.05, Val RMSE = 6.23\n",
      "Epoch 031: Train Loss = 104.6820, Val MAE = 4.28, Val RMSE = 5.29\n",
      "Epoch 032: Train Loss = 69.7877, Val MAE = 4.27, Val RMSE = 5.22\n",
      "Epoch 033: Train Loss = 83.6370, Val MAE = 4.42, Val RMSE = 5.50\n",
      "Epoch 034: Train Loss = 87.5839, Val MAE = 4.23, Val RMSE = 5.22\n",
      "Epoch 035: Train Loss = 75.5820, Val MAE = 3.97, Val RMSE = 4.80\n",
      "Epoch 036: Train Loss = 73.0087, Val MAE = 4.38, Val RMSE = 5.40\n",
      "Epoch 037: Train Loss = 66.7688, Val MAE = 4.14, Val RMSE = 5.07\n",
      "Epoch 038: Train Loss = 63.9212, Val MAE = 4.00, Val RMSE = 4.83\n",
      "Epoch 039: Train Loss = 58.4520, Val MAE = 3.92, Val RMSE = 4.65\n",
      "Epoch 040: Train Loss = 60.5810, Val MAE = 4.09, Val RMSE = 5.06\n",
      "Epoch 041: Train Loss = 53.1290, Val MAE = 3.72, Val RMSE = 4.38\n",
      "Epoch 042: Train Loss = 46.1885, Val MAE = 3.75, Val RMSE = 4.45\n",
      "Epoch 043: Train Loss = 52.8399, Val MAE = 3.81, Val RMSE = 4.59\n",
      "Epoch 044: Train Loss = 49.5592, Val MAE = 4.38, Val RMSE = 5.40\n",
      "Epoch 045: Train Loss = 49.9362, Val MAE = 4.12, Val RMSE = 5.03\n",
      "Epoch 046: Train Loss = 53.7085, Val MAE = 4.16, Val RMSE = 5.12\n",
      "Epoch 047: Train Loss = 49.7338, Val MAE = 3.96, Val RMSE = 4.69\n",
      "Epoch 048: Train Loss = 55.7065, Val MAE = 3.79, Val RMSE = 4.42\n",
      "Epoch 049: Train Loss = 48.9489, Val MAE = 3.63, Val RMSE = 4.19\n",
      "Epoch 050: Train Loss = 45.3288, Val MAE = 3.90, Val RMSE = 4.51\n",
      "Fold 10 Best MAE: 3.63, Best RMSE: 4.19\n",
      "\n",
      "Cross-validation summary:\n",
      "MAE per fold: [3.7520171923515124, 5.014573268401317, 3.2915172576904297, 3.3970787341778097, 3.923462647658128, 3.9910461719219503, 4.061422739273462, 3.755131403605143, 3.8150770725348058, 3.634457074678861]\n",
      "Mean MAE: 3.86\n"
     ]
    }
   ],
   "source": [
    "from graph_attention_model import GATRegressor\n",
    "from create_dataset import BrainGraphDataset\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Load graphs\n",
    "hcp_graphs = torch.load(\"hcp_brain_graph_dataset.pt\", weights_only=False)\n",
    "ppmi_graphs = torch.load(\"ppmi_brain_graph_dataset_new.pt\", weights_only=False)\n",
    "\n",
    "graph_list = hcp_graphs + ppmi_graphs\n",
    "dataset = BrainGraphDataset(graph_list)\n",
    "\n",
    "# Create labels: 0 = HCP, 1 = PPMI\n",
    "graph_labels = np.array([0] * len(hcp_graphs) + [1] * len(ppmi_graphs))\n",
    "\n",
    "# Set up stratified cross-validation\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "folds = []\n",
    "\n",
    "for train_idx, val_idx in skf.split(dataset, graph_labels):\n",
    "    train_subset = [dataset[i] for i in train_idx]\n",
    "    val_subset = [dataset[i] for i in val_idx]\n",
    "\n",
    "    # Create sampler to \"oversample\" PPMI in training\n",
    "    train_labels = graph_labels[train_idx]\n",
    "    sample_weights = np.where(train_labels == 1, 5.0, 1.0)\n",
    "    sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(train_idx), replacement=True)\n",
    "\n",
    "    train_loader = DataLoader(train_subset, batch_size=8, sampler=sampler)\n",
    "    val_loader = DataLoader(val_subset, batch_size=8)\n",
    "\n",
    "    folds.append((train_loader, val_loader))\n",
    "\n",
    "## Train and validate model for all folds\n",
    "all_fold_maes = []\n",
    "all_fold_rmses = []\n",
    "all_results = {}\n",
    "\n",
    "for fold, (train_loader, val_loader) in enumerate(folds):\n",
    "    print(f\"\\nFold {fold+1} --------------------------\")\n",
    "\n",
    "    # Can change hyperparameters here\n",
    "    model = GATRegressor(in_channels=4, hidden_channels=64, heads=4)\n",
    "    best_state, best_mae, best_rmse, results = train_gat(model, train_loader, val_loader, lr=1e-4, epochs=50)\n",
    "\n",
    "    torch.save(best_state, f\"gat_fold{fold+1}_best_model.pt\")\n",
    "\n",
    "    # Evaluate success of model\n",
    "    print(f\"Fold {fold+1} Best MAE: {best_mae:.2f}, Best RMSE: {best_rmse:.2f}\")\n",
    "    all_fold_maes.append(best_mae)\n",
    "    all_fold_rmses.append(best_rmse)\n",
    "    all_results[fold] = results\n",
    "\n",
    "print(\"\\nCross-validation summary:\")\n",
    "print(f\"MAE per fold: {all_fold_maes}\")\n",
    "print(f\"Mean MAE: {sum(all_fold_maes)/len(all_fold_maes):.2f}\")\n",
    "\n",
    "# Save results for plotting\n",
    "with open(\"training_results.pkl\", \"wb\") as f:\n",
    "    pickle.dump(all_results, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-validation summary:\n",
      "MAE per fold: [3.7520171923515124, 5.014573268401317, 3.2915172576904297, 3.3970787341778097, 3.923462647658128, 3.9910461719219503, 4.061422739273462, 3.755131403605143, 3.8150770725348058, 3.634457074678861]\n",
      "RMSE per fold: [np.float32(5.2442), np.float32(5.888731), np.float32(4.2416825), np.float32(4.898218), np.float32(5.198413), np.float32(6.2825904), np.float32(4.8564916), np.float32(6.511677), np.float32(5.433017), np.float32(4.1896567)]\n",
      "Mean MAE: 3.8636\n",
      "Mean RMSE: 5.2745\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCross-validation summary:\")\n",
    "print(f\"MAE per fold: {all_fold_maes}\")\n",
    "print(f\"RMSE per fold: {all_fold_rmses}\")\n",
    "print(f\"Mean MAE: {sum(all_fold_maes)/len(all_fold_maes):.4f}\")\n",
    "print(f\"Mean RMSE: {sum(all_fold_rmses)/len(all_fold_rmses):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqYAAAIhCAYAAACcznj/AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAl05JREFUeJzs3XdYU+cXwPFvwt4IqKDiHoCouPfee7W1aqvWbq1V2/5q7VJbW+220w5nW+2wamut4t4L98ItIioOQEE2JPf3xwUU2QjcQM7nefKQXG5yDwmQk/e+7zk6RVEUhBBCCCGE0Jhe6wCEEEIIIYQASUyFEEIIIYSJkMRUCCGEEEKYBElMhRBCCCGESZDEVAghhBBCmARJTIUQQgghhEmQxFQIIYQQQpgESUyFEEIIIYRJkMRUCCGEEEKYBElMhSilFi1ahE6ny3QpX748nTp1YvXq1cV23Pj4eKZPn87WrVvztf+lS5cyxajX6ylXrhxdu3Zl/fr1WfafPn16xn4XL17M8v24uDicnZ3R6XSMGTMm0/fCwsIYN24cdevWxc7ODjc3Nxo0aMCzzz5LWFhYlmPkdLl06VJBnpJik/7cLVq0KNf9tm7dmhF7Tvt26dIFnU5H9erVs/1+SkoKnp6e6HQ6/vrrr2z3KS3PW246deqUY/wnTpwo8GN16tQpz/3y+zoKIcBS6wCEEA9n4cKF+Pj4oCgK169f55tvvqF///6sWrWK/v37F/nx4uPjmTFjBkC+3pTTTZgwgREjRmAwGDh9+jQzZsygT58+bN68mQ4dOmTZ39HRkYULF/L+++9n2r5s2TJSUlKwsrLKtP3KlSs0adIEV1dXXn31VerVq0d0dDTBwcH8+eefXLx4EW9v70z3CQwMxMXFJcuxvby88v1zmRInJyfmz5+fJWEPCQlh69atODs753jf1atXc+PGDQDmz5/PI488kuO+pf15q1mzJkuWLMmyvVatWhpEI4S4nySmQpRy/v7+NGvWLON2r169KFeuHL/99luxJKaFVbVqVVq1agVA27ZtqVOnDh07dmT+/PnZJqbDhg1j8eLFzJgxA73+3smd+fPnM3jwYFatWpVp/59++omIiAiCgoKoUaNGxvZBgwbx5ptvYjQasxyjadOmeHh4FNWPqLlhw4Yxb948zp07R506dTK2L1iwgMqVK9OgQQOCg4Ozve/8+fOxtramY8eOrF+/nitXrlClSpVs9zXl501RFBITE7Gzs8txHzs7u4zfRSGEaZFT+UKUMba2tlhbW2cZUUxOTmbmzJn4+PhgY2ND+fLleeqpp7h161am/TZv3kynTp1wd3fHzs6OqlWrMnToUOLj47l06RLly5cHYMaMGRmnQB8cocuP9GQ6fZTuQWPHjiUsLIwNGzZkbDt79iw7d+5k7NixWfaPjIxEr9dToUKFbB/v/uT2Yf3xxx/06NEDLy8v7Ozs8PX15Y033iAuLi7TfmPGjMHR0ZHz58/Tp08fHB0d8fb25tVXXyUpKSnTvteuXeOxxx7DyckJFxcXhg0bxvXr1wsUV/fu3fH29mbBggUZ24xGI4sXL2b06NE5PgfXrl0jMDCQ/v3787///Q+j0Vgsp52rV69Ov379WLlyJQ0bNsTW1paaNWvy1VdfZdk3JiaG1157jRo1amBtbU3lypWZNGlSludYp9Px0ksv8f333+Pr64uNjQ2LFy9+qDgTExOZOnVqpmOPHz+eO3fu5HnfongdhTBnkpgKUcoZDAZSU1NJSUnhypUrGW/eI0aMyNjHaDQycOBAZs+ezYgRI/jvv/+YPXs2GzZsoFOnTiQkJADqXLi+fftibW3NggULCAwMZPbs2Tg4OJCcnIyXlxeBgYEAPP300+zZs4c9e/bwzjvvFDjukJAQAOrWrZvt9+vUqUP79u0zJVkLFiygevXqdO3aNcv+rVu3xmg0MmTIENatW0dMTEyeMaQ/d/dfDAZDnvc7d+4cffr0Yf78+QQGBjJp0iT+/PPPbEeoU1JSGDBgAF27duWff/5h7NixfPHFF3z00UcZ+yQkJNCtWzfWr1/PrFmzWLZsGZ6engwbNizPWO6n1+sZM2YMP//8c8bPkT76+dRTT+V4v0WLFmEwGBg7dizdunWjWrVqLFiwAEVRst2/sM8bwJEjR5g0aRKTJ09m5cqVtGnThokTJ/Lpp59m7BMfH0/Hjh1ZvHgxL7/8MmvXrmXKlCksWrSIAQMGZInr77//Zu7cubz77rusW7eO9u3b5xnHg/Gnj6grisKgQYP49NNPefLJJ/nvv/945ZVXWLx4MV26dMnygeJ+RfU6CmHWFCFEqbRw4UIFyHKxsbFRvvvuu0z7/vbbbwqgLF++PNP2/fv3K0DG/n/99ZcCKEeOHMnxuLdu3VIAZdq0afmKMyQkRAGUjz76SElJSVESExOVI0eOKK1bt1a8vLyUkJCQTPtPmzZNAZRbt24pCxcuVGxsbJTIyEglNTVV8fLyUqZPn64oiqI4ODgoo0ePzrif0WhUnn/+eUWv1yuAotPpFF9fX2Xy5Mk5HiO7S61atfL1c91/3JSUFGXbtm0KoBw9ejTje6NHj1YA5c8//8x0nz59+ij16tXLuD137lwFUP75559M+z377LMKoCxcuDDXGLZs2aIAyrJly5SLFy8qOp1OWb16taIoivLoo48qnTp1UhRFUfr27atUq1YtS/y1a9dWKleurKSmpmZ6fjZt2pRp34d93qpVq6bodLosv1/du3dXnJ2dlbi4OEVRFGXWrFmKXq9X9u/fn2m/9N/PNWvWZGwDFBcXFyUqKirP4yuKonTs2DHb+EeOHKkoiqIEBgYqgPLxxx9nut8ff/yhAMqPP/6Y6bE6duyYcfthX0chhKLIiKkQpdzPP//M/v372b9/P2vXrmX06NGMHz+eb775JmOf1atX4+rqSv/+/TONEgUEBODp6Zmxwj4gIABra2uee+45Fi9enO2q+MKaMmUKVlZW2NraEhAQwIkTJ/j3339zXCUO8Oijj2Jtbc2SJUtYs2YN169fz3HagE6n4/vvv+fixYt89913PPXUU6SkpPDFF19Qv359tm3bluU+GzduzHju0i9///13nj/LxYsXGTFiBJ6enlhYWGBlZUXHjh0BOHXqVJa4HhxJbdiwIaGhoRm3t2zZgpOTEwMGDMi03/2j3vlVo0YNOnXqxIIFC4iMjMwYpc3Jtm3bOH/+PKNHj8bCwgKAp556Cp1Ol2m0+n6Ffd4A6tevT6NGjTJtGzFiBDExMRw6dAhQf1/9/f0JCAjI9Pvas2dPdDpdlooQXbp0oVy5cvk6PqiLnB6MP32R3ebNmwGy/J49+uijODg4sGnTphwftyhfRyHMlSx+EqKU8/X1zbL4KTQ0lNdff50nnngCV1dXbty4wZ07d7C2ts72MSIiIgD1DXvjxo18/PHHjB8/nri4OGrWrMnLL7/MxIkTHyrOiRMn8sQTT5CUlMTevXt5++23GThwIEePHsXd3T3b+zg4ODBs2DAWLFhAtWrVMk4z56ZatWq8+OKLGbf//PNPhg8fzv/+9z+CgoIy7duoUaMCL+KJjY2lffv22NraMnPmTOrWrYu9vT1hYWEMGTIkY1pEOnt7e2xtbTNts7GxITExMeN2ZGQkFStWzHIsT0/PAsWW7umnn+app57i888/x87OLtcV9vPnzwdg8ODBGXMoXVxcaNeuHcuXL+ebb77B1dU1030K87yly+5nSt8WGRkJqPOOz58/n2WedLr039d0Ba0GYGtrm+lv5n6RkZFYWlpmzKVOp9Pp8PT0zIgxp/sW5esohDmSxFSIMqhhw4asW7eOs2fP0qJFCzw8PHB3d8+YH/ogJyenjOvt27enffv2GAwGDhw4wNdff82kSZOoWLEijz/+eKFjqlKlSkYy0LZtWzw9PXniiSeYNm1aptHdB40dO5Z58+Zx7NixbEv85OWxxx5j1qxZBa5RmZPNmzdz7do1tm7dmjFKCuRrYUxO3N3dsyTNQKEXzQwZMoTx48cze/Zsnn322RxXqEdHR7N8+XIAmjdvnu0+S5cuZdy4cYWKIzvZ/Uzp29I/oHh4eGBnZ5fjiO2DSbFOpyuy+Nzd3UlNTeXWrVuZklMlrRxbTs9T+n2L8nUUwhzJqXwhyqAjR44AZLyx9uvXj8jISAwGA82aNctyqVevXpbHsLCwoGXLlnz77bcAGadZbWxsALKMDBbUyJEj6dSpEz/99FOm09oPat26NWPHjmXw4MEMHjw4x/3Cw8Oz3R4bG0tYWBiVKlV6qHjTpSdB6c9Duh9++KHQj9m5c2fu3r2bpQTW0qVLC/V4dnZ2vPvuu/Tv3z/T6PGDli5dSkJCAu+//z5btmzJcvHw8MgxOSyskydPcvTo0SxxODk50aRJE0D9fb1w4QLu7u7Z/r7mNv3jYaUvrPv1118zbV++fDlxcXHZLrxLV9SvoxDmSEZMhSjlTpw4QWpqKqCeSlyxYgUbNmxg8ODBGfU8H3/8cZYsWUKfPn2YOHEiLVq0wMrKiitXrrBlyxYGDhzI4MGD+f7779m8eTN9+/alatWqJCYmZiQm3bp1A9TR1WrVqvHPP//QtWtX3Nzc8PDwKFSy8NFHH9GyZUvef/995s2bl+N+6aebc/PBBx+wa9cuhg0bRkBAAHZ2doSEhPDNN98QGRnJJ598kuU+Bw8ezLZQvJ+fX47F6Nu0aUO5cuV44YUXmDZtGlZWVixZsiRLslUQo0aN4osvvmDUqFF88MEH1KlThzVr1rBu3bpCP+Yrr7zCK6+8kus+8+fPp1y5crz22mtZphukx/X5559z9OjRTPNCC/O8patUqRIDBgxg+vTpeHl58euvv7JhwwY++ugj7O3tAZg0aRLLly+nQ4cOTJ48mYYNG2I0Grl8+TLr16/n1VdfpWXLlvl5Ggqse/fu9OzZkylTphATE0Pbtm05duwY06ZNo3Hjxjz55JM53rc4XkchzI7Wq6+EEIWT3ap8FxcXJSAgQPn888+VxMTETPunpKQon376qdKoUSPF1tZWcXR0VHx8fJTnn39eOXfunKIoirJnzx5l8ODBSrVq1RQbGxvF3d1d6dixo7Jq1apMj7Vx40alcePGio2NjQJkWh3/oPRV+Z988km233/00UcVS0tL5fz584qiZF6Vn5sHV+Xv3btXGT9+vNKoUSPFzc1NsbCwUMqXL6/06tUr0yru+4+R02XDhg25Hnv37t1K69atFXt7e6V8+fLKM888oxw6dCjLyuvRo0crDg4OWe6ffvz7XblyRRk6dKji6OioODk5KUOHDlV2795d4FX5ubl/Vf7Ro0cVQJk0aVKO+58+fVoBlAkTJmSKu7DPW7Vq1ZS+ffsqf/31l1K/fn3F2tpaqV69uvL5559n2Tc2NlZ5++23lXr16inW1taKi4uL0qBBA2Xy5MnK9evXM/YDlPHjx+d63Pt17NhRqV+/fq77JCQkKFOmTFGqVaumWFlZKV5eXsqLL76o3L59O8tj3b8qX1Ee7nUUQiiKTlFyKFQnhBBCFKHq1avj7+/P6tWrtQ5FCGGiZI6pEEIIIYQwCZKYCiGEEEIIkyCn8oUQQgghhEmQEVMhhBBCCGESJDEVQgghhBAmQRJTIYQQQghhEkp1gX2j0ci1a9dwcnIq0pZ0QgghhBCiaCiKwt27d6lUqRJ6fe5joqU6Mb127Rre3t5ahyGEEEIIIfIQFhZGlSpVct2nVCemTk5OgPqD5tUGTzyclJQU1q9fT48ePbCystI6HFEC5DU3P/Kamyd53c1PSb/mMTExeHt7Z+RtuSnViWn66XtnZ2dJTItZSkoK9vb2ODs7yz8uMyGvufmR19w8yetufrR6zfMz7VIWPwkhhBBCCJMgiakQQgghhDAJkpgKIYQQQgiTUKrnmOaHoiikpqZiMBi0DqVUS0lJwdLSksTERHkuTYCFhQWWlpZSJk0I8VAMRoV9IVEcjNDhHhJF69oVsNDL/xWhnTKdmCYnJxMeHk58fLzWoZR6iqLg6elJWFiYJEMmwt7eHi8vL6ytrbUORQhRCgWeCGfGv8GERycCFvx87gBeLrZM6+9HL38vrcMTZqrMJqZGo5GQkBAsLCyoVKkS1tbWklA9BKPRSGxsLI6OjnkWxxXFS1EUkpOTuXXrFiEhIdSpU0deEyFEgQSeCOfFXw+hPLD9enQiL/56iLlPNJHkVGiizCamycnJGI1GvL29sbe31zqcUs9oNJKcnIytra0kQSbAzs4OKysrQkNDM14XIYTID4NRYca/wVmSUgAF0AEz/g2mu5+nnNYXJa7MZxiSRImySn63hRCFERQSlXb6PnsKEB6dSFBIVMkFJUQaeWcTQgghzMjNuzknpYXZT4iiJImpEEIIYUYqOOVv6k9+9xOiKElimg8Go8KeC5H8c+Qqey5EYjBmNzNHiIKZPn06AQEBue4zZswYBg0aVCLxCCHMQ4sabng62+S6j5eLLS1quJVQRELcI4lpHgJPhNPuo80M/2kvE38/wvCf9tLuo80EnggvtmOOGTMGnU6XcXF3d6dXr14cO3asyI6Rn6QofT+dToeFhQVubm5UqVKFkSNHEhYWlmm/Tp06odPpmD17dpbH6NOnDzqdjunTp2dsu3jxIsOHD6dSpUrY2tpSpUoVBg4cyNmzZzP2uf85uP/y+++/F/rnLkqLFi3KNr558+ZpHZoQQuTIQq+jTW2PXPd5un0NWfgkNCGJaS7Sy2k8OEk8vZxGcSanvXr1Ijw8nPDwcDZt2oSlpSX9+vUrtuPlpn79+ly9epWTJ0/y22+/cfz4cR577LEs+3l7e7Nw4cJM265du8bmzZvx8rpXdiQ5OZnu3bsTExPDihUrOHPmDH/88Qf+/v5ER0dnuv/ChQsznof0S0mPICYnJ+f4PWdn5yzxjRw5sgSjE0KIgrkTn8zG4BsAuNhZZfqetYWaFizceYmI2KQSj00Is0pMFUUhPjk1X5e7iSlMW3Uyx3IaANNXBXM3MSXPx1KUgp/6t7GxwdPTE09PTwICApgyZQphYWHcunUrY5+rV68ybNgwypUrh7u7OwMHDuTSpUsZ39+6dSstWrTAwcEBV1dX2rZtS2hoKIsWLWLGjBkcPXo0Y5Rv0aJFOcZiaWmJp6cnXl5etG/fnmeffZa9e/cSExOTab9+/foRGRnJrl27MrYtWrSIHj16UKFChYxtwcHBXLx4ke+++45WrVpRrVo12rZtywcffEDz5s0zPaarq2vG85B+ya00kk6nY+7cufTu3Rs7Oztq1KjBsmXLMu2T1/OWfvp81qxZVKpUibp16+Z6vAfjs7OzA+Dy5csMHDgQR0dHnJ2deeyxx7hx40aOj2UwGHjllVdwdXXF3d2d119/vVC/O0IIkZtvt5wnJjEVH08n9r/VjV/HNmNUHQO/jm3GnqldqOHhwNU7CTz/y0ESU6TTnyhZZbaOaXYSUgz4vbuuSB5LAa7HJNJg+vo89w1+ryf21oV/qmNjY1myZAm1a9fG3d0dgPj4eDp37kz79u3Zvn07lpaWzJw5M+OUv16vZ9CgQTz77LP89ttvJCcnExQUhE6nY9iwYZw4cYLAwEA2btwIgIuLS75iuX79OitWrMDCwgILC4tM37O2tmbkyJEsXLiQtm3bAmpi+vHHH2c6jV++fHn0ej1//fUXkyZNyvI4D+udd95h9uzZfPnll/zyyy8MHz4cf39/fH1983ze0rsobdq0CWdnZzZs2FCo5FBRFAYNGoSDgwPbtm0jNTWVcePGMWzYMLZu3ZrtfT777DMWLFjA/Pnz8fPz47PPPmPlypV06dLlYZ4OIYTIEBYVz+LdoQC80dsHa0s9LWu4EXlKoWUNN6ysrJg/uhmDvt3FwdDbTF1xnM8fayQNakSJMavEtDRZvXo1jo6OAMTFxeHl5cXq1aszalf+/vvv6PV65s2bl/EPY+HChbi6urJ161aaNWtGdHQ0/fr1o1atWgD4+vpmPL6jo2PGSGhejh8/jrOzM0ajkYSEBABefvllHBwcsuz79NNP065dO7788ksOHjxIdHQ0ffv2zZSYVq5cma+++orXX3+dGTNm0KxZMzp37szIkSOpWbNmpscbPnx4lsT12LFjWfa736OPPsozzzwDwPvvv8+GDRv4+uuv+e677/J83nr06AGAg4MD8+bNy7PdZ3R0dMbrBOrzev36dTZu3MixY8cICQnB29sbgF9++YX69euzf//+LCPDAHPmzGHq1KkMHToUgO+//55164rmg5QQQgB8tv4MyQYjbWu707Fu+Wz3qVnekblPNGXUgiBWHr5K7QqOjO9cu4QjFebKrBJTOysLgt/rma99g0KiGLNwf577LXqqeZ4rF+2sCj4i2LlzZ+bOnQtAVFQU3333Hb179yYoKIhq1apx8OBBzp8/j5OTU6b7JSYmcuHCBXr06MGYMWPo2bMn3bt3p1u3bjz22GOZ5nrmV7169fj777+JjIxk8+bN/PXXX3zwwQfZ7tuwYUPq1KnDX3/9xZYtW3jyySexsrLKst/48eMZNWoUW7ZsYd++fSxbtowPP/yQVatW0b1794z9vvjiC7p165bpvumJXk5at26d5faRI0cA8nze0jVo0CBfPeidnJw4dOhQxu30Dw6nTp3C29s7U6x+fn64urpy6tSpLIlpdHQ04eHhmWK3tLSkWbNmcjpfCFEkTlyN5u8j1wCY2ts311HQtrU9mDGgPm//fYJP1p2hVnkHaVEqSoRZJaY6nS7fp9Tb1ymPl4st16MTs51nqgM8XWxpX6d8saxcdHBwoHbte59QmzZtiouLCz/99BMzZ87EaDTStGlTlixZkuW+5curn4IXLlzIyy+/TGBgIH/88Qdvv/02GzZsoFWrVgWKxdramtq1a1OhQgVatmzJ+fPnefHFF/nll1+y3X/s2LF8++23BAcHExQUlOPjOjk5MWDAAAYMGMDMmTPp2bMnM2fOzJSYenp6ZnoeCiv9H3B+njcg29Hg7Oj1+mzjUxQl23/6OW0XQojipCgKs9aeAmBQQCX8K+c9feuJVtU4fzOWRbsvMfmPo1QpZ5+v+wnxMMxq8VNBWOh1TOvvB6hJ6P3Sb0/r71di5TR0Oh16vT7jVHqTJk04d+4cFSpUoHbt2pku988Xbdy4MVOnTmX37t34+/uzdOlSQE02DYbCTWp/5513+O233zKNFN5vxIgRHD9+HH9/f/z8/PL98/n4+BAXF1eomO63d+/eLLd9fHyA/D9vD8vPz4/Lly9nKqsVHBxMdHR0pikV6VxcXPDy8soUe2pqKgcPHiyymIQQ5mv7uQh2nY/E2kLPqz3q5ft+b/f1pWPd8iSkGHh68X5uxEg3KFG8JDHNRS9/L+Y+0QRPl8yrwD1dbJn7RJNiPa2RlJTE9evXuX79OqdOnWLChAnExsbSv39/AEaOHImHhwcDBw5kx44dhISEsG3bNiZOnMiVK1cICQlh6tSp7Nmzh9DQUNavX8/Zs2czkqLq1asTEhLCkSNHiIiIICkp/2VBatasycCBA3n33Xez/X65cuUyylxl58iRIwwcOJC//vqL4OBgzp8/z/z581mwYAEDBw7MtO+dO3cynof0S17J67Jly1iwYAFnz55l2rRpBAUF8dJLL+XreSsq3bp1o2HDhowcOZJDhw4RFBTEqFGj6NixI82aNcv2PhMnTmT27NmsXLmS06dPM27cOO7cuVNkMQmRG4NRYV9IFAcjdOwLiZJGImWIwagwa406WjqqdTW83ezzfV9LCz1fj2hMnQqO3IhJ4tmfD5CQLCv1RfExq1P5hdHL34vufp4EhURx824iFZzUbhjFPVIaGBiYMR/UyckJHx8fli1bRqdOnQCwt7dn+/btTJkyhSFDhnD37l0qV65M165dcXZ2JiEhgdOnT7N48WIiIyPx8vLipZde4vnnnwdg6NChrFixgs6dO3Pnzh0WLlzImDFj8h3fq6++Stu2bdm3bx8tW7bM8n1XV9cc71ulShWqV6/OjBkzuHTpEjqdLuP25MmTM+371FNPZbn/rFmzeOONN3J8/BkzZvD7778zbtw4PD09WbJkScbIbV7PW1HR6XT8/fffTJgwgQ4dOqDX6+nVqxdff/11jvd59dVXCQ8PZ8yYMej1esaOHcvgwYOz1HYVoqgFnghnxr/BaTWbLfj53AG8XGyZ1t9P5hWWASsPX+X09bs421ryUpeCT41ytrVi/ujmDPpuF8euRPPasqN8PbwxeinAL4qBTinFKytiYmJwcXEhOjo6S1KRmJhISEgINWrUyLXupcgfo9FITEwMzs7OGQt8TJFOp2PlypVm0cazuH/HU1JSWLNmDX369Ml2AZsoG9IbiTz4RpCechT32SFRvBJTDHT+dCvh0YlM7e3D8x1rZdknv3/rQSFRjJy3lxSDwstdavNKAaYECNNS0v/fc8vXHmS6GYYQQohiZTAqzPg3ONdGIjP+DZbT+qXYwl2XCI9OpLKrHaPbVH+ox2pRw40PBzcA4KvN5/nnyNUiiFCIzCQxFUIIMxUUEpWl5fL9FCA8OpGgkKiSC0oUmai4ZL7bch6AV3vUxbYQpQsf9Ggzb57vqNaR/t9fxzh0+fZDP6YQ95PEVJQp6R2XhBB5u3k3fyus87ufMC3fbD7P3aRUfL2cGRRQucged0pPH7r7VSQ51chzPx/k6p2EIntsISQxFUIIM1XBKX9zk/O7nzAdlyPj+WXvJQDe7ONTpAuV9Hodc4YF4OvlTERsEk8v2k9cUmqRPb4wb5KYCiGEmWpRww13h9w7nHm52ObZ3U6Ynk/WnyHFoNC+jgft62TfevRhONhYMm90MzwcbTh9/S4Tfz8ic5FFkZDEVAghzNS1OwkkpRpz3Wd859ol1khEFI1jV+7w79Fr6HTwRm+fYjtOZVc7fhrVFGtLPRtP3eDjwNPFdixhPiQxFUIIMxSblMoziw8Qm5SKdzk7KjrbZPq+tYWajK47eZ1SXFXQ7CiKwodpxfQHN65M/UrF20K0cdVyfPJIQwB+2H6RPw+E5XEPIXInBfaFEMLMGIwKE387zJkbdynvZMOfL7SmgpMte87fZP2OffRo3xJPVwf6fLWDHeci+OfINQY1LrrFM6L4bD1zi70Xo7C2LFjr0YcxMKAyF27F8dWmc7y18jjV3OxpWdO9RI4tyh4ZMRVCCDPzceBpNp2+iY2lnp9GNcPLxQ4LvY6WNdxo6qHQsoYbtSs4MrFrHQDeWx1MVFyyxlGLvBiMCrPWqqOlT7WpTmVXuxI79qSudejb0IsUg8ILvx4kNDL31tFC5EQS0/wwGiBkBxz/S/1qlD7BInfTp08nICAg133GjBkjpa1EiVt2IIwftl8E4JNHGxHg7Zrjvs+2r0m9ik5ExSXzwX+nSihCUVjLD17h7I1YXOysGNep4K1HH4Zer+PTRxrRsIoLt+NTeHrxAWISU0o0BlE2SGKal+BVMMcfFveD5U+rX+f4q9uLyZgxY9DpdBkXd3d3evXqxbFjx4rsGPlJnNL30+l09O7dO8v3Pv74Y3Q6HZ06dcryvStXrmBtbY2PT/YT7+//+e6//P777wX9UYrFokWLso1v3rx5WocmRKHtvxTFmyuPA/Byl9oMaFQp1/2tLfXMGtoAnQ6WH7rCrvMRJRGmKISEZAOfbTgDwIQutXGxL/k2wnbWFswb1QxPZ1vO34zlpaWHSTXkvrhOiAdJYpqb4FXw5yiIuZZ5e0y4ur0Yk9NevXoRHh5OeHg4mzZtwtLSkn79+hXb8XLj5eXF1q1buXo1c/u5hQsXUrVq1Wzvs2jRIh577DHi4+PZtWtXtvssXLgw42dMv5T0CGJycs6nJ52dnbPEN3LkyBKMToiiExYVz/O/HCTFoNCngSeTutXN1/2aVC3HqFbVAHhz5XESU+SMkSlasCuEGzFJVClnx5Otq2kWRwVnW+aNboadlQXbz95ipoy0iwIyr8RUUSA5Ln+XxBhY+zrk1kU6cIq6X16PVYgVrTY2Nnh6euLp6UlAQABTpkwhLCyMW7duZexz9epVhg0bRrly5XB3d2fgwIFcunQp4/tbt26lRYsWODg44OrqStu2bQkNDWXRokXMmDGDo0ePZowELlq0KMdYKlSoQPfu3fntt98ytu3evZuIiAj69u2b9dlRFBYuXMiTTz7JiBEjmD9/fraP6+rqmvEzpl9sbXMu5K3T6Zg7dy69e/fGzs6OGjVqsGzZskz75PWcpJ8+nzVrFpUqVaJu3ZzfnHU6XZb47OzUOVuXL19m4MCBODo64uzszGOPPcaNGzdyfCyDwcArr7yCq6sr7u7uvP7667LSWZSYu4kpPLP4AFFxyfhXduazRwMKVHD9tZ718HS2JTQyni83nSvGSEVhRMYmMXfrBQD+17MeNpYP33r0YfhXduGLYY0AWLT7Er/sDdU0HlG6mNeq/JR4+DD3U1f5p6gjqbO98971zWtg7VDoI8XGxrJkyRJq166Nu7u60jE+Pp7OnTvTvn17tm/fjqWlJTNnzsw45a/X6xk0aBDPPvssv/32G8nJyQQFBaHT6Rg2bBgnTpwgMDCQjRs3AuDikntJkaeeeorXX3+d9957D4AFCxbkOHq4ZcsW4uPj6datG1WqVKFly5Z8+eWXODk5Ffo5SPfOO+8we/ZsvvzyS3755ReGDx+Ov78/vr6+eT4n1tZqIfFNmzbh7OzMhg0bCpUcprc9dXBwYNu2baSmpjJu3DiGDRvG1q1bs73PZ599xoIFC5g/fz5+fn589tlnrFy5ki5dujzM0yFEngxGhYm/H+HMjbtUcLLhp1HNsLMuWOLiZGvF+4P8efbnA/y4/SIDGlXC18u5mCIWBfX15vPEJqXiX9mZ/g2L6j3u4fTy9+J/PevxybozTF91khruDrSr46F1WKIUMK8R01Jk9erVODo64ujoiJOTE6tWreKPP/5Ar1dfst9//x29Xs+8efNo0KABvr6+LFy4kMuXL7N161ZiYmKIjo6mX79+1KpVC19fX0aPHk3VqlWxs7PD0dERS0vLLCOBOenXrx93795l+/btxMXF8eeffzJ27Nhs950/fz6PP/44FhYW1K9fn9q1a/PHH39k2W/48OEZP2P65eLFi7nG8eijj/LMM89Qt25d3n//fZo1a8bXX3+dr+cknYODA/PmzaN+/fr4+/vneKzo6OhMsXl6egKwceNGjh07xtKlS2natCktW7bkl19+Ydu2bezfvz/bx5ozZw5Tp05l6NCh+Pr68v333+f5YUCIojB77Sk2P7ACvzC6+1Wkt78nBqPCG8uPSZcfE3EpIo5f00Yk3+ztW6StRx/WuE61GNK4MgajwrglB7lwK1brkEQpYF4jplb26uhlfoTuhiWP5L3fyL+gWpu8j1tAnTt3Zu7cuQBERUXx3Xff0bt3b4KCgqhWrRoHDx7k/PnzWUYhExMTuXDhAj169GDMmDH07NmT7t27061bNx577DG8vLwKHAuAlZUVjz32GIsWLeLSpUvUrVuXhg0bZtnvzp07rFixgp07d2Zse+KJJ1iwYAHPPPNMpn2/+OILunXrlmmbt3fuI9CtW7fOcvvIkSMAeT4n6Ro0aJAxepobJycnDh06lHE7/UPBqVOn8Pb2zhSrn58frq6unDp1iubNm2d6nOjoaMLDwzPFbmlpSbNmzeR0vihWf+4P46cdIQB8+mgjGuWyAj8/pg+oz87zERy9Es3Pey7xVNsaRRCleBifrD9DqlGhU73ytKltWiOSOp2OWUMbEBoVz8HQ2zy9aD9/j2+Lq33e/3+F+TKvxFSny/8p9VpdwLmSutAp23mmOvX7tbqAvujn8zg4OFC79r1yH02bNsXFxYWffvqJmTNnYjQaadq0KUuWLMly3/Ll1b7ICxcu5OWXXyYwMJA//viDt99+mw0bNtCqVatCxTRy5Ei6d+/OyZMncxwtXbp0KYmJibRs2TJjm6IoGI1GgoOD8fPzy9ju6emZ6WcsLJ1OHSHIz3MC6nObH3q9Ptv4FEXJOGZ+tguhhX0XI3nrb3UF/sSudeifxwr8/KjobMsbvX14a+UJPll3hh71PUu0VqbI7PDl2/x3LLzYW48+DBtLC354simDvt3Fpch4Xvz1ED8/3QIrCzlhK7Kn+W/G1atXeeKJJ3B3d8fe3p6AgAAOHjyodVhqstnro7QbDyYbabd7zS6WpDQ7Op0OvV5PQkICAE2aNOHcuXNUqFCB2rVrZ7rcf4q4cePGTJ06ld27d+Pv78/SpUsBsLa2xmAo2OpaX19f6tevz4kTJxgxYkS2+8yfP59XX32VI0eOZFyOHj1K586dWbBgQSF/+nv27t2b5XZ6Sar8PicPy8/Pj8uXLxMWdq/1XnBwMNHR0fj6+mbZ38XFBS8vr0yxp6ammsbvuSiTLkfG88Kv6gr8vg28MgrlF4XhzavSrFo54pMNvPP3CRn114iiKMxaq/amH9qkCj6epjvn18PRhvmjm+NgbcGei5G8+4/83oicaZqY3r59m7Zt22JlZcXatWsJDg7ms88+w9XVVcuw7vEbAI/9DM4PnP52rqRu9xtQbIdOSkri+vXrXL9+nVOnTjFhwgRiY2Pp378/oI5eenh4MHDgQHbs2EFISAjbtm1j4sSJXLlyhZCQEKZOncqePXsIDQ1l/fr1nD17NiNxql69OiEhIRw5coSIiAiSkpLyFdfGjRsJDw/P9jU6cuQIhw4d4plnnsHf3z/TZfjw4fz888+kpNwruHznzp2MnzH9EheXe7eQZcuWsWDBAs6ePcu0adMICgripZdeytdzUlS6detGw4YNGTlyJIcOHSIoKIhRo0bRsWNHmjVrlu19Jk6cyOzZs1m5ciWnT59m3Lhx3Llzp8hiEiLd3cQUnl68n9vxKTSo7MKnjzYq0nmHer2OWUMaYGWhY/Ppm6w5fr3IHlvk36ZTNwkKicLGUs8r3fNX+ktL9Tyd+HpEY/Q6+C0ojAW7LmkdkjBRmiamH330Ed7e3ixcuJAWLVpQvXp1unbtSq1atbQMKzO/ATDpBIxeDUPnq18nHS/WpBQgMDAQLy8vvLy8aNmyJfv372fZsmUZxezt7e3Zvn07VatWZciQIfj6+jJ27FgSEhJwdnbG3t6e06dPM3ToUOrWrctzzz3HSy+9xPPPPw/A0KFD6dWrF507d6Z8+fKZSkHlJr30VHbSV5xnV1R/0KBBREVF8e+//2Zse+qppzJ+xvRL+kKmnMyYMYPff/+dhg0bsnjxYpYsWZIxPSCv56So6HQ6/v77b8qVK0eHDh3o1q0bNWvWzHaBV7pXX32VUaNGMWbMGFq3bo2TkxODBw8uspiEAHUF/su/HebczdhCr8DPjzoVnTI6C01bdZLoeOnwU5JSDUZmB6qjpWPb1aBSKZlO0cWnIm/2UQdHPvgvmC2nb2ockTBFOkXD8XQ/Pz969uzJlStX2LZtG5UrV2bcuHE8++yz2e6flJSUaWQvJiYGb29vIiIisiQeiYmJhIWFUb169VxrY4r8URSFu3fv4uTkpNk8SgsLC5YvXy5tPNMkJiZy6dIlvL29i+V3PCUlhQ0bNtC9e3esrEq+i4wouFlrz7Bgdyg2lnp+e6Y5DSoXbApLQV7zpFQjA77dw8WIOIY1q8zMgfUfJnRRAH8cuMLb/wRTzt6KTZPb4WT7cH+fJfm3rigK76wK5o8DV3GwseDPZ1tQt+LDlxIUBVPS/99jYmLw8PAgOjo6z4EiTRPT9DfTV155hUcffZSgoCAmTZrEDz/8wKhRo7LsP336dGbMmJFl+9KlS7G3z7zyPb0Ukre3d75WYAvTV65cOX799ddsi/qbo+TkZMLCwrh+/TqpqalahyM0tueGjt8vqqOjY+oYaOxR/P/aL8TAVyfVNbQT6qdS23SnOZYZSQaYediCmBQdg6sb6ORV+uZqphph7ik952P0uNkovNLAgJN89i3T4uPjGTFihOknptbW1jRr1ozdu3dnbHv55ZfZv38/e/bsybK/jJhqR0ZMTY+MmIp0+0KieGqxutjp5c61mNClcNOhCvOav/1PMH8cuEJND3tWjWuNjZW2XYfKum+2XODLzRfwLmdH4MttsbZ8+Bl5Wvyt345P5tEfggiNiqdpVVcWP9UMmyL4WUT+mPKIqablory8vDKVDwJ15ffy5cuz3d/GxgYbG5ss262srLI8sQaDIWMle3r9SVF4RqMRuFcdQAuyijMzvV6PTqfL9ve/KBX344uHczkyngm/HyXFoNCvoReTe9R76A+PBXnN3+zrx+Yzt7gYEc+Puy6XioU4pVVEbBLzdl4C4PVePjjYZX0/fBgl+bdewcWK+WOaM/i7XRy8fId3V53is8caScm9ElZSr3lBjqFpxta2bVvOnDmTadvZs2epVq2aRhGJ7CiKQlyygbgUiEs2SIIohImIuW8FfsMq6gr8kn5jd7GzYsYAdX7p3K3nOXvjboke35x8tekccckGGlVxoW+DwjVLMSW1Kzgyd2RTLPQ6Vhy+ytxtF/K+kyjzNE1MJ0+ezN69e/nwww85f/48S5cu5ccff2T8+PFFdgxJoh5OdEIyp6/fJSQijsgkCImI4/T1u0QnJGsdmtmT323zlmowMmGpugK/orO6At9Wo9Povf096eZbgRSDwtQVxzFKu9Iid/FWLEv3XQbgDRNrPfow2tXxYHraB5uPA88QeELKj5k7TRPT5s2bs3LlSn777Tf8/f15//33mTNnDiNHjnzox04fNo6Pj3/oxzJX0QnJhEbGk2IwZtqeYjASGhkvyanG0n+35TS7efpwzWm2nb2FrZWeeaOaU9FZu7n0Op2O9wb642BtwcHQ2ywNuqxZLGXVJ+vU1qNdfCrQupa71uEUqSdbVWN0a/VM6eQ/jnDiarTGEQktad6StF+/fvTr16/IH9fCwgJXV1du3lTrpNnb28vclQJQFIUrt+JQjMYc97lyKxXr8g7yvJYwRVGIj4/n5s2buLq6YmEhi03MzW9Bl1mwKwSAzx4NoEGVoutsVliVXO34X896TP83mI/Wnqabb0U8XWThaVE4GHqbtSeuo9fBlF6m2Xr0Yb3Tz4+QyHi2n73FM4sPsOqltlTQ8MOW0I7miWlx8vT0BMhITkX+JaUYuBWb94hoyh1rWYWrEVdX14zfcWE+9lyI5J2/TwDwSve69G1oOnMNn2xdnb+PXONI2B2mrzrJ90821TqkUk9RFGatOQXAo029qedZNmt+Wlro+WZEY4Z8t5vzN2N59ucD/PF8a82mpwjtlOnEVKfT4eXlRYUKFTK1whR523TqBh9uOZXnfm/28aVr3YolEJG4n5WVlYyUmqHQyDheXHKQVKNC/0aVmNClttYhZWKR1q60/9c7CTx5nXUnr9Ozvnx4ehjrg29wIPQ2tlZ6JpfxigfOtlbMH92MQd/u4uiVaF5ddpSvH29cZubTivwp04lpOgsLC3kTL6BExYKrdw157ufm7Ch1YoUoAeoK/APciU+hURUXPnmkoUlOo/H1cua5DjX5busFpv1zkja13B+6M5G5SjEY+Wit2nr0mXY1zWJqRDV3B75/oilPzN/Hf8fCqV3escwn5CIzKfApMlEUhd+CLvPWiuO57qcDvFxsaVHDrWQCE8KMpRqMvLT0MOdvxuLpbKvpCvz8eLlrHaq723M9JpFP1p3J+w4iW3/sD+NiRBxuDtY837Gm1uGUmJY13flgUAMAvtx0jlVHr2kckShJkpiKDLfjknnh14NMXXGcxFQj9So6AmoS+iAFmNbfDws5xSJEsftgzSm2p6/AH93M5BeF2FpZ8OFgNbH4ZW8oB0NvaxxR6ROXlMqcjecAmNi1jtmNOj/W3JvnOqjJ+GvLjnL4svwOmQtJTAUAu85H0OvL7aw7eQMrCx1Te/uwdmIHvn+iSbanj1rXdKeXv+ksuhCirFq67zILd10C4IvHAvCvrP0K/PxoU9uDR5pWQVFg6opjJKfmXOFDZPXTjotExCZR3d2e4S2qah2OJqb08qGbb0WSU408+/NBrt1J0DokUQIkMTVzSakGZq05xRPz93EjJoma5R1YOa4tz3eshV6vo5e/FzundOHXsc0YVcfA9P6+AOwNieRUeIzG0QtRtu2+EMG7/6gr8F/tXpfepazbz1t9fHF3sObsjVh+3C5dffLr5t1Eftx+EVBbj1qbaQ95C72OOY8H4OPpRERsEk8vPkBcUqrWYYliZp6/7QKA8zdjGfLdbn7YfhFFgREtq7J6QrssIzIWeh0ta7jR1ENhZAtv+jb0QlFgVtqkfCFE0bsUEceLvx4i1agwoFElXjKxFfj5Uc7Bmnf7+wHw1ebzXLwVq3FEpcOXG88Rn2wgwNuV3v7mXdXA0caSeaOb4eFozanwGCb9cUQ6i5VxkpiaIUVRWLIvlH5f7+DktRjK2Vvx45NN+XBwA+yt8y7U8HrPelhZ6Nh+9hY7zt0qgYiFMC/RCSk8vXg/0QkpNPJ25WMTXYGfHwMaVaJD3fIkpxqZuuK4tNLNw/mbsfy+PwxQy/GV1te9KFUpZ8+Po5phbalnQ/ANPpYFdWWaJKZmJioumed+OchbK0+QmGKkfR0PAid1oEcBag1Wc3fgiVZq+7hZa07Lp1chipC6Av8QF27F4eViy09PNjXpFfh50el0fDDIHzsrC/aFRLHswBWtQzJpHweexmBU6OZbUaqe3KdJ1XJ88khDAL7fdoFlB8I0jkgUF0lMzcj2s7foOWc7G4JvYG2h5+2+vix+qkWhemy/3KUOTraWBIfHsPLw1WKIVgjzNPO/U+w4F4GdlQU/jTL9Ffj54e1mzytptSg/WHOKW3eTNI7INO2/FMX64BvodfBG73pah2NyBgZUzmgq8ebK4wSFRGkckSgOkpiagaRUA++vDmbUgiBu3U2idgVHVo5vwzPtaxa6o0Y5B2vGd1b/QXy2/gyJKXkX4xdC5O7XvaEs2n0JgC+GNSo1K/Dz46m21fGv7Ex0QgrvrQ7WOhyToygKH6a1Hh3WvCq1K5TN1qMPa3K3uvRp4EmKQeH5Xw5wOTJe65BEEZPEtIw7d+MuA7/ZxfydIQA82aoa/77UjvqVHv4Nb0yb6lRyseVadGJGORshROHsPh/BtFUnAXitR90yV47N0kLP7CEN0evg36PX2HL6ptYhmZTAE9c5fPkOdlYWTO5WR+twTJZer+OzRwNoUNmF2/HqXOyYRGk5XpZIYlpGKYrCL3su0e/rnZy+fhc3B2vmj27G+4P8sbMumvlqtlYWvNZTPd303ZbzRMUlF8njCmFuQiLieHHJIQxGhYEBlTLORpQ1/pVdeLpdDQDe/vuElP5Jk2IwZizoebZDzTIxfaM42Vmr01wqOttw7mYsE5YeJtUgdXLLCklMy6D0em/v/HOSpFQjHeqWJ3BSe7r6VizyYw0KqIyflzN3k1L5evO5In98Icq6+1fgB3i78tHQ0rsCPz8md69LlXJ2XL2TwOcbzmodjkn4PegyIRFxeDhaZ3Q7ErnzdLFl3qjm2Frp2Xb2Fh+kTYMQpZ8kpmXM1jM36TVnB5tP38TaUs+0/n4sGtOcCk7F8wlcr9fxZh+16P6ve0MJjYwrluMIURalr8C/eCuOSi62/DiqdK/Azw97a0tmDvIHYOGuEI6G3dE2II3F3t96tFtdHG3yLtknVA2quPDFYwEALNx1iSX7QrUNSBQJSUzLiMQUA9NXnWTMwv1ExCZRt6Ijq15qy1NtaxR6gVN+tavjQce65UkxKFJfTogCeH918L0V+KObFdsHSFPTqV4FBgZUwqjAGyuOk2LGp2F/3HaByLhkano48Hhzb63DKXV6N/DitR5qxYd3/znJrvMRGkckHpYkpmXAmevqAqf01bxj2lRn1Uvt8PF0LrEY3ujtg04H/x0L5/Dl2yV2XCFKq1/2hrJ4jzrC88WwgCJZkFiavNPPD1d7K06Fx7AgbXGmubkRk8hPO9Sf/fVePlhZyFtyYYzvXJvBjStjMCq8+OtB6TBWyslfQSmmKAqLdoXQ/5udnLlxFw9HaxaOac70AfVL/HSgr5czjzSpAqhF96W7ixA523kugulpK/D/17Mevcyw7aSHow1vpU0D+mLjWbMs+zNn41kSUgw0rVaOnvWLfg2AudDpdMwa0oAmVV2JSUzl6cUHuBMvi3FLK0lMS6lbd5MYs3A/0/8NJjnVSOd65Qmc1IHOPhU0i+mVHnWxtdITdCmKDcE3NItDCFN28VYs45YcxGBUGNy4MuM61dI6JM080rQKbWq5k5hi5K2/zatd6bkbd/kjrfXo1N4+ZXrBW0mwtbLghyebUdnVjpCIOMYtOWTWU0RKM0lMS6HNp2/Qa852tp29hY2lnvcG1mfBmOZ4ONpoGpeXi11GKZjZgaelfIcQD4iOT+GZxQeISUylcVVXZg1pYNYJiU6n48PBDbCx1LPjXIRZdZH7KPA0RgV61q9Is+rSerQolHeyYf6YZjhYW7D7QiTv/nPSrD7slBWSmJYiiSkG3v3nBGMXHSAyLhkfTyf+ndCOUa2rm8yb2wsda+HmYM3FW3H8vl96GQuRLsVgZPzSQ1yMSFuB/2SzMr8CPz+qezjwcle1oPz7q4PNoh7y3ouRbDx1Ewu9jtd7+WgdTpni4+nMV8Mbo9PBb0GXpflLKSSJaSlxKjyG/l/v5Oe0xRJPt6vB3+PbUreiabWtc7K1YmLam8ycjWeJlQLaQgBq0rXzfAT21hbMG92c8k7anuEwJc91qImPpxO341OY+V/ZbleqKAqz0mpuDm/hTa3yjhpHVPZ09a3Im73V+csz/wtmyxnpMlaaSGJq4oxGhfk7Qxj4zS7O3YylvJMNi8e24J1+fiY72jKiZVVqeDgQEZvMj9svah2OEJr7ec8lft4Tik6nrsD3q1RyFTNKAysLfdq0Blhx6Co7zt3SOqRi89/xcI5eicbe2oKJXetqHU6Z9Uz7Ggxr5o1RgQlLD3P2xl2tQxL5JImpCbsZk8johUG8vzqYZIORbr4VCJzYno51y2sdWq6sLPS8ntaq9KftF7kRk6hxREJoZ8e5W8z4Vx0F/F/PevSsb34r8POjcdVyjG5dHYC3Vp4gIdmgbUDFIDnVyCdptZ6f71BLRs2LkU6n4/1B/rSs4UZsUipPL95PZGyS1mGJfJDE1ERtCL5Bry93sONcBLZWemYO8uenUc1w13iBU3718vekSVVXElIMzNkobQeFebpwK5bxSw5hMCoMaVyZFzua7wr8/HitZz28XGy5HBXPl5vKXovjpftCCY2Mp7yTDc+0r6F1OGWetaWe759oSjV3e8KiEnj+l4MkpZa9DzxljSSmJiYh2cBbK4/z7M8HiIpLxs/LmdUT2vFEq2oms8ApP3Q6HW/1Vef4/LE/TE6jCLNzJz45YwV+02rlmDXUvFfg54ejjSXvD1Tblf604yInr0VrHFHRiUlM4avN5wGY3K0uDtJ6tESUc7Bm/ujmONlaciD0NlNXmFdZstJIElMTcuJqNP2+3sGSfZcBeLZ9DVaOb0PtCqa1wCm/mlZzo1d9T4wKzF57WutwhCgx6SvwQyLiqOxqxw9PNsXG0jTnhJuabn4V6dPAE4NRYeqK4xiMZSOJ+GHbBaLikqlV3oHHmlXROhyzUruCI9+NbIKFXseKQ1f5fpusfTBlkpiaAKNR4cftFxj83S4u3IqjgpMNvz7dkrf6+pX6N7PXe9XDUq9j8+mb7L4gPYyFeZjx70l2nY9MW4HfTPMaw6XN9P71cbK15NiV6IxWy6VZeHQC89Jaj07p5YOltB4tce3rlGdafz8APl53mrXHw9lzIZJ/jlxlz4XIMvMBqCyQcwkauxGTyKt/HmXneTVp6+FXkdlDG+LmYK1xZEWjZnlHRrSsys97Qpm15jT/jG+LXi+nM0XZ9fOeS/y69zI6HXz5eGN8vWQFfkFVcLZlam9f3lx5nM/Wn6Fn/YpUKWevdViF9sWGsySlGmlevRzd/aT1qFZGta7O+Zux/LwnlBeXHMr0PS8XW6b196OXv5dG0Yl08rFNQ+tOXqfnnO3sPB+BnZUFs4Y04Icnm5aZpDTdy13r4GhjyfGr0fx77JrW4QhRbLafvbcCf0ovH0lCHsLjzb1pUd2N+GRDqe7gc/p6DH8dvALA1D6+Ms9YYy1rZN9l63p0Ii/+eojAE+ElHJF4kCSmGohPTmXqiuM8/8tB7sSn4F/ZmdUvt2N4i6pl8p+Wh6MNL3SsCcAn687IqkhRJp2/Gcv4pWkr8JtU5vkONbUOqVTT63V8OMQfaws9m0/fZPWx0pkwfLRWbT3ap4EnTaqW0zocs2YwKsz871S230v/2DPj32A5ra8xSUxL2PEr0fT7aie/Bamn+l7oWIsVL7Yt890/nm5XE09nW67cTuCXtO5VQpQV6gr8/dxNTKVZtXJpxeLL3ofMkla7ghPjOqsltmb8e5Lo+BSNIyqY3Rci2HLmFpZ6Hf/rKa1HtRYUEkV4dM51tRUgPDqRoJCokgtKZCGJaQkxGhW+33aBIXN3cTEiDk9nW5Y805I3evtgbVn2XwY7awte6aF2Ofl68/lS9wYjRE5SDEbGLTnEpch4Krva8b2swC9SL3aqRe0KjkTEJjNrbfajXabIaFQyqpGMTOuGJ7R1827+mr3kdz9RPMp+RmQCwqMTGDlvH7PXnibFoNDb35PASe1pU8tD69BK1NAmVfDxdCI6IYVvtpS94tnC/CiKwrRVJ9l9IRIHawvmj5EV+EXNxlKdfw/w+/4w9l6M1Dii/Fl9PJxjV6JxtLFkQtc6WocjgApOtkW6nygekpgWs7XHw+k1Zwd7LqqlYz4e2pDvRjbB1b5sLXDKDwu9jjd6q6ezFu8OJSwqXuOIhHg4i3dfYum+eyvwfTxlBX5xaF7djREtqwLw5orjJKaY9jz1pFQDn6xTR0tf6FhTPqyYiBY13PBysSW3STZeLra0yGGBlCgZkpgWk7ikVF7/6ygvLjlEdEIKjaq48N/L7XmsubdZzz3rWLc8bWu7k2ww8un6M1qHI0ShbT97i/dWqyvw3+jlQzdZgV+spvTyoYKTDRcj4vh2y3mtw8nVr3svExaVQEVnG55uJ4vgTIWFXpdRyzSnd+EmVcthISUNNSWJaTE4GnaHvl/t4M8DV9DpYHznWvz1YhuZY4TaqnRqb190OvjnyDWOXyk7LQeF+Th/8y7jlx7CqMAjTavwnKzAL3YudlbMGFAfgLlbL3Dmumm2OY5OSOHrzepUpcnd6mJnLfONTUkvfy/mPtEET5fMp+td7a0AWHsivNRMFymrJDEtQgajwrdbzjN07m4uRcZTycWW355txf96+mAlnT4y+Fd2YXBAZQA+XHOq1NYnFObpdlwyTy8+wN3EVJpXL8cHg/3N+ixISerl70k334qkGhWmrjiG0QTL+szdeoE78SnUqeDII02l9agp6uXvxc4pXfjt2VZ8+XgAvz3bioNvd+eRplUwKjD5jyPcjkvWOkyzJdlSEbl6J4HhP+3lk3VnSDUq9G3oxdqJHWhV013r0EzSKz3qYm2pZ8/FSLacual1OELkS3KqkReXHCQ0Mp4q5ez4/glZgV+SdDod7w+qj4O1BYcu32HJPtMqPXf1TgILdqmtR9/oLa1HTZmFXkfrWu4MDKhM61ruWOh1zBhQn5oeDoRHJzJl+TEZNNGI/NUUgdXHrtF7znaCQqJwsLbg00cb8c3wxriknRoQWVUpZ89TbasDMGvNaVINRm0DEiIP6Svw915U/87nj26OuyxqKXFeLna83ktdRPlR4Bmu51KXsqR9vv4syalGWtZwo4tPBa3DEQXkYGPJV8MbY22hZ33wDX7dd1nrkMySJKb5ZDAq7LkQyT9HrrLnQiQGo0JsUiqv/nmUl5YeJiYxlQBvV9ZMbM8jTavIqb18GNepNq72Vpy7GZvRsk8IU7Vo96WMxhhfDW9MPU8nrUMyW0+0qkaAtyuxSalMW3VC63AACL4Ww4rD0nq0tPOv7MKUtOox768O5vT1GI0jMj+WWgdQGgSeCGfGv8GZOka4O1ij00FEbDJ6HbzUuTYTutaRuaQF4GJnxYQudXh/dTCfbzjLgIBK2FvLr6QwPVvP3OT9tBX4b/b2pauvrMDXkoVex+yhDej31U7WnbxB4Inr9PL31DSmjwJPoyjQr6EXAd6umsYiHs7YttXZee4WW87cYsLSw6x6qZ0sYitBkkXlIfBEOC/+eihLG7PIuGQiYpNxs7fmj+db80qPepKUFsITrari7WbHzbtJzNsRonU4QmRx/uZdJiw9jFGBR5tW4Zn2NbQOSQA+ns4831GthjBt1QliErXrJrfzXATbzt7CykLH/3rW0ywOUTR0Oh2fPNqI8k42nLsZy/v/BWsdklmRTCoXBqPCjH+DyW36s5WljiZVy5VYTGWNjaUFr6f1kP5h2wVu3U3SOCJh7u6ftrPh5HWeWrifu0mptKjuxkxZgW9SJnSpQ3V3e27EJPFx4GlNYjAalYxWqU+0qkY1dykLWBZ4ONowZ1gAOh0s3XeZtcfDtQ7JbEhimougkKgsI6UPuhGTRFBIVAlFVDb1a+hFoyouxCUb+HLTWa3DEWYs8EQ47T7azPCf9jLx9yM8+8tBwm4n4O5gzdwnmsgKfBNja2XBh2ntSn/de5kDl0r+f/Gqo9c4eS0GJxtLJnSR1qNlSdvaHrzQsRYAU5Yf4+qdBI0jMg+SmObi5t38rfbM734iezqdjjf7+ALwW1AY52/GahyRMEc5TdsBderOfg2SHpG3NrU8eDStXujUFcdJTi25Ch+JKQY+Wad2sHuxcy3cHMyv1XRZ90r3ujTydiUmMZWJvx2WCjIlQBLTXFRwss17pwLsJ3LWsqY73XwrYjAqmp2SE+Yrr2k7OmDGv8EYTLCgu4A3+/ji7mDNuZuxfL/tQokd95c9oVy9k4Cnsy1j28rc47LIykLP1483xsnGkgOht/lqs2m3wy0LJDHNRYsabni52ObYU1cHeLnY0qKGW0mGVWa90bseFnod64NvyPQIUaKCQiJznbajAOHRifJ7aaLKOVjzbloP9G82n+fCreI/63InPjmj9egrPepiayXTPMqqqu72zBzsD8A3m89Jy9JiJolpLiz0Oqal/bN7MDlNvz2tvx8WelkMURRqV3BiWHNvQFqViuKnKArHr0Qze+1pXlp6OF/3kWk7pmtAo0p0rFueZIORqSuOF3u70u+2XiAmMZV6FZ0Y2kRaj5Z1AwMq86i0LC0RkpjmoZe/F3OfaIKnS+bT9Z4utsx9ogm9/L00iqxsmtStDvbWFhwJu8Oa49e1DkeUMYqicOzKHWatPUXHT7bS/5udfL/tApH5fJORaTumS6fTMXOQP3ZWFgSFRPHngbBiO1ZYVDyLdl0C4I0+PjI4YSam39ey9HVpWVpspJp5PvTy96K7nydBIVHcvJtIBSf19L38Myp6FZxsea5DTeZsPMfH607T3a8i1pby+UkUnpqMRrPmeDj/HQ/nyu17K2vtrCzo4lOBXvU9mbkmmJsxSdnOM9WhfhiVaTumzdvNnld71GXmf6f4cM0puvhWKJYPE59vOEuywUibWu50qlu+yB9fmKb0lqVDvtvNhuAb/Lo3lCdbV9c6rDJHEtN8stDraF3LXeswzMKz7WuyZN9lQiPjWbIvlKdkUYEoIEVROJqWjK7JLhn1rUDfBl50qlc+o9uYlaWOF389hA4yJacybad0GdOmOv8cucbxq9HM+DeYb0c0KdLHP3E1mr+PXAVgam9pPWpu/Cu78EZvH95bHcz7/52ieQ03fDydtQ6rTJGhKGFyHGwsmdytLgBfbTpHdIJ2HV1E6aEoCocu32bm6mDafbSFQd/u4sftF7lyOwF7awv6NfRi7sgmHHqnO9+OaEKfBl6ZWuDKtJ2ywdJCz6whDbDQ6/jvWDibTt0o0sdPbz06MKASDaq4FOlji9LhqbbV6eJTgeRUIxOWHiYh2aB1SGWKjJgKk/RYsyos2BXC+bTyL1N6+WgdkjBBRqPC4bA7rDkeztrj4Vy7b2W9vbUFXX0r0reBJx3rVshXr2uZtlM2+Fd24el2Nfhx+0Xe+fsErWq642Dz8G9328/eYse5CKwt9LzWQ1qPmiudTscnjzSk15c7OHczlvdWBzMrrdGDeHiSmAqTZGmh541ePjzz8wEW7AzhyVbVqORqp3VYwgSoyeht/jt2nbUnwjOVeXJIS0b7pJ2mL0wJH5m2UzZM6lYnYxrHp+vPMK1//Yd6PINRYdZatcbyqNbV8HazL4owRSnlntay9In5+/gt6DLt63jQp4GcVSkKkpgKk9XVtwIta7ixLySKT9ef4fPHArQOSWjEaFRP0/93PJy1x69zPeZeMupoY0lX3wr0aeBFx7qFS0ZF2WNvbckHgxswekEQi3ZfYmBAZQK8XQv9eH8fvsqp8BicbS15qUvtogtUlFrpLUvnbr3AG8uP0bCKC1XKyQeWhyWJqcib0YAudCeVo/agC3WGmh1AX/xv/umtSgd+u4uVh6/ydLsa1K8kc7rMhdGocPDybf47Fk7giazJaLe0ZLSDJKMiBx3rlmdQQCX+PnKNqSuOs+qltlhZFHxpRWKKgc/Wq61Hx3Wujau9tB4Vqle612XPhUiOhN1h0u9H+P25VlgW4ndM3COJqchd8CoInIJlzDWaAYTOBedK0Osj8BtQ7Idv5O1K/0aV+PfoNWavPc0vT7cs9mMK7RiNCgdCb6tzRk+EcyMmKeN7TjaWdPNTT9O3r+MhyajIl3f6+bH17C1Ohccwb0cIL3aqVeDHWLT7EteiE6nkYsuYNtWLPkhRallZ6Pl6eGP6fLlDbVm66RyvyPzjh6JpWj99+nR0Ol2mi6enp5YhifsFr4I/R0HMtczbY8LV7cGrSiSM13vWw8pCx45zEWw/e6tEjilKjsGosO9iJNP+OUGrWZt47Ic9LNp9iRsxSTjZWDKkcWXmjWrGgXe68cWwALr7VZSkVOSbu6MNb/dVO/jN2XiW0Mi4At3/dlwy325R+6O/2qOe/O6JLLzd7rUs/XrLefZckJalD0PzEdP69euzcePGjNsWFvJHbxKMBgicAtmWG1cAHQS+AT59i/20vrebPaNaV2f+zhA+XHOKtrU9ZJV0KWcwKuy/FJU2MnqdW3fvGxm1taSHnyd9GnjSro4HNpbyP0E8nKFNKrPy8BV2nY/kzZXH+fXplvmuP/rNlvPcTUzF18uZQY0rF3OkorQaGFCZneciWHbwCpP/OMLaie0p5yBTPgpD88TU0tJSRklNUejurCOlmSgQc1Xdr0b7Yg9nQpfaLDsQxunrd1l5+CqPNJXe1KWNwaiwLySSNcfDCTxxg4jYe8mos60lPep70reBF21re0i3L1GkdDodHwxqQM8529l1PpIVh64yNB//Q8Ki4vllTygAU3tL61GRuxkD63Pw8m0u3orj9eXH+PHJptKAoRA0T0zPnTtHpUqVsLGxoWXLlnz44YfUrFkz232TkpJISrr3ZhYTEwNASkoKKSlShL0o6aKv5uuXIzX6KkoJPPcOVjpe7FiTj9ad5dN1p+npK3MMi1v639TD/G2lGozsD73N2hM3WB98M1NPehc7dQFT7/oVaV3T/V4yqhhISZGC1VooitfcVFV2sWZC51p8uuEcM/8Lpm2tcrjnMaL1ceApkg1G2tZyp3UN1zL5vEDZft1LkpUOPn+kAY/+uI8NwTdYvOsiI1tW1TqsbJX0a16Q4+gURcnuXG2JWLt2LfHx8dStW5cbN24wc+ZMTp8+zcmTJ3F3z1pHcPr06cyYMSPL9qVLl2JvLyUaipL73VO0Oz8rz/121p5KpJNvCUQEKUb48IgFUUk6+lU10L2yZr+6IhcGBc7H6DgSqeNYpI7Y1HsjBvYWCg3cFBq7K9RxUZCBUVGSDEb49LgF1+J1NPMw8mQdY477hsXCp8ct0aHwWkMDVRxKMFBRqm0N17HykgWWOoVXGhioLL87xMfHM2LECKKjo3F2zr2Fq6aJ6YPi4uKoVasWr7/+Oq+88kqW72c3Yurt7U1ERESeP6goIKMBy8/roEuKyfbbCjpwrkTq+EMlUjoq3T9Hw3ntr+M42FiwaXL7PEc8ROGlpKSwYcMGunfvjpWVVa77phqM7LukjoxuOHWDqLh7n45d7azo7qeOjLaq6Vaocj2iZBTkNS+tjl6J5tEf96EosGB0E9rX9siyj6IojFp4gL0htxnUyItPHinbXX3M4XUvSYqi8Nyvh9l6NoJa5R1Y+UKrfHWeK0kl/ZrHxMTg4eGRr8RU81P593NwcKBBgwacO3cu2+/b2NhgY2OTZbuVlZX8MRW1aychOefVqzoU6DUbKxvbHPcpDkOaeLNoTygnrsbw/fZLTB/wcN1cRPYMRoVDIVEcjNDhfuUurWtXyDK/LtVgZM9Fdc7oupM3iLrvNH05eyt61vekTwMvWtdyl2S0lCnL/1Ob1fBgdOvqLNp9iWn/nmL9pI5ZkoYtZ26yN+Q21pZ6XuvlU2afiweV5de9pH32WAC9v9zBhVtxzFp3zmRblpbUa16QY5hUYpqUlMSpU6do3774F9OIXCTHwfKnQTFA5WZw91rWhVDlfcC3f4mHptfreLO3LyPm7ePXvaGMaVOd6h5ynqQoBZ4IZ8a/wWmtPi34+dwBvFxsmdbfj66+FdlzIT0Zvc7t+Hsjo24O1vSsr9YZbVVTklFhul7rWY/1J68TFpXAnI1nmdrn3nQkg1Fh9hq19eiYNtWlk48oFHdHG76QlqWFomli+tprr9G/f3+qVq3KzZs3mTlzJjExMYwePVrLsETgGxB5HpwqwchlYOtC6sXtHNmxjoAmTbH8ZxzcOg0Xt0CtLiUeXpvaHnSuV54tZ27x8brTfDeyaYnHUFYFngjnxV8PZSkSFh6dyAu/HsLe2oL45HsLk9RkVF1N36qmm3Q8EaWCo40l7w3055mfDzBvZwh9GngRn2zg5t1Egq/FcObGXVzsrBjfSVqPisJrW9uDFzvW4jtpWVogmiamV65cYfjw4URERFC+fHlatWrF3r17qVatmpZhmbfgf+DQz4AOhvwA9m4AKNXacfVkDI38+kD4Ydj7LWx6D2p2Bg3KYbzR25dtZ2+x5vh1Dobepmm1ciUeQ1ljMCrM+Dc428q16eKTDbjZW9GrgRd9G3jRsoYko6J06uZXkb4NvPjveDiPzN1NijHzb3433wq42MtpbfFwJnevy+60lqUTfz/CH9KyNE+aPju///47165dIzk5matXr7J8+XL8/Py0DMm8RV+BVS+r19tNghodst+v/Stg7QjXDsOpf0ssvPvV83Ti0abeAMxacwoTWsNXagWFRKWdvs/dV8Mb8+HgBrSt7SH/YEWp1qGuuvDpwaQUYMWhqwSeCC/pkEQZk96y1MnGkoNpLUtF7uRdRaiMBlj5AiTegUqNodObOe/r4AGtxqnXN89U76uByd3rYmul50DobdadvKFJDGXJzbt5J6VAplqkQpRWBqPCnI25Jwkz/g3GkE3SKkRBeLvZ82Ha4idpWZo3SUyFateXcGkHWDnA0PlgmUcZpjYvgV05iDgDx/4omRgf4Oliy7Pt1WYMHweeJsWQc01Ckbert+PztV8Fp5KtxCBEccjrDIGCOrc6KCSq5IISZVb/RpV4rFkVFAUm/3GE2/IBP0eSmAq4ehC2fKBe7/MxuNfK+z62LtBusnp9yyxITcp9/2LyXIeauDtYczEijt+DLmsSQ2mXlGpgxr8n+Xjd2Vz30wFeLra0qOFWMoEJUYzye4Ygv/sJkZfpA+pTs7wD12MS+d9fx2QKWg4kMTV3SXdh+TNgTIX6gyFgZP7v2+I5cPKC6MtwcHHxxZgLJ1srJnWrA8CcjeeITUrVJI7S6vzNWAZ/u5uFuy4B0NmnPDrUJPR+6ben9feTfuGiTMjvyL+cIRBFxd7akq+HN8baQs/GUzf4ZW+o1iGZJElMzd3aKRB1EZyrQL8vCrbC3soOOvxPvb79k1wL8henx1tUpaaHA5Fxyfyw7YImMZQ2iqLwx/7L9P96J8HhMbg5WLNgTDMWjmnB3Cea4OmS+c3Y08WWuU80oZe/1OETZUOLGm54udhm+RCWTs4QiOJQv5ILU/v4ADDzv1OcCs++u6I5k8TUnJ1YAUeWgE4PQ35U54wWVOMnoVx1iLsJ+74v8hDzw8pCz+u91D/0n3Zc5Ho+Vpabs+iEFF767TBTlh8nIcVA29ruBE5sTxefigD08vdi55Qu/Dq2GaPqGPh1bDN2TukiSakoUyz0Oqb1V6vAyBkCUZLGtKlOF58KJKcamfDbYRKStVlAbKokMTVXdy7Dv5PU6+1fheptC/c4ltbQ+S31+q4vIeF2kYRXUD3rV6RZtXIkphj5YkPucyXN2cHQKPp8uYP/joVjqdcxpZcPv4xtSQXnzCOkFnodLWu40dRDoWUNN3lzFmVSL38vOUMgSpxOp+OTRxpSwcmG8zdjeW/1Sa1DMimSmJojowFWPA9J0WrL0Y5THu7x/IdCBT9IjIbdXxdNjAWk0+ky2gouOxjGmet3NYnDVBmMCt9sPsdjP+zl6p0EvN3sWPZCa17sVAu9JJ3CjKWfIfjt2VZ8+XgAvz3bSs4QiGLn7mjDnGEB6HTwW1AY/x2TmrnpJDE1Rzs+h8u7wdoJhs4Di4fsbqK3gC7vqNf3zoW72tQUbVqtHH0aeGJUYPbaU5rEYIrCoxMYOW8vn64/i8GoMKBRJda83J7GVaVblhCgniFoXcudgQGVaV3LXc4QiBLRprYH4zqpVXDeWHGMK/ks2VfWSWJqbsKCYOss9XrfT8GtRtE8br3e6uhrSjzs+KxoHrMQXu/pg6Vex5Yzt9h9PkKzOEzF+pPX6f3lDvZejMLe2oJPH23El48H4GQrrRaFEEJrk7rVpXFVV+4mpjLx9yOkSj1uSUzNSmKMWhpKMYD/I9BwWNE9tk4HXd9Vrx9YoM5h1UB1DweeaFUNgA/WnMJopl1bElMMvPvPCZ775SB34lPwr+zM6gnteKRpFXQFqbwghBCi2FhZ6Pnq8XstS7+UlqWSmJqVNf+DO6HgWhX6fV6w0lD5UbMj1OwExhTYOrtoH7sAJnSpjZONJSevxbDq6DXN4tDKuRt3GfTtLn7eo9bIe7Z9DVa82Jaa5R01jkwIIcSD7m9Z+o20LJXE1GwcWwbHfk8rDfWT2rmpOHRJGzU9+hvcOlM8x8iDu6MNL6TN2/lk3RkSU8yjFIeiKCzZF0q/r3dy+vpdPBytWTy2BW/19cPaUv7UhRDCVN3fsnTSH4eJMuOWpfJuZQ5uX4L/XlGvd5wCVVsV37GqNAWffqAYYfPM4jtOHp5uVwMvF1uu3kng5z2XNIujpNyJT+bFXw/x1soTJKUa6VC3PGsndqBj3fJahyaEECIf0luW3ohJ4nUzblkqiWlZZ0iF5c9CUgx4t4L2rxX/Mbu8Dejg1Cq4eqj4j5cNWysLXu1RD4BvNp/nTnzZ/fQZFKLWJg08eR0rCx1v9fFl0ZjmlHey0To0IYQQ+fRgy9L06VjmRhLTsm77J3AlCGyc1e5OFpbFf8wKvvcWVmk4ajq4cWV8PJ2ISUzlm83nNYujuKQa1GYCj/+4h2vRiVR3t2f5i214tkNNqU0qhBCl0P0tSz9Yc4rga+bXslQS07Ls8l7Y/rF6vd8XUK5ayR2781TQW8GFTXBpZ8kd9z4Weh1vphXd/3lPKGFRZadG3NU7CQz/aS9fbjqHUYEhTSqz+uX2NKziqnVoQgghHsKYNtXpmtGy9BDxyalah1SiJDEtqxLuqKfwFSM0fBwaPFKyxy9XHZqOVq9veg80mivToW552tfxINlg5ON12izGKmprj4fTe8529l+6jaONJXOGBfD5YwE42pTAaLgQQohipdPp+OTRRlRwsuHCrTjeXx2sdUglShLTskhR4L9XIfqymiD2+USbODr8DyztIGwfnF2nTQzAG7190Ong36PXOBp2R7M4HlZCsoE3Vx7nxSWHiElMpVEVF/57uR2DGlfWOjQhhBBFyM3B2mxblkpiWhYd+wNO/AU6Cxg6H2ydtYnDyRNaPq9e3/w+GLXpaFG/kguD05K3D9ecKpUrHU+FxzDgm50s3ac2LnihYy2WvdCGau4OGkcmhBCiODzYsrQsTUfLjSSmZU3URXW0FKDTVKjSTNt42k4EGxe4cQJOrtAsjNd61MPGUs++kCg2n76pWRwFpSgKP++5xMBvd3HuZizlnWz49emWvNHbR2qTCiFEGZe5Zelhs2hZKu9sZYkhRZ1XmhwLVdtA+1e0jgjs3aDtBPX6lg/UGDVQydWOse1qADBr7elS8cd9Oy6ZZ38+yLv/nCQ51UjneuUJnNiednU8tA5NCCFECbi/Zemhy3fMomWpJKZlydbZcPWA2tVpyI+gt9A6IlXLF8HeQx3NPbJEszBe7FSLcvZWnL8Zy58HrmgWR37suRBJ7y93sPHUDawt9Lzbz48FY5rj7ii1SYUQwpyYW8tSSUzLiku7YMdn6vV+c8DVW9NwMrFxhA5phf23fgQpCZqE4Wxrxctd6wDwxcazxCWZXgmOFIORT9edYcS8vVyPSaRmeQdWjGvD2HY10OmkNqkQQpij/o0qMayZt1m0LJXEtCxIuA0rngMUCHgC/IdoHVFWzcaCcxW4ew32z9csjJEtq1HN3Z5bd5P4acdFzeLITlhUPMN+2MM3W86jKPBYsyqsntAO/8ouWocmhBBCY9MG+FEro2Xp0VK5kDc/JDEt7RQF/p0EMVfArSb0/kjriLJnaQOd3lCv7/gMErXpZmFtqef1nmpXjR+3X+Tm3URN4njQv0ev0eerHRy6fAcnG7Ut3cePNMLeWmqTCiGESG9Z2iStZenNMtuyVBLT0u7IEgj+G/SWMHSeetrcVDUaDu51ICEK9n6nWRh9GngS4O1KfLKBORu1nUgen5zK638dZcJvh7mbmErjqq6smdie/o0qaRqXEEII0+NXyZk3y3jLUklMS7PIC7DmdfV657egclNt48mLhSV0eUu9vvsbiNNmArdOp+Otvmqr0j/2h3H+5l1N4jh5LZp+X+/kzwNX0Ongpc61+fP51ni72WsSjxBCCNM3uoy3LJXEtLRKTYblT0NKHFRvr9YLLQ18B4JnQ0i+C7u+0CyM5tXd6OFXEYNRYfbakm1VqigKC3aGMPjb3Vy8FUdFZxuWPNOS13rWw8pC/iSFEELk7MGWpe/9W7Zalsq7YGm19UO4dhhsXWHwD6ZTGiovej10naZeD/oJYq5pFsqU3j5Y6HVsPHWDfRdLZvQ2MjaJpxcf4L3VwSQbjHTzrcjaiR1oU0tqkwohhMgfNwdr5jyutiz9fX8Yq49p915a1CQxLY1CtsPOOer1AV+DSynrlV67q9oAIDURtn2sWRi1yjsyvIVaVqskWpXuPBdBry93sPn0Tawt9bw3sD4/jWqKm4N1sR5XCCFE2dOmlgfjO9UGYOqK42WmZakkpqVNfBSseB5QoMlo8BugdUQFp9NB13fV64d/UefKamRi17o4WFtw9Eo0q4+FF8sxUgxGZq89zZML9nHrbhK1Kzjyz/i2jGpdXWqTCiGEKLSJ3erQ5L6WpSmloKthXiQxLU0UBVZNUGuButeBXrO0jqjwqrWGOj3AmApbtfs5yjvZ8HzHWgB8vO40SamGIn380Mg4Hvl+D99vu4CiwPAWVfn3pXb4ejkX6XGEEEKYHysLPV/e37JU40ozRUES09Lk0GI4vRr0VmppKGsHrSN6OF3eVr8e/wuun9AsjGfa16CCkw1hUQn8uvdykT3u34ev0vernRwNu4OzrSVzRzZh1pAG2FmXkvnAQgghTJ63mz2zhqotS7/dep7dFyI0jujhSGJaWtw6C4FT1etd34VKAZqGUyS8GkH9IYACm2dqFoa9tSWvdK8LwNebzxGdkPJQjxeblMorfx5h0h9HiE1KpXn1cqyd1IHeDbyKIlwhhBAik34NK/F4c7Vl6eQ/jpTqlqWSmJYGqUlppaHioWYnaP2S1hEVnc5vgc4Czq6FsCDNwnikaRXqVnTkTnwK3209X+jHOX4lmn5f7WDFoavodTCxax1+e7YVlV3tijBaIYQQIrN3+5eNlqWSmJYGm9+H68fAzg0Gfa+WXCorPGpDwAj1+qb31Hm0GrC00PNGb7WbxsJdl7hyu2CrG41GhZ+2X2TI3F1cioynkostvz/Xmsnd62IptUmFEEIUswdbli7efUnrkApF3jFN3YUtsPtr9frAb8G5DJ4O7vQGWFjDpR1wcYtmYXSuV4HWNd1JTjXy+fqz+b7fzbuJjF4YxAdrTpFiUOhZvyJrJranRQ23YoxWCCGEyOz+lqUfrjldKluWSmJqyuIiYeUL6vVmT4NPH23jKS4uVaD5M+p1DUdNdTodb/ZRW5WuPHKVE1ej87zPtrO36PPlDnaci8DGUs8Hg/35/ommuNpLbVIhhBAlb3Sb6nTzrUCyoXS2LJXE1FQpCqx6CWKvg0c96KHd4qAS0e4VsHJQu1md+lezMBpUcWFgQCUUBWatzbnofnKqkQ/+C2b0giAiYpOpV9GJfye0Y2TLalKbVAghhGZ0Oh0fP9KIis6ls2WpJKam6sB8OLNGPcX9yHywttc6ouLlWB5aj1evb54JxqKtJ1oQr/Woh7WFnl3nI9ly+iZ7LkTyz5Gr7LkQicGoEBIRx9C5u/lpRwgAT7aqxj8vtaVuRSfNYhZCCCHSuTlY88Wwey1L/z1aelqWWmodgMjGzdOw7i31ercZ4NlA23hKSpuXYP9PEHEGjv1xb1FUCfN2s2d0m2r8tCOE5345SKrx3qipi50VCSkGklONuNpb8dHQhvSs76lJnEIIIURO0luWfrPlPG+uOE6AtyvebqY/yCUjpqYmJRGWP6P2ka/VFVq+oHVEJcfWBdpNVq9vmaWWydKIj6famen+pBQgOiGF5FQjdSo4snZie0lKhRBCmKyMlqVJqbxcSlqWSmJqajbNgBvHwd4DBs0tW6Wh8qP5s+DoCdGX4dDPmoRgMCp8uv5MrvvEJqVSwcm2hCISQgghCi6jZamtJYdLSctSM8t6TNy5jbD3O/X6oO/AqaK28WjB2h46/k+9vu1jSI4r8RCCQqIIj07MdZ/w6ESCQqJKKCIhhBCicLzd7Jk9pCGgtizdefYW+0KiOBihY19IFAajaRXil8TUVMTegr9fVK+3eA7q9tQ2Hi01HgXlqkPcTdj3Q4kf/ubd3JPSgu4nhBBCaKlvQ6+MlqWjFgbxxIID/HzOgicWHKDdR5sJPBGudYgZJDE1BYoC/4xTE7EKftD9Pa0j0palNXR6U72+aw4k3CnRw+f3FL2cyhdCCFFatK7lDsCDA6TXoxN58ddDJpOcSmJqCoJ+gnPrwcIGhs4HK+mrToNHoLwvJEbD7q9K9NAtarjh5WJLTtVIdYCXi610dhJCCFEqGIwKs9eezvZ76XnqjH+DTeK0viSmWrtxEta/rV7vMRMq+mkbj6nQW0DXd9Tre+dC7M0SO7SFXse0/urr8GBymn57Wn8/LPRSSF8IIYTpy2vthILprJ2QxFRLKQlqaShDEtTpCS2e1Toi01KvD1RuBinxsP3TEj10L38v5j7RBE+XzKfrPV1smftEE3r5e5VoPEIIIURhlaa1E1JgX0sb3oWbweBQAQZ+C9LKMjOdDrq+Cz8PgAML1AL8rlVL7PC9/L3o7udJUEgUN+8mUsFJPX0vI6VCCCFKk9K0dkJGTLVydh0E/aheHzRXbckpsqrZEWp0BGMKbP2oxA9vodfRupY7AwMq07qWuySlQgghSp3StHZCElMt3L0Bf49Tr7caB3W6aRuPqev6rvr16FK4lXvheyGEEEJkVprWTkhiWtKMRrVeaXwEVGwA3aZrHZHpq9IMfPqBYoQtH2gdjRCirDEaIGQHHP9L/Wo0aB2REEWutKydkDmmJW3f93BhE1jawtB5YGmjdUSlQ+e34PR/EPwPXDsMlRprHZEQoiwIXgWBUyDm2r1tzpWg10fgN0C7uIQoBulrJ/acv8n6Hfvo0b4lrWtXMImR0nQyYlqSrh+HjdPU6z0/gAo+2sZTmlT0g4bD1Oub3tc2FiFE2RC8Cv4clTkpBYgJV7cHr9ImLiGKkYVeR8sabjT1UGhpggt6JTEtKcnx8NfTYEhWyyA1e1rriEqfTm+A3lIdcb60U+tohBClkSFFnecffhxWT+ZeefH7pW0LfENO6wtRwuRUfklZ/zZEnAFHTxjwjZSGKgy3GtBkNByYD5veg7Hr5HkUoqgYDehCd1I5ag+6UGeo2UFtdGHKjAZIuA3xkWmXqPuu53A7KTqfD65AzFUI3Q012hfrjyGEuMdkEtNZs2bx5ptvMnHiRObMmaN1OEXr9H9qMgUw+HtwcNc2ntKs4+twZCmE7VPbuNbtqXVEQpR+afMsLWOu0QwgdG7Jz7M0GiHxjpo8JjyYUOaQaCbcIfsRz7zowNoBkmPz3vW/V6DFc+A3EBwrFOJYQoiCMInEdP/+/fz44480bNhQ61CKXkw4/POSer3NBKjVWdt4SjsnT2j5HOz6Up1rWrs76GVGihCFlj7P8sEEL32e5WM/Fzw5VRRIiklLJHNKMh9INBOi1MobhWHrCvbuaRe3B75mc7F1UUdCF/fL+7EjzsKa12Dt61C9HdQfAr4DZIBBiGKieWIaGxvLyJEj+emnn5g5c6bW4RQtoxH+fkH9h+vZELq8q3VEZUPbSXBgIdw4DidXQINHtI5IiNLJaFBXpOc4z1KnzrOs2SltNDOnU+TZbDOmFi4mG+esSaWdW86Jpl05sCjEW1m1NuqocEx4Dj+/DhwrQutxcPJvuHYIQrarl/9eVZt/1B8Cvv3UGIQQRULzxHT8+PH07duXbt265ZmYJiUlkZSUlHE7JiYGgJSUFFJSUoo1zsLQ7/0Gi4tbUazsSR30Ayg6MME48yP9+TWJ59nKCX2r8Vhsm4WyeSapdfqAhZXWUZU5JvWai6KhKJB0FxKi0CVEobu0A4sHV6RnvoM6z3K2d+EOZ+UA9m4odvdGMRW7tGTS3g0lLelU7k8+LawLdhCjonaGKwRd9w+xWP4UoEN3X3KqpJUcN/ScjeLTD1qMg9uX0J9ahT54Jbobx+HCZriwGWX1ZJQaHTH6DUap2xtsnQsVi5bkb938lPRrXpDj6BRFKcwEnSLx+++/88EHH7B//35sbW3p1KkTAQEBOc4xnT59OjNmzMiyfenSpdjb2xdztAXjEn+JDmdnoFcMHPF+ilAPOYVflCwNCXQLfg2b1Lvy/IqipRhxjz2DbcodEq1ciXSsBzrTmy6iU1KxTo3DOjUWK0Ms1qmxWKd/TY3FOvXuvduGWKxSY7FOjUNP4VaZG3RWJFs6kWTpSLKlE8kWTiSnX8/Y5kiSpVPGNqO+gEmmBrzu7KfBlSXYpURlbIu3cuNElZGEuzbP9j4OieFUvrOfSrf34ZIYlrHdoLPkpnMDrrq25IZLY1It7Io9fiFKg/j4eEaMGEF0dDTOzrl/eNMsMQ0LC6NZs2asX7+eRo0aAeSZmGY3Yurt7U1ERESeP2iJSo7Dcn4XdFEXMNbrh2HowlK/ejwlJYUNGzbQvXt3rKxMY3RSH/QDFhveQnHyInXcfrVpgSgypviaFzfd6dVYrH8T3d17o4iKUyUMPT5UR86Kg6JASry6ujwhCl3a4h9d2m0SbqNLiIL42/dtj0SXdLfwh7SyTzsFbo3udkie+6cO+x2lVtdS/38sR0YDurA9EHsDHCuieLfOf0WCiLPog1eiD/4bXeS5jM2KpS1KrW4Y/Qah1O6uLrYyUeb4t27uSvo1j4mJwcPDI1+JqWan8g8ePMjNmzdp2rRpxjaDwcD27dv55ptvSEpKwsIi8z8GGxsbbGyydkqysrIyrT+mte9C1AVwqoR+4NforU1/1CC/TOq5bvEM7JuLLuYKVkd+htbjtY6oTDKp17w4Ba+C5U/x4HxD3d1wLJc/lb9FQFlWlmfzNT4yrcTRfdsMSbk/bo506kKe9MU+6afD7dzAvlza16zf01mlfYgzGmCOf+7zLJ0rYVmvh+mXjnooVlC7kGddvOqrly5vwc1gOLECTq5AF3UR3ZnV6M+sBit7qNsL6g+GOt3ByjRHUs3mb11kKKnXvCDH0Cwx7dq1K8ePH8+07amnnsLHx4cpU6ZkSUpLjeBVcGgxoIMhP6hvBKJ4WNlCpymwagLs+AyajAIbJ62jEqVRnouAgH8nQtxNtUTRg4llxtfbOTxGPuitHkgiyz2QaGaTfNq5PlzCqLdQS0L9OQrQPRB72uhor9llPCktIjodVKyvXrq8DdePpSWpK+FOqLpQ8+QKsHZUm6zUHwy1u0pbaiEeoFli6uTkhL+/f6ZtDg4OuLu7Z9leakRfVZMkgHaToEYHTcMxC41GqKWjIs/Dnu/URFWIggrdnbUt5YMSotTV2Plh7ZRNYumWeYV52gKgjNvWjtqcKvcboI4GZ9svfrb0iy8MnQ68GqmXbtPVFf0nVqir+2OuwPE/1YuNC/j0VZPUmp3AsuycXROisDRflV9mGA2w8nn1NF6lxtDpTa0jMg8WltD5LfjrKdj9NTR/RuoLioKLvZG//Twbgad/NqfNH/ha2hIMvwHg05fUi9s5smMdAe17YlkaOj+VBjodVG6qXrq/D1cPqElq8N9wNxyOLlUvtq7g219NUmt0LFwJLCHKAJP6zd+6davWIRTeri/h0g6wcoCh80vfG1Np5jcIPL9QT53t+gJ6lLF6uKJ4xd6Eo7/lb9+eH5Td9pR6C5Rq7bh6MoZG1dpJUloc9HrwbqFeen4IYXvTktR/1Gkih39RL/buahH/+oPVov7yWggzYno1UEqjqwdhywfq9T4fg3stbeMxN3o9dE1rXhD0U96nZIUASE1WR9m/bgrnN+axsw6cK6tF2YUoCnq9+vvU91N49TSMWgVNn1KT0vhIOLgQfh4An/nAf6+p002MheyMJUQpIonpw0qKheXPqF1O6g+GgJFaR2SeaneDqq0hNRG2fax1NMLUndsAc9vA+rfV1pleAWmd2XRkLPrJIIuARDHTW6idpPrPgVfPwhMroPGT6un9uJuw/ydY2Bu+8IO1b0BYkCSpD8togJAdcPwv9auxcPV9RdEzqVP5pdLaKRB1EZyrQL8vym6dP1On06mjpgt7q6fC2kyQkWuRVeQFCJwK59aptx3KQ9dp6gdKvR486sgiIKEtC0t1tX7trtD3c7i4VV3Zf3q1Oid131z14lwF6g8C/yFQqYm89xRE8Koc/s4/kr9zEyCJ6cM4uRKO/Kp2hRnyo/RL1lq1NlC7O5zfAFtnwdB5WkckTEViDGz/BPbOVdtX6i2h5QvQ8XW1Dmi6tEVAhO7OKLZOtTYyUiq0YWkNdXuol9Q5cH6T+r5zZo26un/PN+rFtZp6xs5/CHg2lCQ1N8Gr0sqjPVDWLSZc3Z6fesWiWEliWlh3wtS6hgDtX4XqbbWNR6i6vqMmpsf/graT1BXUwnwZjerCpk0z7q28r90des1SR0ezo7couwucROllaQM+fdRLSoI6HeXkSjgbqNZJ3TVHvbjVupekVvCTJBXAkKLWH46PhP8mk3O9Yh0EvqF+OJUPo5qRxDS/jIZ7oygO5WHLLEiMhsrNoKPUzjQZXo3Uf8onV6oL0obnc7W1KHuuHIC1r6uLE0F9w+41C+r21DYuIR6WlZ06quc3AJLj4Ow6tXj/uQ1q18Edn6oXj3r3ktTy9bJ/LKMBXehOKkftQRfqDKZaJiw1SU0uE6PVsowJd/L/NSUunwdRIOYqrH5Ffc68GqlNLESJksQ0P7KbjwJqb/ah88BCWriZlM5vqa/ZmTXqIgHvFlpHJErS3euwcfq9ElDWjuop+5YvShk3UfZYO6hJlP8QSLoLZwLVJPX8Rog4A9tmq5cK9e8lqenz79Pe2yxjrtEMIHRu8c61TEkseFKZ/jU14eGPb2mXv8c5tEi9AJSrAZUC1AWSlQLSklWZtlecJDHNS07zUUBdAX79OLjVKPGwRC486kDACHUR1Kb3YPS/cjrLHKQmwd7vYPunkByrbgsYqS5ucqqobWxClAQbJ2j4qHpJuANn1qpJ6oXNcPOketkyU52HWt4Hji+jQHMtFUWdRpCRNBZw9DI18SF/QB3YOqvVCuxc1fnhGddz+1oObJzh8h5Y3C/vw1RrC9FX1CkSt0PUy8mV975frrraSEeS1WIhiWlucu2fDTIfxYR1nALH/lCbHlzcCrU6ax2RKC6Kos6zW/emWiED1Ck2vT+GKk21jU0Irdi5QsBw9RIfBaf/U5PUi9vUZiTXj+Vwx7T3u5XPwaGfsyafhuSHDEynJpR5JpPZfLVxfrj32mpt1BHhmHCyf1/Xqd8f/a96nPgoCD8K1w5D+BG4diQtWb2kXh5MVjMS1bSvkqwWiiSmucmzf3bafJTQ3bJYwtS4ekOzp9WyKpveU/tQy6hp2XPrrPrh8MIm9bZjReg2AxoOU8s/CSHUVrlNnlQvcRGw43PY+23u90lJUBeSZkenzz55zE/CaeOs3d+m3kKdpvDnKNT6xPcnp9nUK7Z3Uwc17h/YSE9W0xPV8CP3EtXbl9RWs+keTFa9GqmPKXIliWlu8ts/O7/7iZLV/lX1E/+1Q2oNQN/+WkckikpiNGz9CIJ+UJtbWFhDq3HQ4TX1dKYQInsOHlC5Sf72bTJabV6SJbl0Kr0f9P0GqNMUCluv+GGTVddq942qNpZkNRuSmObGMZ/z0vK7nyhZjuWh9Ti1fuXmmVCvj0y5KO2MBjj8qzoKHh+hbqvbW+1hLw0VhMif/L5nNXi0bJ4NLOp6xdklqwm306YBHElLWA+rSeqdUPUS/M+9fTMlq2lfzThZlcQ0N/mdjyL9s01XmwkQ9BPcOg3H/lTnW4nS6fJetfxT+FH1tkddtfxT7W7axiVEaSPvbcVfr9iunDqFrGane9uyJKtH1IVV2SarVR9YYBVgNsmqJKa5Keh8FGF6bF2g3WTYOA22fgj+Q6VkUGkTfVV9/Y4vU2/bOEOnN6DFc1KqTYjCkPc2beSYrB7LvMDqdgjcuaxeHkxW0xPV9KS1MMmqideulcQ0Lw87H0Vor8VzaivKO5fh0GJo8azWEYn8SEmEPV+rCzVS4gGdunijy7vqNA0hROHJe5tpsCsHNTuql3QJdzLPWb12OHOyemrVvX3vT1bT563mlqyWdO3aQpDEND+kf3bpZm0PHf8H/70K2z5Wa5xaO2gdlciJoqiL1da9pZ7eAvBuBb1nq/90hRBFI+29LfXido7sWEdA+55YmtjomVmyc807WQ0/opbHyy5ZdamaNqoakDlZzakue261azUgiWl+Sf/s0q3xKNj1lZro7PsB2r+idUQiOzdPwdopELJNve1UCbq/Bw0eKb2rgIUwZXoLlGrtuHoyhkbV2klSaqpySlavp00DuD9Zjb6sXu5PVp29If4W2c8pVjCluuySmArzYGkNnd+Elc/DrjnQbKz0QDYlCbdhyyzYPw8UA1jYqAvX2k0GG0etoxNCCNNj5wo1OqiXdBnJ6pF7o6tRFyAmLI8HM5267JKYCvPR4FHYOQdunYLdX0PXd7SOSBgNcHAhbP4AEqLUbT79oMdMafUrhBAFlV2ymhitnjHc8Wne9zeBuuzSGkWYD70FdHlbvb53LsTe1DYec3dpF/zQUZ37mxAF5X1h1D/w+BJJSoUQoqjYumSuBJAbE6jLLompMC8+faFyU0iJgx2faR2NeboTBsvGwKI+cOO4+k+z98fwws78//MUQgiRf+m1a8lprr4OnCubRO1aSUyFedHpoOu76vUDC9TVjKJkJMfD1tnwTXM4uVLtt91sLEw4DC2fBwuZWSSEEMUivXYtkDU5Na3atZKYCvNTs5M6/8aQrPZbF8VLUdRE9NsWsHUWpCZAtbbw/Hbo9wU4uGsdoRBClH3ptWudvTJvd65kMqWiQBY/CXPVdRrM6wpHl0LbiVC+rtYRlU3XT6jln0J3qredq0CP96H+YCn/JIQQJa0U1K6VEVNhnqo0g3p9QTHClplaR1P2xEXC6lfgh/ZqUmppC52mwkv7wX+IJKVCCKGV9Nq1bq1RTLB2rYyYCvPV5W04s0btRXztsHQVKgqGVDgwH7Z8CIl31G31B0P398HVW9PQhBBCmD4ZMRXmq6IfNHxMvb5ZRk0f2sWt8H07WPu6mpRW9Icx/8GjiyQpFUIIkS+FSkzDwsK4cuVKxu2goCAmTZrEjz/+WGSBCVEiOr0Beks4v1GtqykK7vYl+H0k/DxQbV5gVw76fgbPbYPq7bSOTgghRClSqMR0xIgRbNmyBYDr16/TvXt3goKCePPNN3nvvfeKNEAhipVbTWgyWr2+6T11BbnIn+Q42PQ+fNMCTq8GnQW0eA4mHILmz0j5JyGEEAVWqMT0xIkTtGjRAoA///wTf39/du/ezdKlS1m0aFFRxidE8evwP3VxTtheOLde62hMn6LA8b/g62ZqiztDklp+64Wd0OcTsHfTOkIhhBClVKES05SUFGxsbADYuHEjAwaota98fHwIDw8vuuiEKAnOXupIH6gjgEajtvGYAqMBXehOKkftQRe6U+1pD3DtCCzoBcufhrvXwLUqDPsVRq1S5+wKIYQQD6FQ59rq16/P999/T9++fdmwYQPvv/8+ANeuXcPdXYpli1Ko3WQ4uEhtkRm8EvyHah2RdoJXQeAULGOu0QwgdC44ekL5ehCyHVDAyh7avwKtJ4CVrcYBCyGEKCsKNWL60Ucf8cMPP9CpUyeGDx9Oo0aNAFi1alXGKX4hShV7N2gzQb2++QMwpGgbj1aCV8GfoyDmWubtsdchZBugQINH4aUD6hQISUqFEEIUoUKNmHbq1ImIiAhiYmIoV65cxvbnnnsOe3v7IgtOiBLV6kXY9wNEXYAjS6HpaK0jKlmpKbDmf0AuC8AcysPgH0yuILMQQoiyoVCJaUJCAoqiZCSloaGhrFy5El9fX3r27FmkAQpRYmycoP2rsG4qbPsIGg4rWyOCSXch+kraJQyirz5w+woohtwfI+4WhO6GGu1LJmYhhBBmpVCJ6cCBAxkyZAgvvPACd+7coWXLllhZWREREcHnn3/Oiy++WNRxClEymo2FPd9CzBW1g1Hr8VpHlD+GVLgbnjnRjHkg8UyMLppjxd4omscRQgghHlCoxPTQoUN88cUXAPz1119UrFiRw4cPs3z5ct59911JTEXpZWULnabAqgmw4zNoMkodSdWSoqidlDKSzGxGPO9eAyUf1QRsXcHFG1yqpF0q37sdcw3+eirvx3Cs+LA/kRBCCJGtQiWm8fHxODmpb9br169nyJAh6PV6WrVqRWhoaJEGKESJazQCds5R55ru/kbtXhR7Q03IqrUp+vmVqckPjG7ed2o9fXtybN6Po7fKnGi6VAHn+29Xzj3JNhrAuRLEhJP9PFOd+v1qbQr7kwohhBC5KlRiWrt2bf7++28GDx7MunXrmDx5MgA3b97E2dm5SAMUosRZWEKXt+Cvsepc022z733PuRL0+gj8BuTvsRQF4iPvJZoPJp7RV9NOjeej45S9x30jnd5ZRzwdKoC+UIU2VHoL9Wf7cxSgeyAmnfql12xZ+CSEEKLYFCoxfffddxkxYgSTJ0+mS5cutG7dGlBHTxs3blykAQqhCV36n8YDCWNMuJq4PfazmpymJKSdUs8h8Yy5CqmJeR/P0va+pPO+xDNjxLMyWNkV+Y+Zhd8A9WcLnJK5ZJRzJTUpzW9CLoQQQhRCoRLTRx55hHbt2hEeHp5RwxSga9euDB48uMiCE0ITRgOseyOHb6Ylqn+NVU+LJ0Tl7zEdPbNPPNNHPO3dQacrkvAfmt8A8OlL6sXtHNmxjoD2PbGs2UFGSoUQQhS7QiWmAJ6ennh6enLlyhV0Oh2VK1eW4vqibAjdnbXA/IOMKfeSUmvHB5LOB0Y8nSuBpU3xx12U9BYo1dpx9WQMjaq1k6RUCCFEiShUYmo0Gpk5cyafffYZsbHqogwnJydeffVV3nrrLfQPM89NCK3ltxxS1+nQbIy60t1URjuFEEKIUqxQielbb73F/PnzmT17Nm3btkVRFHbt2sX06dNJTEzkgw8+KOo4hSg5+S2HVKUZ2JXLez8hhBBC5EuhEtPFixczb948Bgy4txCiUaNGVK5cmXHjxkliKkq3am2kbJIQQgihgUKdc4+KisLHxyfLdh8fH6Ki8rkYRAhTlV42Ccgok5RByiYJIYQQxaVQiWmjRo345ptvsmz/5ptvaNiw4UMHJYTm0ssmOXtl3u5c6V6pKCGEEEIUqUKdyv/444/p27cvGzdupHXr1uh0Onbv3k1YWBhr1qwp6hiF0EZa2SRCdxdv5ychhBBCAIUcMe3YsSNnz55l8ODB3Llzh6ioKIYMGcLJkydZuHBhUccohHb0FlCjPTR4RP0qSakQQghRbApdx7RSpUpZFjkdPXqUxYsXs2DBgocOTAghhBBCmBcpOCqEEEIIIUyCJKZCCCGEEMIkSGIqhBBCCCFMQoHmmA4ZMiTX79+5c+dhYhFCCCGEEGasQImpi4tLnt8fNWrUQwUkhBBCCCHMU4ESUykFJYQQQgghiovMMRVCCCGEECZBElMhhBBCCGESNE1M586dS8OGDXF2dsbZ2ZnWrVuzdu1aLUMSQgghhBAa0TQxrVKlCrNnz+bAgQMcOHCALl26MHDgQE6ePKllWEIIIYQQQgOFbklaFPr375/p9gcffMDcuXPZu3cv9evX1ygqIYQQQgihBU0T0/sZDAaWLVtGXFwcrVu3znafpKQkkpKSMm7HxMQAkJKSQkpKSonEaa7Sn195ns2HvObmR15z8ySvu/kp6de8IMfRKYqiFGMseTp+/DitW7cmMTERR0dHli5dSp8+fbLdd/r06cyYMSPL9qVLl2Jvb1/coQohhBBCiAKKj49nxIgRREdH4+zsnOu+miemycnJXL58mTt37rB8+XLmzZvHtm3b8PPzy7JvdiOm3t7eRERE5PmDioeTkpLChg0b6N69O1ZWVlqHI0qAvObmR15z8ySvu/kp6dc8JiYGDw+PfCWmmp/Kt7a2pnbt2gA0a9aM/fv38+WXX/LDDz9k2dfGxgYbG5ss262srOSPqYTIc21+5DU3P/Kamyd53c1PSb3mBTmGydUxVRQl06ioEEIIIYQwD5qOmL755pv07t0bb29v7t69y++//87WrVsJDAzUMiwhhBBCCKEBTRPTGzdu8OSTTxIeHo6LiwsNGzYkMDCQ7t27axmWEEIIIYTQgKaJ6fz587U8vBBCCCGEMCEmN8dUCCGEEEKYJ0lMhRBCCCGESZDEVAghhBBCmARJTIUQQgghhEmQxFQIIYQQQpgESUyFEEIIIYRJkMRUCCGEEEKYBElMhRBCCCGESZDEVAghhBBCmARJTIUQQgghhEmQxFQIIYQQQpgESUyFEEIIIYRJkMRUCCGEEEKYBElMhRBCCCGESZDEVAghhBBCmARJTIUQQgghhEmQxFQIIYQQQpgESUyFEEIIIYRJkMRUCCGEEEKYBElMhRBCCCGESZDEVAghhBBCmARJTIUQQgghhEmQxFQIIYQQQpgESUyFEEIIIYRJkMRUCCGEEEKYBElMhRBCCCGESZDEVAghhBBCmARJTIUQQgghhEmQxFQIIYQQQpgESUyFEEIIIYRJkMRUCCGEEEKYBElMhRBCCCGESZDEVAghhBBCmARJTIUQQgghhEmQxFQIIYQQQpgESUyFEEIIIYRJkMRUCCGEEEKYBElMhRBCCCGESZDEVAghhBBCmARJTIUQQgghhEmQxFQIIYQQQpgESUyFEEIIIYRJkMRUCCGEEEKYBElMhRBCCCGESZDEVAghhBBCmARJTIUQQgghhEmQxFQIIYQQQpgESUyFEEIIIYRJkMRUCCGEEEKYBElMhRBCCCGESZDEVAghhBBCmARJTIUQQgghhEmQxFQIIYQQQpgESUyFEEIIIYRJkMRUCCGEEEKYBElMhRBCCCGESZDEVAghhBBCmARJTIUQQgghhEnQNDGdNWsWzZs3x8nJiQoVKjBo0CDOnDmjZUhCCCGEEEIjmiam27ZtY/z48ezdu5cNGzaQmppKjx49iIuL0zIsIYQQQgihAUstDx4YGJjp9sKFC6lQoQIHDx6kQ4cOGkUlhBBCCCG0oGli+qDo6GgA3Nzcsv1+UlISSUlJGbdjYmIASElJISUlpfgDNGPpz688z+ZDXnPzI6+5eZLX3fyU9GtekOPoFEVRijGWfFMUhYEDB3L79m127NiR7T7Tp09nxowZWbYvXboUe3v74g5RCCGEEEIUUHx8PCNGjCA6OhpnZ+dc9zWZxHT8+PH8999/7Ny5kypVqmS7T3Yjpt7e3kREROT5g4qHk5KSwoYNG+jevTtWVlZahyNKgLzm5kdec/Mkr7v5KenXPCYmBg8Pj3wlpiZxKn/ChAmsWrWK7du355iUAtjY2GBjY5Nlu5WVlfwxlRB5rs2PvObmR15z8ySvu/kpqde8IMfQNDFVFIUJEyawcuVKtm7dSo0aNbQMRwghhBBCaEjTxHT8+PEsXbqUf/75BycnJ65fvw6Ai4sLdnZ2WoYmhBBCCCFKmKZ1TOfOnUt0dDSdOnXCy8sr4/LHH39oGZYQQgghhNCA5qfyhRBCCCGEAI1HTIUQQgghhEgniakQQgghhDAJkpgKIYQQQgiTIImpEEIIIYQwCZKYCiGEEEIIkyCJqRBCCCGEMAmSmAohhBBCCJMgiakQQgghhDAJkpgKIYQQQgiTIImpEEIIIYQwCZKYCiGEEEIIkyCJqRBCCCGEMAmSmAohhBBCCJMgiakQQgghhDAJkpgKIYQQQgiTIImpEEIIIYQwCZKYCiGEEEIIkyCJqRBCCCGEMAmSmAohhBBCCJMgiakQQgghhDAJkpgKIYQQQgiTIImpEEIIIYQwCZKYCiGEEEIIkyCJqRBCCCGEMAmSmAohhBBCCJMgiakQQgghhDAJkpgKIYQQQgiTIImpEEIIIYQwCZKYCiGEEEIIkyCJqRBCCCGEMAmSmAohhBBCCJMgiakQQgjx//buPqbquv/j+OuEcABDHRgHj4GdlgVqoUk5b0pY6cRiY7VutBtZSrlQO52tiWUKLmHaYm6RFM3pumH5R6HO6RbLBRozlKSaqeRiSpYjb0LADUHP749+nutieHtdnvP5XJ7nY+OP74fvgTd8pnvue76cA8AKhCkAAACsQJgCAADACoQpAAAArECYAgAAwAqEKQAAAKxAmAIAAMAKhCkAAACsQJgCAADACoQpAAAArECYAgAAwAqEKQAAAKxAmAIAAMAKhCkAAACsQJgCAADACoQpAAAArECYAgAAwAqEKQAAAKxAmAIAAMAKhCkAAACsQJgCAADACoQpAAAArECYAgAAwAqEKQAAAKxAmAIAAMAKhCkAAACsQJgCAADACoQpAAAArGA0TOvq6pSTkyO32y2Hw6FNmzaZHAcAAAAGGQ3Trq4upaenq7y83OQYAAAAsMAAk988Oztb2dnZ13x+d3e3uru7A8dnzpyRJPX09Kinp+eGz4d/ufj75fccPtjz8MOehyf2PfyEes+v5/s4/H6/P4izXDOHw6Hq6mrl5uZe9pyioiIVFxf3W6+qqlJsbGwQpwMAAMB/4uzZs5o9e7ba29s1aNCgK577PxWml7pimpycrBMnTlz1B8V/p6enRzU1NZo2bZoiIyNNj4MQYM/DD3sentj38BPqPT9z5oyGDh16TWFq9Kn86+V0OuV0OvutR0ZG8o8pRPhdhx/2PPyw5+GJfQ8/odrz6/kevFwUAAAArECYAgAAwApGn8rv7OzU4cOHA8ctLS1qampSfHy8UlJSDE4GAACAUDMapnv37lVWVlbg2OfzSZLmzJmjDRs2GJoKAAAAJhgN08zMTFnyogAAAAAwjHtMAQAAYAXCFAAAAFYgTAEAAGAFwhQAAABWIEwBAABgBcIUAAAAViBMAQAAYAXCFAAAAFYgTAEAAGAFwhQAAABWIEwBAABgBcIUAAAAViBMAQAAYAXCFAAAAFYgTAEAAGAFwhQAAABWIEwBAABgBcIUAAAAViBMAQAAYAXCFAAAAFYgTAEAAGAFwhQAAABWIEwBAABgBcIUAAAAViBMAQAAYAXCFAAAAFYgTAEAAGAFwhQAAABWIEwBAABgBcIUAAAAViBMAQAAYAXCFAAAAFYgTAEAAGAFwhQAAABWIEwBAABgBcIUAAAAViBMAQAAYAXCFAAAAFYgTAEAAGAFwhQAAABWIEwBAABgBcIUAAAAViBMAQAAYAXCFAAAAFYgTAEAAGAFwhQAAABWIEwBAABgBcIUAAAAViBMAQAAYAXCFAAAAFYgTAEAAGAFwhQAAABWIEwBAABgBcIUAAAAViBMAQAAYAXCFAAAAFYgTAEAAGAFwhQAAABWMB6ma9eulcfjUXR0tMaPH6+dO3eaHgkAAAAGGA3TjRs3yuv16q233tK+ffv00EMPKTs7W0ePHjU5FgAAAAwwGqZlZWWaO3eu5s2bp7S0NK1Zs0bJycmqqKgwORYAAAAMGGDqG587d06NjY0qLCzssz59+nTV19df8jHd3d3q7u4OHLe3t0uSTp06pZ6enuANC/X09Ojs2bM6efKkIiMjTY+DEGDPww97Hp7Y9/AT6j3v6OiQJPn9/queayxMT5w4ofPnz8vlcvVZd7lcOn78+CUfU1paquLi4n7rHo8nKDMCAADgxujo6NDgwYOveI6xML3I4XD0Ofb7/f3WLlqyZIl8Pl/g+MKFCzp16pQSEhIu+xjcGGfOnFFycrJaW1s1aNAg0+MgBNjz8MOehyf2PfyEes/9fr86Ojrkdruveq6xMB06dKgiIiL6XR1ta2vrdxX1IqfTKafT2WdtyJAhwRoRlzBo0CD+4woz7Hn4Yc/DE/sefkK551e7UnqRsT9+ioqK0vjx41VTU9NnvaamRpMmTTI0FQAAAEwx+lS+z+fTCy+8oIyMDE2cOFGVlZU6evSo5s+fb3IsAAAAGGA0TJ955hmdPHlSK1as0J9//qkxY8Zo27ZtGjFihMmxcAlOp1PLly/vdysFbl7sefhhz8MT+x5+bN5zh/9a/nYfAAAACDLjb0kKAAAASIQpAAAALEGYAgAAwAqEKQAAAKxAmOKKSktL9cADDyguLk6JiYnKzc3VoUOHTI+FECktLZXD4ZDX6zU9CoLs2LFjev7555WQkKDY2FiNHTtWjY2NpsdCkPT29mrp0qXyeDyKiYnRnXfeqRUrVujChQumR8MNVFdXp5ycHLndbjkcDm3atKnP5/1+v4qKiuR2uxUTE6PMzEzt37/fzLD/jzDFFdXW1qqgoEC7d+9WTU2Nent7NX36dHV1dZkeDUG2Z88eVVZW6r777jM9CoLs9OnTmjx5siIjI7V9+3b98ssveu+993hnvZvYqlWr9OGHH6q8vFwHDhzQ6tWr9e677+r99983PRpuoK6uLqWnp6u8vPySn1+9erXKyspUXl6uPXv2KCkpSdOmTVNHR0eIJ/0XXi4K1+Wvv/5SYmKiamtr9fDDD5seB0HS2dmp+++/X2vXrtU777yjsWPHas2aNabHQpAUFhbqu+++086dO02PghB5/PHH5XK5tG7dusDak08+qdjYWH366acGJ0OwOBwOVVdXKzc3V9I/V0vdbre8Xq8WL14sSeru7pbL5dKqVav0yiuvGJmTK6a4Lu3t7ZKk+Ph4w5MgmAoKCvTYY4/p0UcfNT0KQmDLli3KyMjQU089pcTERI0bN04ff/yx6bEQRFOmTNE333yj5uZmSdKPP/6oXbt2aebMmYYnQ6i0tLTo+PHjmj59emDN6XRq6tSpqq+vNzaX0Xd+wv8Wv98vn8+nKVOmaMyYMabHQZB88cUX+uGHH7Rnzx7ToyBEfvvtN1VUVMjn8+nNN99UQ0ODFi1aJKfTqRdffNH0eAiCxYsXq729XampqYqIiND58+e1cuVKzZo1y/RoCJHjx49LklwuV591l8ulI0eOmBhJEmGK67BgwQL99NNP2rVrl+lRECStra167bXX9PXXXys6Otr0OAiRCxcuKCMjQyUlJZKkcePGaf/+/aqoqCBMb1IbN27UZ599pqqqKo0ePVpNTU3yer1yu92aM2eO6fEQQg6Ho8+x3+/vtxZKhCmuycKFC7VlyxbV1dXp9ttvNz0OgqSxsVFtbW0aP358YO38+fOqq6tTeXm5uru7FRERYXBCBMOwYcM0atSoPmtpaWn68ssvDU2EYHvjjTdUWFioZ599VpJ077336siRIyotLSVMw0RSUpKkf66cDhs2LLDe1tbW7ypqKHGPKa7I7/drwYIF+uqrr7Rjxw55PB7TIyGIHnnkEf38889qamoKfGRkZOi5555TU1MTUXqTmjx5cr+XgWtubtaIESMMTYRgO3v2rG65pW8CRERE8HJRYcTj8SgpKUk1NTWBtXPnzqm2tlaTJk0yNhdXTHFFBQUFqqqq0ubNmxUXFxe4J2Xw4MGKiYkxPB1utLi4uH73Dw8cOFAJCQncV3wTe/311zVp0iSVlJTo6aefVkNDgyorK1VZWWl6NARJTk6OVq5cqZSUFI0ePVr79u1TWVmZXnrpJdOj4Qbq7OzU4cOHA8ctLS1qampSfHy8UlJS5PV6VVJSopEjR2rkyJEqKSlRbGysZs+ebWxmXi4KV3S5+0zWr1+vvLy80A4DIzIzM3m5qDCwdetWLVmyRL/++qs8Ho98Pp/y8/NNj4Ug6ejo0Ntvv63q6mq1tbXJ7XZr1qxZWrZsmaKiokyPhxvk22+/VVZWVr/1OXPmaMOGDfL7/SouLtZHH32k06dPa8KECfrggw+MXoggTAEAAGAF7jEFAACAFQhTAAAAWIEwBQAAgBUIUwAAAFiBMAUAAIAVCFMAAABYgTAFAACAFQhTAAAAWIEwBQBLZWZmyuv1XvGcO+64g3flAnDTIEwBIIjy8vLkcDj6ffz7+1cDAP4xwPQAAHCzmzFjhtavX99n7bbbbjM0DQDYiyumABBkTqdTSUlJfT4iIiJUW1urBx98UE6nU8OGDVNhYaF6e3sv+3Xa2tqUk5OjmJgYeTweff755yH8KQAg+LhiCgAGHDt2TDNnzlReXp4++eQTHTx4UPn5+YqOjlZRUdElH5OXl6fW1lbt2LFDUVFRWrRokdra2kI7OAAEEWEKAEG2detW3XrrrYHj7Oxs3X333UpOTlZ5ebkcDodSU1P1xx9/aPHixVq2bJluuaXvE1rNzc3avn27du/erQkTJkiS1q1bp7S0tJD+LAAQTIQpAARZVlaWKioqAscDBw5UQUGBJk6cKIfDEVifPHmyOjs79fvvvyslJaXP1zhw4IAGDBigjIyMwFpqaqqGDBkS9PkBIFQIUwAIsoEDB+quu+7qs+b3+/tE6cU1Sf3Wr/Y5ALhZ8MdPAGDAqFGjVF9fHwhOSaqvr1dcXJyGDx/e7/y0tDT19vZq7969gbVDhw7p77//DsW4ABAShCkAGPDqq6+qtbVVCxcu1MGDB7V582YtX75cPp+v3/2lknTPPfdoxowZys/P1/fff6/GxkbNmzdPMTExBqYHgOAgTAHAgOHDh2vbtm1qaGhQenq65s+fr7lz52rp0qWXfcz69euVnJysqVOn6oknntDLL7+sxMTEEE4NAMHl8P/780gAAACAIVwxBQAAgBUIUwAAAFiBMAUAAIAVCFMAAABYgTAFAACAFQhTAAAAWIEwBQAAgBUIUwAAAFiBMAUAAIAVCFMAAABYgTAFAACAFf4PNrzkLD5THyYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "folds = list(range(1, len(all_fold_maes) + 1))\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(folds, all_fold_rmses, marker='o', label='Best RMSE per Fold')\n",
    "plt.plot(folds, all_fold_maes, marker='o', label='Best MAE per Fold')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Best RMSE and MAE per Fold')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.ylim(bottom=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 most important nodes:\n",
      "1. Node 36 with score 0.3826\n",
      "2. Node 67 with score 0.3271\n",
      "3. Node 90 with score 0.3160\n",
      "4. Node 59 with score 0.3157\n",
      "5. Node 65 with score 0.3127\n",
      "6. Node 34 with score 0.2961\n",
      "7. Node 70 with score 0.2632\n",
      "8. Node 22 with score 0.2593\n",
      "9. Node 38 with score 0.2546\n",
      "10. Node 69 with score 0.2542\n",
      "[np.int64(2), np.int64(4), np.int64(5), np.int64(7), np.int64(8), np.int64(10), np.int64(11), np.int64(12), np.int64(13), np.int64(14), np.int64(15), np.int64(16), np.int64(17), np.int64(18), np.int64(24), np.int64(26), np.int64(28), np.int64(31), np.int64(41), np.int64(43), np.int64(44), np.int64(46), np.int64(47), np.int64(49), np.int64(50), np.int64(51), np.int64(52), np.int64(53), np.int64(54), np.int64(58), np.int64(60), np.int64(63), np.int64(77), np.int64(1002), np.int64(1003), np.int64(1005), np.int64(1006), np.int64(1007), np.int64(1008), np.int64(1009), np.int64(1010), np.int64(1011), np.int64(1012), np.int64(1013), np.int64(1014), np.int64(1015), np.int64(1016), np.int64(1017), np.int64(1018), np.int64(1019), np.int64(1020), np.int64(1021), np.int64(1022), np.int64(1023), np.int64(1024), np.int64(1025), np.int64(1026), np.int64(1027), np.int64(1028), np.int64(1029), np.int64(1030), np.int64(1031), np.int64(1034), np.int64(1035), np.int64(2002), np.int64(2003), np.int64(2005), np.int64(2006), np.int64(2007), np.int64(2008), np.int64(2009), np.int64(2010), np.int64(2011), np.int64(2012), np.int64(2013), np.int64(2014), np.int64(2015), np.int64(2016), np.int64(2017), np.int64(2018), np.int64(2019), np.int64(2020), np.int64(2021), np.int64(2022), np.int64(2023), np.int64(2024), np.int64(2025), np.int64(2026), np.int64(2027), np.int64(2028), np.int64(2029), np.int64(2030), np.int64(2031), np.int64(2034), np.int64(2035)]\n",
      "\n",
      "Top 10 Most Important Brain Regions:\n",
      "1. Node 36 = Label 1006 = ctx-lh-entorhinal with score 0.3826\n",
      "2. Node 67 = Label 2006 = ctx-rh-entorhinal with score 0.3271\n",
      "3. Node 90 = Label 2029 = ctx-rh-superiorparietal with score 0.3160\n",
      "4. Node 59 = Label 1029 = ctx-lh-superiorparietal with score 0.3157\n",
      "5. Node 65 = Label 2003 = ctx-rh-caudalmiddlefrontal with score 0.3127\n",
      "6. Node 34 = Label 1003 = ctx-lh-caudalmiddlefrontal with score 0.2961\n",
      "7. Node 70 = Label 2009 = ctx-rh-inferiortemporal with score 0.2632\n",
      "8. Node 22 = Label 47 = Right-Cerebellum-Cortex with score 0.2593\n",
      "9. Node 38 = Label 1008 = ctx-lh-inferiorparietal with score 0.2546\n",
      "10. Node 69 = Label 2008 = ctx-rh-inferiorparietal with score 0.2542\n",
      "\n",
      "Top 10 Most Important Brain Regions:\n",
      "1. Node 36 = Label 1006 = ctx-lh-entorhinal with score 0.3826\n",
      "2. Node 67 = Label 2006 = ctx-rh-entorhinal with score 0.3271\n",
      "3. Node 90 = Label 2029 = ctx-rh-superiorparietal with score 0.3160\n",
      "4. Node 59 = Label 1029 = ctx-lh-superiorparietal with score 0.3157\n",
      "5. Node 65 = Label 2003 = ctx-rh-caudalmiddlefrontal with score 0.3127\n",
      "6. Node 34 = Label 1003 = ctx-lh-caudalmiddlefrontal with score 0.2961\n",
      "7. Node 70 = Label 2009 = ctx-rh-inferiortemporal with score 0.2632\n",
      "8. Node 22 = Label 47 = Right-Cerebellum-Cortex with score 0.2593\n",
      "9. Node 38 = Label 1008 = ctx-lh-inferiorparietal with score 0.2546\n",
      "10. Node 69 = Label 2008 = ctx-rh-inferiorparietal with score 0.2542\n",
      "\n",
      "Saved top ROI importance to roi_importance.csv\n",
      "Using atlas: /projectnb/ec523/projects/proj_GS_LQ_EPB/models/T1stats_GNN/template/aparc+aseg.mgz\n",
      "Unique labels in atlas: [   0    2    4    5    7    8   10   11   12   13   14   15   16   17\n",
      "   18   24   26   28   30   31   41   43   44   46   47   49   50   51\n",
      "   52   53   54   58   60   62   63   77   85  251  252  253  254  255\n",
      " 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013\n",
      " 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027\n",
      " 1028 1029 1030 1031 1032 1033 1034 1035 2000 2001 2002 2003 2004 2005\n",
      " 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019\n",
      " 2020 2021 2022 2023 2024 2025 2026 2027 2028 2029 2030 2031 2032 2033\n",
      " 2034 2035]\n",
      "Number of unique labels: 114\n",
      "Saved heatmap NIfTI to dkt_roi_heatmap.nii.gz\n",
      "Saved glass brain plot to dkt_roi_heatmap_glass.png\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from nilearn import plotting\n",
    "import pandas as pd\n",
    "\n",
    "# Load trained model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GATRegressor(in_channels=4, hidden_channels=64, heads=4)\n",
    "model.load_state_dict(torch.load('gat_fold5_best_model.pt', map_location=device, weights_only=False))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Load dataset\n",
    "dataset = BrainGraphDataset(torch.load('hcp_brain_graph_dataset.pt', weights_only=False) + torch.load('ppmi_brain_graph_dataset.pt', weights_only=False))\n",
    "dataloader = DataLoader(dataset, batch_size=1)\n",
    "num_nodes = dataset[0].num_nodes\n",
    "\n",
    "node_attention_sum = torch.zeros(num_nodes, device=device)\n",
    "node_counts = torch.zeros(num_nodes, device=device)\n",
    "\n",
    "# Analyze attention\n",
    "for data in dataloader:\n",
    "    data = data.to(device)\n",
    "    x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "\n",
    "    # Get first GAT layer attention\n",
    "    x1, (edge_idx1, attn_weights1) = model.gat1(x, edge_index, return_attention_weights=True)\n",
    "    attn_mean = attn_weights1.mean(dim=1)\n",
    "    dest_nodes = edge_idx1[1]\n",
    "\n",
    "    for idx, dest in enumerate(dest_nodes):\n",
    "        node_attention_sum[dest] += attn_mean[idx]\n",
    "        node_counts[dest] += 1\n",
    "\n",
    "# Normalize attention by number of times each node was visited\n",
    "avg_node_attention = node_attention_sum / (node_counts + 1e-8)\n",
    "\n",
    "# Find top 10 nodes\n",
    "topk = 10\n",
    "topk_nodes = torch.topk(avg_node_attention, k=topk)\n",
    "\n",
    "print(\"Top 10 most important nodes:\")\n",
    "for rank, (node_idx, score) in enumerate(zip(topk_nodes.indices.tolist(), topk_nodes.values.tolist()), 1):\n",
    "    print(f\"{rank}. Node {node_idx} with score {score:.4f}\")\n",
    "\n",
    "def load_freesurfer_lut(lut_path):\n",
    "    \"\"\"Reads FreeSurfer LUT and returns a {label: region_name} dictionary.\"\"\"\n",
    "    lut_dict = {}\n",
    "    with open(lut_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.strip() == '' or line.strip().startswith('#'):\n",
    "                continue\n",
    "            \n",
    "            parts = line.strip().split()\n",
    "            if len(parts) >= 2:\n",
    "                try:\n",
    "                    label_num = int(parts[0])\n",
    "                    label_name = parts[1]\n",
    "                    lut_dict[label_num] = label_name\n",
    "                except ValueError:\n",
    "                    continue\n",
    "    return lut_dict\n",
    "\n",
    "lut_path = '/projectnb/ec523/projects/proj_GS_LQ_EPB/models/T1stats_GNN/FsTutorial_AnatomicalROI_FreeSurferColorLUT.txt'\n",
    "freesurfer_lut = load_freesurfer_lut(lut_path)\n",
    "\n",
    "def build_label_list(segmentation_path):\n",
    "    \"\"\"Builds sorted label list from a segmentation file.\"\"\"\n",
    "    seg = nib.load(segmentation_path).get_fdata()\n",
    "    labels = np.unique(seg)\n",
    "    labels = labels[labels != 0]\n",
    "    return sorted(labels.astype(int))\n",
    "\n",
    "segmentation_file = '/projectnb/ec523/projects/proj_GS_LQ_EPB/data/T1w_segmented/HCP_processed/100307/100307/mri/aparc.DKTatlas+aseg.deep.mgz'\n",
    "label_list = build_label_list(segmentation_file)\n",
    "print(label_list)\n",
    "\n",
    "# === Top 10 Most Important Brain Regions ===\n",
    "roi_rows = []\n",
    "print(\"\\nTop 10 Most Important Brain Regions:\")\n",
    "for rank, (node_idx, score) in enumerate(zip(topk_nodes.indices.tolist(), topk_nodes.values.tolist()), 1):\n",
    "    label_number = label_list[node_idx]\n",
    "    region_name = freesurfer_lut.get(label_number, f\"Unknown Label {label_number}\")\n",
    "    print(f\"{rank}. Node {node_idx} = Label {label_number} = {region_name} with score {score:.4f}\")\n",
    "\n",
    "    roi_rows.append({\n",
    "        \"atlas_index\": label_number,\n",
    "        \"importance\": float(score)\n",
    "    })\n",
    "\n",
    "roi_df = pd.DataFrame(roi_rows)\n",
    "roi_csv_path = \"roi_importance.csv\"\n",
    "roi_df.to_csv(roi_csv_path, index=False)\n",
    "print(f\"\\nSaved top ROI importance to {roi_csv_path}\")\n",
    "\n",
    "## Use brain atlas\n",
    "ATLAS_PATH = '/projectnb/ec523/projects/proj_GS_LQ_EPB/models/T1stats_GNN/template/aparc+aseg.mgz'\n",
    "OUT_PREFIX = \"dkt_roi_heatmap\"\n",
    "\n",
    "print(f\"Using atlas: {ATLAS_PATH}\")\n",
    "\n",
    "## Build heatmap\n",
    "atlas_img = nib.load(ATLAS_PATH)\n",
    "atlas_data = atlas_img.get_fdata().astype(int)\n",
    "heat = np.zeros_like(atlas_data, dtype=np.float32)\n",
    "\n",
    "unique_labels = np.unique(atlas_data)\n",
    "print(\"Unique labels in atlas:\", unique_labels)\n",
    "print(\"Number of unique labels:\", len(unique_labels))\n",
    "\n",
    "for _, row in roi_df.iterrows():\n",
    "    label = int(row[\"atlas_index\"])\n",
    "    weight = float(row[\"importance\"])\n",
    "    heat[atlas_data == label] = weight\n",
    "\n",
    "heat_img = nib.Nifti1Image(heat, affine=atlas_img.affine, header=atlas_img.header)\n",
    "nib.save(heat_img, f\"{OUT_PREFIX}.nii.gz\")\n",
    "print(f\"Saved heatmap NIfTI to {OUT_PREFIX}.nii.gz\")\n",
    "\n",
    "## Plot glass brain\n",
    "display = plotting.plot_glass_brain(\n",
    "    heat_img,\n",
    "    colorbar=True,\n",
    "    plot_abs=False,\n",
    "    threshold=1e-6,\n",
    "    title=\"Top-ROI importance (DKT atlas)\",\n",
    ")\n",
    "display.savefig(f\"{OUT_PREFIX}_glass.png\", dpi=300)\n",
    "display.close()\n",
    "print(f\"Saved glass brain plot to {OUT_PREFIX}_glass.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Avg MSE Loss: 2009.6356\n",
      "Epoch 2 - Avg MSE Loss: 1162.3388\n",
      "Epoch 3 - Avg MSE Loss: 662.3371\n",
      "Epoch 4 - Avg MSE Loss: 305.8184\n",
      "Epoch 5 - Avg MSE Loss: 157.6215\n",
      "Epoch 6 - Avg MSE Loss: 103.5220\n",
      "Epoch 7 - Avg MSE Loss: 94.8596\n",
      "Epoch 8 - Avg MSE Loss: 96.8812\n",
      "Epoch 9 - Avg MSE Loss: 98.3416\n",
      "Epoch 10 - Avg MSE Loss: 100.6850\n",
      "\n",
      "AFTER Fine-tuning on ADNI:\n",
      "ADNI MAE: 7.6516\n",
      "ADNI RMSE: 9.8084\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load your model\n",
    "device = torch.device('cpu')\n",
    "model = GATRegressor(in_channels=4, hidden_channels=64, heads=4)\n",
    "model.load_state_dict(torch.load('gat_fold5_best_model.pt', map_location='cpu', weights_only=False))\n",
    "model = model.to('cpu')\n",
    "model.train()\n",
    "\n",
    "# Load the graphs\n",
    "adni_graphs = torch.load('adni_brain_graph_dataset.pt', map_location='cpu', weights_only=False)\n",
    "\n",
    "adni_dataset = BrainGraphDataset(adni_graphs)\n",
    "adni_loader = DataLoader(adni_dataset, batch_size=8, shuffle=True)  # small batches\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)  # Small LR for fine-tuning\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for data in adni_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.mse_loss(output.squeeze(), data.y.squeeze())  # Regression = MSE loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(adni_loader)\n",
    "    print(f\"Epoch {epoch} - Avg MSE Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# Evaluate after fine-tuning\n",
    "model.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "for data in adni_loader:\n",
    "    output = model(data)\n",
    "    preds = output.view(-1).detach().numpy()\n",
    "    targets = data.y.view(-1).numpy()\n",
    "    all_preds.extend(preds.tolist())\n",
    "    all_targets.extend(targets.tolist())\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "all_targets = np.array(all_targets)\n",
    "\n",
    "mae = np.mean(np.abs(all_preds - all_targets))\n",
    "rmse = np.sqrt(np.mean((all_preds - all_targets) ** 2))\n",
    "\n",
    "torch.save(model.state_dict(), \"gat_finetuned_on_adni.pt\")\n",
    "\n",
    "print(f\"\\nAFTER Fine-tuning on ADNI:\")\n",
    "print(f\"ADNI MAE: {mae:.4f}\")\n",
    "print(f\"ADNI RMSE: {rmse:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER Fine-tuning on ADNI:\n",
      "ADNI MAE: 7.6516\n",
      "ADNI RMSE: 9.8084\n",
      "\n",
      "Top 10 Most Important Nodes in ADNI Dataset:\n",
      "1. Node 36 with score 0.3498\n",
      "2. Node 67 with score 0.3275\n",
      "3. Node 59 with score 0.3192\n",
      "4. Node 90 with score 0.3183\n",
      "5. Node 65 with score 0.3021\n",
      "6. Node 34 with score 0.2770\n",
      "7. Node 11 with score 0.2743\n",
      "8. Node 69 with score 0.2534\n",
      "9. Node 38 with score 0.2528\n",
      "10. Node 76 with score 0.2500\n",
      "\n",
      "Top 10 Most Important Brain Regions in ADNI Dataset:\n",
      "1. Node 36 = Label 1006 = ctx-lh-entorhinal with score 0.3498\n",
      "2. Node 67 = Label 2006 = ctx-rh-entorhinal with score 0.3275\n",
      "3. Node 59 = Label 1029 = ctx-lh-superiorparietal with score 0.3192\n",
      "4. Node 90 = Label 2029 = ctx-rh-superiorparietal with score 0.3183\n",
      "5. Node 65 = Label 2003 = ctx-rh-caudalmiddlefrontal with score 0.3021\n",
      "6. Node 34 = Label 1003 = ctx-lh-caudalmiddlefrontal with score 0.2770\n",
      "7. Node 11 = Label 16 = Brain-Stem with score 0.2743\n",
      "8. Node 69 = Label 2008 = ctx-rh-inferiorparietal with score 0.2534\n",
      "9. Node 38 = Label 1008 = ctx-lh-inferiorparietal with score 0.2528\n",
      "10. Node 76 = Label 2015 = ctx-rh-middletemporal with score 0.2500\n",
      "\n",
      "Saved top ROI importance to all_adni_roi_importance.csv\n",
      "Saved heatmap NIfTI to all_adni_dkt_roi_heatmap.nii.gz\n",
      "Saved glass brain plot to all_adni_dkt_roi_heatmap_glass.png\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from nilearn import plotting\n",
    "import pandas as pd\n",
    "\n",
    "device = torch.device('cpu')\n",
    "model = GATRegressor(in_channels=4, hidden_channels=64, heads=4)\n",
    "model.load_state_dict(torch.load('gat_finetuned_on_adni.pt', map_location='cpu', weights_only=False))\n",
    "model = model.to('cpu')\n",
    "model.eval()\n",
    "\n",
    "adni_graphs = torch.load('adni_brain_graph_dataset.pt', map_location='cpu', weights_only=False)\n",
    "\n",
    "for g in adni_graphs:\n",
    "    if hasattr(g, 'group'):\n",
    "        del g.group\n",
    "\n",
    "adni_dataset = BrainGraphDataset(adni_graphs)\n",
    "adni_loader = DataLoader(adni_dataset, batch_size=1)\n",
    "\n",
    "## Evaluate results on new dataset\n",
    "\n",
    "model.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "for data in adni_loader:\n",
    "    output = model(data)\n",
    "    preds = output.view(-1).detach().numpy()\n",
    "    targets = data.y.view(-1).numpy()\n",
    "    all_preds.extend(preds.tolist())\n",
    "    all_targets.extend(targets.tolist())\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "all_targets = np.array(all_targets)\n",
    "\n",
    "mae = np.mean(np.abs(all_preds - all_targets))\n",
    "rmse = np.sqrt(np.mean((all_preds - all_targets) ** 2))\n",
    "\n",
    "print(f\"\\nAFTER Fine-tuning on ADNI:\")\n",
    "print(f\"ADNI MAE: {mae:.4f}\")\n",
    "print(f\"ADNI RMSE: {rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 37 CN participants.\n",
      "\n",
      "AFTER Fine-tuning on ADNI:\n",
      "CN-ONLY MAE: 5.8681\n",
      "CN-ONLY RMSE: 6.9785\n",
      "\n",
      "Top 10 Most Important Nodes in CN Participants:\n",
      "1. Node 36 with score 0.3814\n",
      "2. Node 67 with score 0.3274\n",
      "3. Node 59 with score 0.3190\n",
      "4. Node 90 with score 0.3136\n",
      "5. Node 65 with score 0.3008\n",
      "6. Node 34 with score 0.2937\n",
      "7. Node 11 with score 0.2741\n",
      "8. Node 69 with score 0.2534\n",
      "9. Node 38 with score 0.2517\n",
      "10. Node 76 with score 0.2483\n",
      "\n",
      "Top 10 Most Important Brain Regions (CN participants):\n",
      "1. Node 36 = Label 1006 = ctx-lh-entorhinal with score 0.3814\n",
      "2. Node 67 = Label 2006 = ctx-rh-entorhinal with score 0.3274\n",
      "3. Node 59 = Label 1029 = ctx-lh-superiorparietal with score 0.3190\n",
      "4. Node 90 = Label 2029 = ctx-rh-superiorparietal with score 0.3136\n",
      "5. Node 65 = Label 2003 = ctx-rh-caudalmiddlefrontal with score 0.3008\n",
      "6. Node 34 = Label 1003 = ctx-lh-caudalmiddlefrontal with score 0.2937\n",
      "7. Node 11 = Label 16 = Brain-Stem with score 0.2741\n",
      "8. Node 69 = Label 2008 = ctx-rh-inferiorparietal with score 0.2534\n",
      "9. Node 38 = Label 1008 = ctx-lh-inferiorparietal with score 0.2517\n",
      "10. Node 76 = Label 2015 = ctx-rh-middletemporal with score 0.2483\n",
      "\n",
      "Saved top ROI importance to cn_adni_roi_importance.csv\n",
      "Saved heatmap NIfTI to cn_adni_dkt_roi_heatmap.nii.gz\n",
      "Saved glass brain plot to results/cn_adni_dkt_roi_heatmap_glass.png\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from nilearn import plotting\n",
    "import pandas as pd\n",
    "\n",
    "# ======= Load model on CPU =======\n",
    "\n",
    "device = torch.device('cpu')\n",
    "model = GATRegressor(in_channels=4, hidden_channels=64, heads=4)\n",
    "model.load_state_dict(torch.load('gat_finetuned_on_adni.pt', map_location='cpu', weights_only=False))\n",
    "model = model.to('cpu')\n",
    "model.eval()\n",
    "\n",
    "adni_graphs = torch.load('adni_brain_graph_dataset.pt', map_location='cpu', weights_only=False)\n",
    "\n",
    "cn_graphs = []\n",
    "for g in adni_graphs:\n",
    "    if hasattr(g, 'group') and g.group == 'CN':\n",
    "        cn_graphs.append(g)\n",
    "\n",
    "print(f\"Found {len(cn_graphs)} CN participants.\")\n",
    "\n",
    "cn_dataset = BrainGraphDataset(cn_graphs)\n",
    "cn_loader = DataLoader(cn_dataset, batch_size=1)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "for data in cn_loader:\n",
    "    output = model(data)\n",
    "    preds = output.view(-1).detach().numpy()\n",
    "    targets = data.y.view(-1).numpy()\n",
    "    all_preds.extend(preds.tolist())\n",
    "    all_targets.extend(targets.tolist())\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "all_targets = np.array(all_targets)\n",
    "\n",
    "mae = np.mean(np.abs(all_preds - all_targets))\n",
    "rmse = np.sqrt(np.mean((all_preds - all_targets) ** 2))\n",
    "\n",
    "print(f\"\\nAFTER Fine-tuning on ADNI:\")\n",
    "print(f\"CN-ONLY MAE: {mae:.4f}\")\n",
    "print(f\"CN-ONLY RMSE: {rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23 AD participants.\n",
      "\n",
      "AFTER Fine-tuning on ADNI:\n",
      "AD-ONLY MAE: 9.5344\n",
      "AD-ONLY RMSE: 12.5945\n",
      "\n",
      "Top 10 Most Important Nodes in AD Participants:\n",
      "1. Node 36 with score 0.3382\n",
      "2. Node 90 with score 0.3239\n",
      "3. Node 59 with score 0.3194\n",
      "4. Node 67 with score 0.3194\n",
      "5. Node 65 with score 0.3067\n",
      "6. Node 11 with score 0.2911\n",
      "7. Node 38 with score 0.2527\n",
      "8. Node 34 with score 0.2527\n",
      "9. Node 69 with score 0.2527\n",
      "10. Node 76 with score 0.2500\n",
      "\n",
      "Top 10 Most Important Brain Regions (AD participants):\n",
      "1. Node 36 = Label 1006 = ctx-lh-entorhinal with score 0.3382\n",
      "2. Node 90 = Label 2029 = ctx-rh-superiorparietal with score 0.3239\n",
      "3. Node 59 = Label 1029 = ctx-lh-superiorparietal with score 0.3194\n",
      "4. Node 67 = Label 2006 = ctx-rh-entorhinal with score 0.3194\n",
      "5. Node 65 = Label 2003 = ctx-rh-caudalmiddlefrontal with score 0.3067\n",
      "6. Node 11 = Label 16 = Brain-Stem with score 0.2911\n",
      "7. Node 38 = Label 1008 = ctx-lh-inferiorparietal with score 0.2527\n",
      "8. Node 34 = Label 1003 = ctx-lh-caudalmiddlefrontal with score 0.2527\n",
      "9. Node 69 = Label 2008 = ctx-rh-inferiorparietal with score 0.2527\n",
      "10. Node 76 = Label 2015 = ctx-rh-middletemporal with score 0.2500\n",
      "\n",
      "Saved top ROI importance to ad_adni_roi_importance.csv\n",
      "Saved heatmap NIfTI to ad_adni_dkt_roi_heatmap.nii.gz\n",
      "Saved glass brain plot to results/ad_adni_dkt_roi_heatmap_glass.png\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from nilearn import plotting\n",
    "import pandas as pd\n",
    "\n",
    "device = torch.device('cpu')\n",
    "model = GATRegressor(in_channels=4, hidden_channels=64, heads=4)\n",
    "model.load_state_dict(torch.load('gat_finetuned_on_adni.pt', map_location='cpu', weights_only=False))\n",
    "model = model.to('cpu')\n",
    "model.eval()\n",
    "\n",
    "adni_graphs = torch.load('adni_brain_graph_dataset.pt', map_location='cpu', weights_only=False)\n",
    "\n",
    "ad_graphs = []\n",
    "for g in adni_graphs:\n",
    "    if hasattr(g, 'group') and g.group == 'AD':\n",
    "        ad_graphs.append(g)\n",
    "\n",
    "print(f\"Found {len(ad_graphs)} AD participants.\")\n",
    "\n",
    "ad_dataset = BrainGraphDataset(ad_graphs)\n",
    "ad_loader = DataLoader(ad_dataset, batch_size=1)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "for data in ad_loader:\n",
    "    output = model(data)\n",
    "    preds = output.view(-1).detach().numpy()\n",
    "    targets = data.y.view(-1).numpy()\n",
    "    all_preds.extend(preds.tolist())\n",
    "    all_targets.extend(targets.tolist())\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "all_targets = np.array(all_targets)\n",
    "\n",
    "mae = np.mean(np.abs(all_preds - all_targets))\n",
    "rmse = np.sqrt(np.mean((all_preds - all_targets) ** 2))\n",
    "\n",
    "print(f\"\\nAFTER Fine-tuning on ADNI:\")\n",
    "print(f\"AD-ONLY MAE: {mae:.4f}\")\n",
    "print(f\"AD-ONLY RMSE: {rmse:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ec523",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
